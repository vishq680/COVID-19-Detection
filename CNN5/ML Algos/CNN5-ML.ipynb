{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import copy\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Covid','No Covid']\n",
    "num_classes=2\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape all images to 64x64 and apply tensor transformation\n",
    "dataset = torchvision.datasets.ImageFolder(root=\"./Full\",transform=transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Resize([227,227])\n",
    "                                                            # transforms.Grayscale(num_output_channels=1)\n",
    "                                                            ]))\n",
    "# testset = torchvision.datasets.ImageFolder(root=\"./xray\",train=False,transform=transforms.Compose([transforms.Resize([300,305]),transforms.ToTensor()]))\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n",
      "1617.5 404.5\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "trainset,testset=torch.utils.data.random_split(dataset,[round(0.8*len(dataset)),round(0.2*len(dataset))],generator=torch.Generator().manual_seed(42))\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=4,shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=4,shuffle=False)\n",
    "print(len(trainset)/batch_size,len(testset)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def get_first_FC_Layer(self,x):\n",
    "            x=self.representation_network(x).flatten(1)\n",
    "            x=self.classification_network[0](x)\n",
    "            return x;\n",
    "    def get_Representation_Net(self,x):\n",
    "            x=self.representation_network(x).flatten(1)\n",
    "            return  x;\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.representation_network=nn.Sequential(\n",
    "            nn.Conv2d(3,32,3), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2,stride=3),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(32,32,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=3),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "        self.classification_network=nn.Sequential(\n",
    "            nn.Linear(18432,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "#         print(x.shape)\n",
    "        x=self.representation_network(x)\n",
    "#         print(x.shape)\n",
    "        # flattening of the vector=> same dimension of first index(batch size) , everythign else is flattened(-1)\n",
    "        x=x.view(x.size(0),-1)\n",
    "#         print(x.shape)\n",
    "        x=self.classification_network(x)\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNN()\n",
    "net.load_state_dict(torch.load(\"./CNN5.pth\").state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader,model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total,correct=0,0\n",
    "        for data in dataloader:\n",
    "            inputs,labels=data\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            outputs=model(inputs)\n",
    "    #         print(outputs)\n",
    "    #         print(outputs,labels)\n",
    "            m = nn.Sigmoid()\n",
    "            outputs=m(outputs)\n",
    "            pred=outputs>=0.5\n",
    "            pred=pred.flatten()\n",
    "            total+=labels.size(0)\n",
    "            # labels=torch.add(labels,-1)\n",
    "            # print(pred,labels)\n",
    "    #         print(list(map(lambda a: classes[a],pred)),list(map(lambda a: classes[a],labels)))\n",
    "            correct+=(pred==labels).sum().item()\n",
    "    print(correct,total)\n",
    "    model.train()\n",
    "    return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 128)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "Done with the batch: 405\n",
      "Done with the batch: 406\n",
      "Done with the batch: 407\n",
      "Done with the batch: 408\n",
      "Done with the batch: 409\n",
      "Done with the batch: 410\n",
      "Done with the batch: 411\n",
      "Done with the batch: 412\n",
      "Done with the batch: 413\n",
      "Done with the batch: 414\n",
      "Done with the batch: 415\n",
      "Done with the batch: 416\n",
      "Done with the batch: 417\n",
      "Done with the batch: 418\n",
      "Done with the batch: 419\n",
      "Done with the batch: 420\n",
      "Done with the batch: 421\n",
      "Done with the batch: 422\n",
      "Done with the batch: 423\n",
      "Done with the batch: 424\n",
      "Done with the batch: 425\n",
      "Done with the batch: 426\n",
      "Done with the batch: 427\n",
      "Done with the batch: 428\n",
      "Done with the batch: 429\n",
      "Done with the batch: 430\n",
      "Done with the batch: 431\n",
      "Done with the batch: 432\n",
      "Done with the batch: 433\n",
      "Done with the batch: 434\n",
      "Done with the batch: 435\n",
      "Done with the batch: 436\n",
      "Done with the batch: 437\n",
      "Done with the batch: 438\n",
      "Done with the batch: 439\n",
      "Done with the batch: 440\n",
      "Done with the batch: 441\n",
      "Done with the batch: 442\n",
      "Done with the batch: 443\n",
      "Done with the batch: 444\n",
      "Done with the batch: 445\n",
      "Done with the batch: 446\n",
      "Done with the batch: 447\n",
      "Done with the batch: 448\n",
      "Done with the batch: 449\n",
      "Done with the batch: 450\n",
      "Done with the batch: 451\n",
      "Done with the batch: 452\n",
      "Done with the batch: 453\n",
      "Done with the batch: 454\n",
      "Done with the batch: 455\n",
      "Done with the batch: 456\n",
      "Done with the batch: 457\n",
      "Done with the batch: 458\n",
      "Done with the batch: 459\n",
      "Done with the batch: 460\n",
      "Done with the batch: 461\n",
      "Done with the batch: 462\n",
      "Done with the batch: 463\n",
      "Done with the batch: 464\n",
      "Done with the batch: 465\n",
      "Done with the batch: 466\n",
      "Done with the batch: 467\n",
      "Done with the batch: 468\n",
      "Done with the batch: 469\n",
      "Done with the batch: 470\n",
      "Done with the batch: 471\n",
      "Done with the batch: 472\n",
      "Done with the batch: 473\n",
      "Done with the batch: 474\n",
      "Done with the batch: 475\n",
      "Done with the batch: 476\n",
      "Done with the batch: 477\n",
      "Done with the batch: 478\n",
      "Done with the batch: 479\n",
      "Done with the batch: 480\n",
      "Done with the batch: 481\n",
      "Done with the batch: 482\n",
      "Done with the batch: 483\n",
      "Done with the batch: 484\n",
      "Done with the batch: 485\n",
      "Done with the batch: 486\n",
      "Done with the batch: 487\n",
      "Done with the batch: 488\n",
      "Done with the batch: 489\n",
      "Done with the batch: 490\n",
      "Done with the batch: 491\n",
      "Done with the batch: 492\n",
      "Done with the batch: 493\n",
      "Done with the batch: 494\n",
      "Done with the batch: 495\n",
      "Done with the batch: 496\n",
      "Done with the batch: 497\n",
      "Done with the batch: 498\n",
      "Done with the batch: 499\n",
      "Done with the batch: 500\n",
      "Done with the batch: 501\n",
      "Done with the batch: 502\n",
      "Done with the batch: 503\n",
      "Done with the batch: 504\n",
      "Done with the batch: 505\n",
      "Done with the batch: 506\n",
      "Done with the batch: 507\n",
      "Done with the batch: 508\n",
      "Done with the batch: 509\n",
      "Done with the batch: 510\n",
      "Done with the batch: 511\n",
      "Done with the batch: 512\n",
      "Done with the batch: 513\n",
      "Done with the batch: 514\n",
      "Done with the batch: 515\n",
      "Done with the batch: 516\n",
      "Done with the batch: 517\n",
      "Done with the batch: 518\n",
      "Done with the batch: 519\n",
      "Done with the batch: 520\n",
      "Done with the batch: 521\n",
      "Done with the batch: 522\n",
      "Done with the batch: 523\n",
      "Done with the batch: 524\n",
      "Done with the batch: 525\n",
      "Done with the batch: 526\n",
      "Done with the batch: 527\n",
      "Done with the batch: 528\n",
      "Done with the batch: 529\n",
      "Done with the batch: 530\n",
      "Done with the batch: 531\n",
      "Done with the batch: 532\n",
      "Done with the batch: 533\n",
      "Done with the batch: 534\n",
      "Done with the batch: 535\n",
      "Done with the batch: 536\n",
      "Done with the batch: 537\n",
      "Done with the batch: 538\n",
      "Done with the batch: 539\n",
      "Done with the batch: 540\n",
      "Done with the batch: 541\n",
      "Done with the batch: 542\n",
      "Done with the batch: 543\n",
      "Done with the batch: 544\n",
      "Done with the batch: 545\n",
      "Done with the batch: 546\n",
      "Done with the batch: 547\n",
      "Done with the batch: 548\n",
      "Done with the batch: 549\n",
      "Done with the batch: 550\n",
      "Done with the batch: 551\n",
      "Done with the batch: 552\n",
      "Done with the batch: 553\n",
      "Done with the batch: 554\n",
      "Done with the batch: 555\n",
      "Done with the batch: 556\n",
      "Done with the batch: 557\n",
      "Done with the batch: 558\n",
      "Done with the batch: 559\n",
      "Done with the batch: 560\n",
      "Done with the batch: 561\n",
      "Done with the batch: 562\n",
      "Done with the batch: 563\n",
      "Done with the batch: 564\n",
      "Done with the batch: 565\n",
      "Done with the batch: 566\n",
      "Done with the batch: 567\n",
      "Done with the batch: 568\n",
      "Done with the batch: 569\n",
      "Done with the batch: 570\n",
      "Done with the batch: 571\n",
      "Done with the batch: 572\n",
      "Done with the batch: 573\n",
      "Done with the batch: 574\n",
      "Done with the batch: 575\n",
      "Done with the batch: 576\n",
      "Done with the batch: 577\n",
      "Done with the batch: 578\n",
      "Done with the batch: 579\n",
      "Done with the batch: 580\n",
      "Done with the batch: 581\n",
      "Done with the batch: 582\n",
      "Done with the batch: 583\n",
      "Done with the batch: 584\n",
      "Done with the batch: 585\n",
      "Done with the batch: 586\n",
      "Done with the batch: 587\n",
      "Done with the batch: 588\n",
      "Done with the batch: 589\n",
      "Done with the batch: 590\n",
      "Done with the batch: 591\n",
      "Done with the batch: 592\n",
      "Done with the batch: 593\n",
      "Done with the batch: 594\n",
      "Done with the batch: 595\n",
      "Done with the batch: 596\n",
      "Done with the batch: 597\n",
      "Done with the batch: 598\n",
      "Done with the batch: 599\n",
      "Done with the batch: 600\n",
      "Done with the batch: 601\n",
      "Done with the batch: 602\n",
      "Done with the batch: 603\n",
      "Done with the batch: 604\n",
      "Done with the batch: 605\n",
      "Done with the batch: 606\n",
      "Done with the batch: 607\n",
      "Done with the batch: 608\n",
      "Done with the batch: 609\n",
      "Done with the batch: 610\n",
      "Done with the batch: 611\n",
      "Done with the batch: 612\n",
      "Done with the batch: 613\n",
      "Done with the batch: 614\n",
      "Done with the batch: 615\n",
      "Done with the batch: 616\n",
      "Done with the batch: 617\n",
      "Done with the batch: 618\n",
      "Done with the batch: 619\n",
      "Done with the batch: 620\n",
      "Done with the batch: 621\n",
      "Done with the batch: 622\n",
      "Done with the batch: 623\n",
      "Done with the batch: 624\n",
      "Done with the batch: 625\n",
      "Done with the batch: 626\n",
      "Done with the batch: 627\n",
      "Done with the batch: 628\n",
      "Done with the batch: 629\n",
      "Done with the batch: 630\n",
      "Done with the batch: 631\n",
      "Done with the batch: 632\n",
      "Done with the batch: 633\n",
      "Done with the batch: 634\n",
      "Done with the batch: 635\n",
      "Done with the batch: 636\n",
      "Done with the batch: 637\n",
      "Done with the batch: 638\n",
      "Done with the batch: 639\n",
      "Done with the batch: 640\n",
      "Done with the batch: 641\n",
      "Done with the batch: 642\n",
      "Done with the batch: 643\n",
      "Done with the batch: 644\n",
      "Done with the batch: 645\n",
      "Done with the batch: 646\n",
      "Done with the batch: 647\n",
      "Done with the batch: 648\n",
      "Done with the batch: 649\n",
      "Done with the batch: 650\n",
      "Done with the batch: 651\n",
      "Done with the batch: 652\n",
      "Done with the batch: 653\n",
      "Done with the batch: 654\n",
      "Done with the batch: 655\n",
      "Done with the batch: 656\n",
      "Done with the batch: 657\n",
      "Done with the batch: 658\n",
      "Done with the batch: 659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 660\n",
      "Done with the batch: 661\n",
      "Done with the batch: 662\n",
      "Done with the batch: 663\n",
      "Done with the batch: 664\n",
      "Done with the batch: 665\n",
      "Done with the batch: 666\n",
      "Done with the batch: 667\n",
      "Done with the batch: 668\n",
      "Done with the batch: 669\n",
      "Done with the batch: 670\n",
      "Done with the batch: 671\n",
      "Done with the batch: 672\n",
      "Done with the batch: 673\n",
      "Done with the batch: 674\n",
      "Done with the batch: 675\n",
      "Done with the batch: 676\n",
      "Done with the batch: 677\n",
      "Done with the batch: 678\n",
      "Done with the batch: 679\n",
      "Done with the batch: 680\n",
      "Done with the batch: 681\n",
      "Done with the batch: 682\n",
      "Done with the batch: 683\n",
      "Done with the batch: 684\n",
      "Done with the batch: 685\n",
      "Done with the batch: 686\n",
      "Done with the batch: 687\n",
      "Done with the batch: 688\n",
      "Done with the batch: 689\n",
      "Done with the batch: 690\n",
      "Done with the batch: 691\n",
      "Done with the batch: 692\n",
      "Done with the batch: 693\n",
      "Done with the batch: 694\n",
      "Done with the batch: 695\n",
      "Done with the batch: 696\n",
      "Done with the batch: 697\n",
      "Done with the batch: 698\n",
      "Done with the batch: 699\n",
      "Done with the batch: 700\n",
      "Done with the batch: 701\n",
      "Done with the batch: 702\n",
      "Done with the batch: 703\n",
      "Done with the batch: 704\n",
      "Done with the batch: 705\n",
      "Done with the batch: 706\n",
      "Done with the batch: 707\n",
      "Done with the batch: 708\n",
      "Done with the batch: 709\n",
      "Done with the batch: 710\n",
      "Done with the batch: 711\n",
      "Done with the batch: 712\n",
      "Done with the batch: 713\n",
      "Done with the batch: 714\n",
      "Done with the batch: 715\n",
      "Done with the batch: 716\n",
      "Done with the batch: 717\n",
      "Done with the batch: 718\n",
      "Done with the batch: 719\n",
      "Done with the batch: 720\n",
      "Done with the batch: 721\n",
      "Done with the batch: 722\n",
      "Done with the batch: 723\n",
      "Done with the batch: 724\n",
      "Done with the batch: 725\n",
      "Done with the batch: 726\n",
      "Done with the batch: 727\n",
      "Done with the batch: 728\n",
      "Done with the batch: 729\n",
      "Done with the batch: 730\n",
      "Done with the batch: 731\n",
      "Done with the batch: 732\n",
      "Done with the batch: 733\n",
      "Done with the batch: 734\n",
      "Done with the batch: 735\n",
      "Done with the batch: 736\n",
      "Done with the batch: 737\n",
      "Done with the batch: 738\n",
      "Done with the batch: 739\n",
      "Done with the batch: 740\n",
      "Done with the batch: 741\n",
      "Done with the batch: 742\n",
      "Done with the batch: 743\n",
      "Done with the batch: 744\n",
      "Done with the batch: 745\n",
      "Done with the batch: 746\n",
      "Done with the batch: 747\n",
      "Done with the batch: 748\n",
      "Done with the batch: 749\n",
      "Done with the batch: 750\n",
      "Done with the batch: 751\n",
      "Done with the batch: 752\n",
      "Done with the batch: 753\n",
      "Done with the batch: 754\n",
      "Done with the batch: 755\n",
      "Done with the batch: 756\n",
      "Done with the batch: 757\n",
      "Done with the batch: 758\n",
      "Done with the batch: 759\n",
      "Done with the batch: 760\n",
      "Done with the batch: 761\n",
      "Done with the batch: 762\n",
      "Done with the batch: 763\n",
      "Done with the batch: 764\n",
      "Done with the batch: 765\n",
      "Done with the batch: 766\n",
      "Done with the batch: 767\n",
      "Done with the batch: 768\n",
      "Done with the batch: 769\n",
      "Done with the batch: 770\n",
      "Done with the batch: 771\n",
      "Done with the batch: 772\n",
      "Done with the batch: 773\n",
      "Done with the batch: 774\n",
      "Done with the batch: 775\n",
      "Done with the batch: 776\n",
      "Done with the batch: 777\n",
      "Done with the batch: 778\n",
      "Done with the batch: 779\n",
      "Done with the batch: 780\n",
      "Done with the batch: 781\n",
      "Done with the batch: 782\n",
      "Done with the batch: 783\n",
      "Done with the batch: 784\n",
      "Done with the batch: 785\n",
      "Done with the batch: 786\n",
      "Done with the batch: 787\n",
      "Done with the batch: 788\n",
      "Done with the batch: 789\n",
      "Done with the batch: 790\n",
      "Done with the batch: 791\n",
      "Done with the batch: 792\n",
      "Done with the batch: 793\n",
      "Done with the batch: 794\n",
      "Done with the batch: 795\n",
      "Done with the batch: 796\n",
      "Done with the batch: 797\n",
      "Done with the batch: 798\n",
      "Done with the batch: 799\n",
      "Done with the batch: 800\n",
      "Done with the batch: 801\n",
      "Done with the batch: 802\n",
      "Done with the batch: 803\n",
      "Done with the batch: 804\n",
      "Done with the batch: 805\n",
      "Done with the batch: 806\n",
      "Done with the batch: 807\n",
      "Done with the batch: 808\n",
      "Done with the batch: 809\n",
      "Done with the batch: 810\n",
      "Done with the batch: 811\n",
      "Done with the batch: 812\n",
      "Done with the batch: 813\n",
      "Done with the batch: 814\n",
      "Done with the batch: 815\n",
      "Done with the batch: 816\n",
      "Done with the batch: 817\n",
      "Done with the batch: 818\n",
      "Done with the batch: 819\n",
      "Done with the batch: 820\n",
      "Done with the batch: 821\n",
      "Done with the batch: 822\n",
      "Done with the batch: 823\n",
      "Done with the batch: 824\n",
      "Done with the batch: 825\n",
      "Done with the batch: 826\n",
      "Done with the batch: 827\n",
      "Done with the batch: 828\n",
      "Done with the batch: 829\n",
      "Done with the batch: 830\n",
      "Done with the batch: 831\n",
      "Done with the batch: 832\n",
      "Done with the batch: 833\n",
      "Done with the batch: 834\n",
      "Done with the batch: 835\n",
      "Done with the batch: 836\n",
      "Done with the batch: 837\n",
      "Done with the batch: 838\n",
      "Done with the batch: 839\n",
      "Done with the batch: 840\n",
      "Done with the batch: 841\n",
      "Done with the batch: 842\n",
      "Done with the batch: 843\n",
      "Done with the batch: 844\n",
      "Done with the batch: 845\n",
      "Done with the batch: 846\n",
      "Done with the batch: 847\n",
      "Done with the batch: 848\n",
      "Done with the batch: 849\n",
      "Done with the batch: 850\n",
      "Done with the batch: 851\n",
      "Done with the batch: 852\n",
      "Done with the batch: 853\n",
      "Done with the batch: 854\n",
      "Done with the batch: 855\n",
      "Done with the batch: 856\n",
      "Done with the batch: 857\n",
      "Done with the batch: 858\n",
      "Done with the batch: 859\n",
      "Done with the batch: 860\n",
      "Done with the batch: 861\n",
      "Done with the batch: 862\n",
      "Done with the batch: 863\n",
      "Done with the batch: 864\n",
      "Done with the batch: 865\n",
      "Done with the batch: 866\n",
      "Done with the batch: 867\n",
      "Done with the batch: 868\n",
      "Done with the batch: 869\n",
      "Done with the batch: 870\n",
      "Done with the batch: 871\n",
      "Done with the batch: 872\n",
      "Done with the batch: 873\n",
      "Done with the batch: 874\n",
      "Done with the batch: 875\n",
      "Done with the batch: 876\n",
      "Done with the batch: 877\n",
      "Done with the batch: 878\n",
      "Done with the batch: 879\n",
      "Done with the batch: 880\n",
      "Done with the batch: 881\n",
      "Done with the batch: 882\n",
      "Done with the batch: 883\n",
      "Done with the batch: 884\n",
      "Done with the batch: 885\n",
      "Done with the batch: 886\n",
      "Done with the batch: 887\n",
      "Done with the batch: 888\n",
      "Done with the batch: 889\n",
      "Done with the batch: 890\n",
      "Done with the batch: 891\n",
      "Done with the batch: 892\n",
      "Done with the batch: 893\n",
      "Done with the batch: 894\n",
      "Done with the batch: 895\n",
      "Done with the batch: 896\n",
      "Done with the batch: 897\n",
      "Done with the batch: 898\n",
      "Done with the batch: 899\n",
      "Done with the batch: 900\n",
      "Done with the batch: 901\n",
      "Done with the batch: 902\n",
      "Done with the batch: 903\n",
      "Done with the batch: 904\n",
      "Done with the batch: 905\n",
      "Done with the batch: 906\n",
      "Done with the batch: 907\n",
      "Done with the batch: 908\n",
      "Done with the batch: 909\n",
      "Done with the batch: 910\n",
      "Done with the batch: 911\n",
      "Done with the batch: 912\n",
      "Done with the batch: 913\n",
      "Done with the batch: 914\n",
      "Done with the batch: 915\n",
      "Done with the batch: 916\n",
      "Done with the batch: 917\n",
      "Done with the batch: 918\n",
      "Done with the batch: 919\n",
      "Done with the batch: 920\n",
      "Done with the batch: 921\n",
      "Done with the batch: 922\n",
      "Done with the batch: 923\n",
      "Done with the batch: 924\n",
      "Done with the batch: 925\n",
      "Done with the batch: 926\n",
      "Done with the batch: 927\n",
      "Done with the batch: 928\n",
      "Done with the batch: 929\n",
      "Done with the batch: 930\n",
      "Done with the batch: 931\n",
      "Done with the batch: 932\n",
      "Done with the batch: 933\n",
      "Done with the batch: 934\n",
      "Done with the batch: 935\n",
      "Done with the batch: 936\n",
      "Done with the batch: 937\n",
      "Done with the batch: 938\n",
      "Done with the batch: 939\n",
      "Done with the batch: 940\n",
      "Done with the batch: 941\n",
      "Done with the batch: 942\n",
      "Done with the batch: 943\n",
      "Done with the batch: 944\n",
      "Done with the batch: 945\n",
      "Done with the batch: 946\n",
      "Done with the batch: 947\n",
      "Done with the batch: 948\n",
      "Done with the batch: 949\n",
      "Done with the batch: 950\n",
      "Done with the batch: 951\n",
      "Done with the batch: 952\n",
      "Done with the batch: 953\n",
      "Done with the batch: 954\n",
      "Done with the batch: 955\n",
      "Done with the batch: 956\n",
      "Done with the batch: 957\n",
      "Done with the batch: 958\n",
      "Done with the batch: 959\n",
      "Done with the batch: 960\n",
      "Done with the batch: 961\n",
      "Done with the batch: 962\n",
      "Done with the batch: 963\n",
      "Done with the batch: 964\n",
      "Done with the batch: 965\n",
      "Done with the batch: 966\n",
      "Done with the batch: 967\n",
      "Done with the batch: 968\n",
      "Done with the batch: 969\n",
      "Done with the batch: 970\n",
      "Done with the batch: 971\n",
      "Done with the batch: 972\n",
      "Done with the batch: 973\n",
      "Done with the batch: 974\n",
      "Done with the batch: 975\n",
      "Done with the batch: 976\n",
      "Done with the batch: 977\n",
      "Done with the batch: 978\n",
      "Done with the batch: 979\n",
      "Done with the batch: 980\n",
      "Done with the batch: 981\n",
      "Done with the batch: 982\n",
      "Done with the batch: 983\n",
      "Done with the batch: 984\n",
      "Done with the batch: 985\n",
      "Done with the batch: 986\n",
      "Done with the batch: 987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 988\n",
      "Done with the batch: 989\n",
      "Done with the batch: 990\n",
      "Done with the batch: 991\n",
      "Done with the batch: 992\n",
      "Done with the batch: 993\n",
      "Done with the batch: 994\n",
      "Done with the batch: 995\n",
      "Done with the batch: 996\n",
      "Done with the batch: 997\n",
      "Done with the batch: 998\n",
      "Done with the batch: 999\n",
      "Done with the batch: 1000\n",
      "Done with the batch: 1001\n",
      "Done with the batch: 1002\n",
      "Done with the batch: 1003\n",
      "Done with the batch: 1004\n",
      "Done with the batch: 1005\n",
      "Done with the batch: 1006\n",
      "Done with the batch: 1007\n",
      "Done with the batch: 1008\n",
      "Done with the batch: 1009\n",
      "Done with the batch: 1010\n",
      "Done with the batch: 1011\n",
      "Done with the batch: 1012\n",
      "Done with the batch: 1013\n",
      "Done with the batch: 1014\n",
      "Done with the batch: 1015\n",
      "Done with the batch: 1016\n",
      "Done with the batch: 1017\n",
      "Done with the batch: 1018\n",
      "Done with the batch: 1019\n",
      "Done with the batch: 1020\n",
      "Done with the batch: 1021\n",
      "Done with the batch: 1022\n",
      "Done with the batch: 1023\n",
      "Done with the batch: 1024\n",
      "Done with the batch: 1025\n",
      "Done with the batch: 1026\n",
      "Done with the batch: 1027\n",
      "Done with the batch: 1028\n",
      "Done with the batch: 1029\n",
      "Done with the batch: 1030\n",
      "Done with the batch: 1031\n",
      "Done with the batch: 1032\n",
      "Done with the batch: 1033\n",
      "Done with the batch: 1034\n",
      "Done with the batch: 1035\n",
      "Done with the batch: 1036\n",
      "Done with the batch: 1037\n",
      "Done with the batch: 1038\n",
      "Done with the batch: 1039\n",
      "Done with the batch: 1040\n",
      "Done with the batch: 1041\n",
      "Done with the batch: 1042\n",
      "Done with the batch: 1043\n",
      "Done with the batch: 1044\n",
      "Done with the batch: 1045\n",
      "Done with the batch: 1046\n",
      "Done with the batch: 1047\n",
      "Done with the batch: 1048\n",
      "Done with the batch: 1049\n",
      "Done with the batch: 1050\n",
      "Done with the batch: 1051\n",
      "Done with the batch: 1052\n",
      "Done with the batch: 1053\n",
      "Done with the batch: 1054\n",
      "Done with the batch: 1055\n",
      "Done with the batch: 1056\n",
      "Done with the batch: 1057\n",
      "Done with the batch: 1058\n",
      "Done with the batch: 1059\n",
      "Done with the batch: 1060\n",
      "Done with the batch: 1061\n",
      "Done with the batch: 1062\n",
      "Done with the batch: 1063\n",
      "Done with the batch: 1064\n",
      "Done with the batch: 1065\n",
      "Done with the batch: 1066\n",
      "Done with the batch: 1067\n",
      "Done with the batch: 1068\n",
      "Done with the batch: 1069\n",
      "Done with the batch: 1070\n",
      "Done with the batch: 1071\n",
      "Done with the batch: 1072\n",
      "Done with the batch: 1073\n",
      "Done with the batch: 1074\n",
      "Done with the batch: 1075\n",
      "Done with the batch: 1076\n",
      "Done with the batch: 1077\n",
      "Done with the batch: 1078\n",
      "Done with the batch: 1079\n",
      "Done with the batch: 1080\n",
      "Done with the batch: 1081\n",
      "Done with the batch: 1082\n",
      "Done with the batch: 1083\n",
      "Done with the batch: 1084\n",
      "Done with the batch: 1085\n",
      "Done with the batch: 1086\n",
      "Done with the batch: 1087\n",
      "Done with the batch: 1088\n",
      "Done with the batch: 1089\n",
      "Done with the batch: 1090\n",
      "Done with the batch: 1091\n",
      "Done with the batch: 1092\n",
      "Done with the batch: 1093\n",
      "Done with the batch: 1094\n",
      "Done with the batch: 1095\n",
      "Done with the batch: 1096\n",
      "Done with the batch: 1097\n",
      "Done with the batch: 1098\n",
      "Done with the batch: 1099\n",
      "Done with the batch: 1100\n",
      "Done with the batch: 1101\n",
      "Done with the batch: 1102\n",
      "Done with the batch: 1103\n",
      "Done with the batch: 1104\n",
      "Done with the batch: 1105\n",
      "Done with the batch: 1106\n",
      "Done with the batch: 1107\n",
      "Done with the batch: 1108\n",
      "Done with the batch: 1109\n",
      "Done with the batch: 1110\n",
      "Done with the batch: 1111\n",
      "Done with the batch: 1112\n",
      "Done with the batch: 1113\n",
      "Done with the batch: 1114\n",
      "Done with the batch: 1115\n",
      "Done with the batch: 1116\n",
      "Done with the batch: 1117\n",
      "Done with the batch: 1118\n",
      "Done with the batch: 1119\n",
      "Done with the batch: 1120\n",
      "Done with the batch: 1121\n",
      "Done with the batch: 1122\n",
      "Done with the batch: 1123\n",
      "Done with the batch: 1124\n",
      "Done with the batch: 1125\n",
      "Done with the batch: 1126\n",
      "Done with the batch: 1127\n",
      "Done with the batch: 1128\n",
      "Done with the batch: 1129\n",
      "Done with the batch: 1130\n",
      "Done with the batch: 1131\n",
      "Done with the batch: 1132\n",
      "Done with the batch: 1133\n",
      "Done with the batch: 1134\n",
      "Done with the batch: 1135\n",
      "Done with the batch: 1136\n",
      "Done with the batch: 1137\n",
      "Done with the batch: 1138\n",
      "Done with the batch: 1139\n",
      "Done with the batch: 1140\n",
      "Done with the batch: 1141\n",
      "Done with the batch: 1142\n",
      "Done with the batch: 1143\n",
      "Done with the batch: 1144\n",
      "Done with the batch: 1145\n",
      "Done with the batch: 1146\n",
      "Done with the batch: 1147\n",
      "Done with the batch: 1148\n",
      "Done with the batch: 1149\n",
      "Done with the batch: 1150\n",
      "Done with the batch: 1151\n",
      "Done with the batch: 1152\n",
      "Done with the batch: 1153\n",
      "Done with the batch: 1154\n",
      "Done with the batch: 1155\n",
      "Done with the batch: 1156\n",
      "Done with the batch: 1157\n",
      "Done with the batch: 1158\n",
      "Done with the batch: 1159\n",
      "Done with the batch: 1160\n",
      "Done with the batch: 1161\n",
      "Done with the batch: 1162\n",
      "Done with the batch: 1163\n",
      "Done with the batch: 1164\n",
      "Done with the batch: 1165\n",
      "Done with the batch: 1166\n",
      "Done with the batch: 1167\n",
      "Done with the batch: 1168\n",
      "Done with the batch: 1169\n",
      "Done with the batch: 1170\n",
      "Done with the batch: 1171\n",
      "Done with the batch: 1172\n",
      "Done with the batch: 1173\n",
      "Done with the batch: 1174\n",
      "Done with the batch: 1175\n",
      "Done with the batch: 1176\n",
      "Done with the batch: 1177\n",
      "Done with the batch: 1178\n",
      "Done with the batch: 1179\n",
      "Done with the batch: 1180\n",
      "Done with the batch: 1181\n",
      "Done with the batch: 1182\n",
      "Done with the batch: 1183\n",
      "Done with the batch: 1184\n",
      "Done with the batch: 1185\n",
      "Done with the batch: 1186\n",
      "Done with the batch: 1187\n",
      "Done with the batch: 1188\n",
      "Done with the batch: 1189\n",
      "Done with the batch: 1190\n",
      "Done with the batch: 1191\n",
      "Done with the batch: 1192\n",
      "Done with the batch: 1193\n",
      "Done with the batch: 1194\n",
      "Done with the batch: 1195\n",
      "Done with the batch: 1196\n",
      "Done with the batch: 1197\n",
      "Done with the batch: 1198\n",
      "Done with the batch: 1199\n",
      "Done with the batch: 1200\n",
      "Done with the batch: 1201\n",
      "Done with the batch: 1202\n",
      "Done with the batch: 1203\n",
      "Done with the batch: 1204\n",
      "Done with the batch: 1205\n",
      "Done with the batch: 1206\n",
      "Done with the batch: 1207\n",
      "Done with the batch: 1208\n",
      "Done with the batch: 1209\n",
      "Done with the batch: 1210\n",
      "Done with the batch: 1211\n",
      "Done with the batch: 1212\n",
      "Done with the batch: 1213\n",
      "Done with the batch: 1214\n",
      "Done with the batch: 1215\n",
      "Done with the batch: 1216\n",
      "Done with the batch: 1217\n",
      "Done with the batch: 1218\n",
      "Done with the batch: 1219\n",
      "Done with the batch: 1220\n",
      "Done with the batch: 1221\n",
      "Done with the batch: 1222\n",
      "Done with the batch: 1223\n",
      "Done with the batch: 1224\n",
      "Done with the batch: 1225\n",
      "Done with the batch: 1226\n",
      "Done with the batch: 1227\n",
      "Done with the batch: 1228\n",
      "Done with the batch: 1229\n",
      "Done with the batch: 1230\n",
      "Done with the batch: 1231\n",
      "Done with the batch: 1232\n",
      "Done with the batch: 1233\n",
      "Done with the batch: 1234\n",
      "Done with the batch: 1235\n",
      "Done with the batch: 1236\n",
      "Done with the batch: 1237\n",
      "Done with the batch: 1238\n",
      "Done with the batch: 1239\n",
      "Done with the batch: 1240\n",
      "Done with the batch: 1241\n",
      "Done with the batch: 1242\n",
      "Done with the batch: 1243\n",
      "Done with the batch: 1244\n",
      "Done with the batch: 1245\n",
      "Done with the batch: 1246\n",
      "Done with the batch: 1247\n",
      "Done with the batch: 1248\n",
      "Done with the batch: 1249\n",
      "Done with the batch: 1250\n",
      "Done with the batch: 1251\n",
      "Done with the batch: 1252\n",
      "Done with the batch: 1253\n",
      "Done with the batch: 1254\n",
      "Done with the batch: 1255\n",
      "Done with the batch: 1256\n",
      "Done with the batch: 1257\n",
      "Done with the batch: 1258\n",
      "Done with the batch: 1259\n",
      "Done with the batch: 1260\n",
      "Done with the batch: 1261\n",
      "Done with the batch: 1262\n",
      "Done with the batch: 1263\n",
      "Done with the batch: 1264\n",
      "Done with the batch: 1265\n",
      "Done with the batch: 1266\n",
      "Done with the batch: 1267\n",
      "Done with the batch: 1268\n",
      "Done with the batch: 1269\n",
      "Done with the batch: 1270\n",
      "Done with the batch: 1271\n",
      "Done with the batch: 1272\n",
      "Done with the batch: 1273\n",
      "Done with the batch: 1274\n",
      "Done with the batch: 1275\n",
      "Done with the batch: 1276\n",
      "Done with the batch: 1277\n",
      "Done with the batch: 1278\n",
      "Done with the batch: 1279\n",
      "Done with the batch: 1280\n",
      "Done with the batch: 1281\n",
      "Done with the batch: 1282\n",
      "Done with the batch: 1283\n",
      "Done with the batch: 1284\n",
      "Done with the batch: 1285\n",
      "Done with the batch: 1286\n",
      "Done with the batch: 1287\n",
      "Done with the batch: 1288\n",
      "Done with the batch: 1289\n",
      "Done with the batch: 1290\n",
      "Done with the batch: 1291\n",
      "Done with the batch: 1292\n",
      "Done with the batch: 1293\n",
      "Done with the batch: 1294\n",
      "Done with the batch: 1295\n",
      "Done with the batch: 1296\n",
      "Done with the batch: 1297\n",
      "Done with the batch: 1298\n",
      "Done with the batch: 1299\n",
      "Done with the batch: 1300\n",
      "Done with the batch: 1301\n",
      "Done with the batch: 1302\n",
      "Done with the batch: 1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 1304\n",
      "Done with the batch: 1305\n",
      "Done with the batch: 1306\n",
      "Done with the batch: 1307\n",
      "Done with the batch: 1308\n",
      "Done with the batch: 1309\n",
      "Done with the batch: 1310\n",
      "Done with the batch: 1311\n",
      "Done with the batch: 1312\n",
      "Done with the batch: 1313\n",
      "Done with the batch: 1314\n",
      "Done with the batch: 1315\n",
      "Done with the batch: 1316\n",
      "Done with the batch: 1317\n",
      "Done with the batch: 1318\n",
      "Done with the batch: 1319\n",
      "Done with the batch: 1320\n",
      "Done with the batch: 1321\n",
      "Done with the batch: 1322\n",
      "Done with the batch: 1323\n",
      "Done with the batch: 1324\n",
      "Done with the batch: 1325\n",
      "Done with the batch: 1326\n",
      "Done with the batch: 1327\n",
      "Done with the batch: 1328\n",
      "Done with the batch: 1329\n",
      "Done with the batch: 1330\n",
      "Done with the batch: 1331\n",
      "Done with the batch: 1332\n",
      "Done with the batch: 1333\n",
      "Done with the batch: 1334\n",
      "Done with the batch: 1335\n",
      "Done with the batch: 1336\n",
      "Done with the batch: 1337\n",
      "Done with the batch: 1338\n",
      "Done with the batch: 1339\n",
      "Done with the batch: 1340\n",
      "Done with the batch: 1341\n",
      "Done with the batch: 1342\n",
      "Done with the batch: 1343\n",
      "Done with the batch: 1344\n",
      "Done with the batch: 1345\n",
      "Done with the batch: 1346\n",
      "Done with the batch: 1347\n",
      "Done with the batch: 1348\n",
      "Done with the batch: 1349\n",
      "Done with the batch: 1350\n",
      "Done with the batch: 1351\n",
      "Done with the batch: 1352\n",
      "Done with the batch: 1353\n",
      "Done with the batch: 1354\n",
      "Done with the batch: 1355\n",
      "Done with the batch: 1356\n",
      "Done with the batch: 1357\n",
      "Done with the batch: 1358\n",
      "Done with the batch: 1359\n",
      "Done with the batch: 1360\n",
      "Done with the batch: 1361\n",
      "Done with the batch: 1362\n",
      "Done with the batch: 1363\n",
      "Done with the batch: 1364\n",
      "Done with the batch: 1365\n",
      "Done with the batch: 1366\n",
      "Done with the batch: 1367\n",
      "Done with the batch: 1368\n",
      "Done with the batch: 1369\n",
      "Done with the batch: 1370\n",
      "Done with the batch: 1371\n",
      "Done with the batch: 1372\n",
      "Done with the batch: 1373\n",
      "Done with the batch: 1374\n",
      "Done with the batch: 1375\n",
      "Done with the batch: 1376\n",
      "Done with the batch: 1377\n",
      "Done with the batch: 1378\n",
      "Done with the batch: 1379\n",
      "Done with the batch: 1380\n",
      "Done with the batch: 1381\n",
      "Done with the batch: 1382\n",
      "Done with the batch: 1383\n",
      "Done with the batch: 1384\n",
      "Done with the batch: 1385\n",
      "Done with the batch: 1386\n",
      "Done with the batch: 1387\n",
      "Done with the batch: 1388\n",
      "Done with the batch: 1389\n",
      "Done with the batch: 1390\n",
      "Done with the batch: 1391\n",
      "Done with the batch: 1392\n",
      "Done with the batch: 1393\n",
      "Done with the batch: 1394\n",
      "Done with the batch: 1395\n",
      "Done with the batch: 1396\n",
      "Done with the batch: 1397\n",
      "Done with the batch: 1398\n",
      "Done with the batch: 1399\n",
      "Done with the batch: 1400\n",
      "Done with the batch: 1401\n",
      "Done with the batch: 1402\n",
      "Done with the batch: 1403\n",
      "Done with the batch: 1404\n",
      "Done with the batch: 1405\n",
      "Done with the batch: 1406\n",
      "Done with the batch: 1407\n",
      "Done with the batch: 1408\n",
      "Done with the batch: 1409\n",
      "Done with the batch: 1410\n",
      "Done with the batch: 1411\n",
      "Done with the batch: 1412\n",
      "Done with the batch: 1413\n",
      "Done with the batch: 1414\n",
      "Done with the batch: 1415\n",
      "Done with the batch: 1416\n",
      "Done with the batch: 1417\n",
      "Done with the batch: 1418\n",
      "Done with the batch: 1419\n",
      "Done with the batch: 1420\n",
      "Done with the batch: 1421\n",
      "Done with the batch: 1422\n",
      "Done with the batch: 1423\n",
      "Done with the batch: 1424\n",
      "Done with the batch: 1425\n",
      "Done with the batch: 1426\n",
      "Done with the batch: 1427\n",
      "Done with the batch: 1428\n",
      "Done with the batch: 1429\n",
      "Done with the batch: 1430\n",
      "Done with the batch: 1431\n",
      "Done with the batch: 1432\n",
      "Done with the batch: 1433\n",
      "Done with the batch: 1434\n",
      "Done with the batch: 1435\n",
      "Done with the batch: 1436\n",
      "Done with the batch: 1437\n",
      "Done with the batch: 1438\n",
      "Done with the batch: 1439\n",
      "Done with the batch: 1440\n",
      "Done with the batch: 1441\n",
      "Done with the batch: 1442\n",
      "Done with the batch: 1443\n",
      "Done with the batch: 1444\n",
      "Done with the batch: 1445\n",
      "Done with the batch: 1446\n",
      "Done with the batch: 1447\n",
      "Done with the batch: 1448\n",
      "Done with the batch: 1449\n",
      "Done with the batch: 1450\n",
      "Done with the batch: 1451\n",
      "Done with the batch: 1452\n",
      "Done with the batch: 1453\n",
      "Done with the batch: 1454\n",
      "Done with the batch: 1455\n",
      "Done with the batch: 1456\n",
      "Done with the batch: 1457\n",
      "Done with the batch: 1458\n",
      "Done with the batch: 1459\n",
      "Done with the batch: 1460\n",
      "Done with the batch: 1461\n",
      "Done with the batch: 1462\n",
      "Done with the batch: 1463\n",
      "Done with the batch: 1464\n",
      "Done with the batch: 1465\n",
      "Done with the batch: 1466\n",
      "Done with the batch: 1467\n",
      "Done with the batch: 1468\n",
      "Done with the batch: 1469\n",
      "Done with the batch: 1470\n",
      "Done with the batch: 1471\n",
      "Done with the batch: 1472\n",
      "Done with the batch: 1473\n",
      "Done with the batch: 1474\n",
      "Done with the batch: 1475\n",
      "Done with the batch: 1476\n",
      "Done with the batch: 1477\n",
      "Done with the batch: 1478\n",
      "Done with the batch: 1479\n",
      "Done with the batch: 1480\n",
      "Done with the batch: 1481\n",
      "Done with the batch: 1482\n",
      "Done with the batch: 1483\n",
      "Done with the batch: 1484\n",
      "Done with the batch: 1485\n",
      "Done with the batch: 1486\n",
      "Done with the batch: 1487\n",
      "Done with the batch: 1488\n",
      "Done with the batch: 1489\n",
      "Done with the batch: 1490\n",
      "Done with the batch: 1491\n",
      "Done with the batch: 1492\n",
      "Done with the batch: 1493\n",
      "Done with the batch: 1494\n",
      "Done with the batch: 1495\n",
      "Done with the batch: 1496\n",
      "Done with the batch: 1497\n",
      "Done with the batch: 1498\n",
      "Done with the batch: 1499\n",
      "Done with the batch: 1500\n",
      "Done with the batch: 1501\n",
      "Done with the batch: 1502\n",
      "Done with the batch: 1503\n",
      "Done with the batch: 1504\n",
      "Done with the batch: 1505\n",
      "Done with the batch: 1506\n",
      "Done with the batch: 1507\n",
      "Done with the batch: 1508\n",
      "Done with the batch: 1509\n",
      "Done with the batch: 1510\n",
      "Done with the batch: 1511\n",
      "Done with the batch: 1512\n",
      "Done with the batch: 1513\n",
      "Done with the batch: 1514\n",
      "Done with the batch: 1515\n",
      "Done with the batch: 1516\n",
      "Done with the batch: 1517\n",
      "Done with the batch: 1518\n",
      "Done with the batch: 1519\n",
      "Done with the batch: 1520\n",
      "Done with the batch: 1521\n",
      "Done with the batch: 1522\n",
      "Done with the batch: 1523\n",
      "Done with the batch: 1524\n",
      "Done with the batch: 1525\n",
      "Done with the batch: 1526\n",
      "Done with the batch: 1527\n",
      "Done with the batch: 1528\n",
      "Done with the batch: 1529\n",
      "Done with the batch: 1530\n",
      "Done with the batch: 1531\n",
      "Done with the batch: 1532\n",
      "Done with the batch: 1533\n",
      "Done with the batch: 1534\n",
      "Done with the batch: 1535\n",
      "Done with the batch: 1536\n",
      "Done with the batch: 1537\n",
      "Done with the batch: 1538\n",
      "Done with the batch: 1539\n",
      "Done with the batch: 1540\n",
      "Done with the batch: 1541\n",
      "Done with the batch: 1542\n",
      "Done with the batch: 1543\n",
      "Done with the batch: 1544\n",
      "Done with the batch: 1545\n",
      "Done with the batch: 1546\n",
      "Done with the batch: 1547\n",
      "Done with the batch: 1548\n",
      "Done with the batch: 1549\n",
      "Done with the batch: 1550\n",
      "Done with the batch: 1551\n",
      "Done with the batch: 1552\n",
      "Done with the batch: 1553\n",
      "Done with the batch: 1554\n",
      "Done with the batch: 1555\n",
      "Done with the batch: 1556\n",
      "Done with the batch: 1557\n",
      "Done with the batch: 1558\n",
      "Done with the batch: 1559\n",
      "Done with the batch: 1560\n",
      "Done with the batch: 1561\n",
      "Done with the batch: 1562\n",
      "Done with the batch: 1563\n",
      "Done with the batch: 1564\n",
      "Done with the batch: 1565\n",
      "Done with the batch: 1566\n",
      "Done with the batch: 1567\n",
      "Done with the batch: 1568\n",
      "Done with the batch: 1569\n",
      "Done with the batch: 1570\n",
      "Done with the batch: 1571\n",
      "Done with the batch: 1572\n",
      "Done with the batch: 1573\n",
      "Done with the batch: 1574\n",
      "Done with the batch: 1575\n",
      "Done with the batch: 1576\n",
      "Done with the batch: 1577\n",
      "Done with the batch: 1578\n",
      "Done with the batch: 1579\n",
      "Done with the batch: 1580\n",
      "Done with the batch: 1581\n",
      "Done with the batch: 1582\n",
      "Done with the batch: 1583\n",
      "Done with the batch: 1584\n",
      "Done with the batch: 1585\n",
      "Done with the batch: 1586\n",
      "Done with the batch: 1587\n",
      "Done with the batch: 1588\n",
      "Done with the batch: 1589\n",
      "Done with the batch: 1590\n",
      "Done with the batch: 1591\n",
      "Done with the batch: 1592\n",
      "Done with the batch: 1593\n",
      "Done with the batch: 1594\n",
      "Done with the batch: 1595\n",
      "Done with the batch: 1596\n",
      "Done with the batch: 1597\n",
      "Done with the batch: 1598\n",
      "Done with the batch: 1599\n",
      "Done with the batch: 1600\n",
      "Done with the batch: 1601\n",
      "Done with the batch: 1602\n",
      "Done with the batch: 1603\n",
      "Done with the batch: 1604\n",
      "Done with the batch: 1605\n",
      "Done with the batch: 1606\n",
      "Done with the batch: 1607\n",
      "Done with the batch: 1608\n",
      "Done with the batch: 1609\n",
      "Done with the batch: 1610\n",
      "Done with the batch: 1611\n",
      "Done with the batch: 1612\n",
      "Done with the batch: 1613\n",
      "Done with the batch: 1614\n",
      "Done with the batch: 1615\n",
      "Done with the batch: 1616\n",
      "Done with the batch: 1617\n",
      "(6470, 128) (6470,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"60eb1bf9-d59b-4231-816a-7a77c26d892c\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"60eb1bf9-d59b-4231-816a-7a77c26d892c\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "\n",
    "X_Train=np.empty((0,128))\n",
    "Y_Train=np.empty((0,batch_size))\n",
    "print(X_Train.shape)\n",
    "for i,data in enumerate(trainloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    FCLayer=net.get_first_FC_Layer(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Train=np.append(X_Train,FCLayer,axis=0)\n",
    "    Y_Train=np.append(Y_Train,labels.numpy())\n",
    "print(X_Train.shape,Y_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 128)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "(1618, 128) (1618,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"8210d0eb-0915-4754-9a78-5950c8ddd506\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"8210d0eb-0915-4754-9a78-5950c8ddd506\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "X_Test=np.empty((0,128))\n",
    "Y_Test=np.empty((0,batch_size))\n",
    "print(X_Test.shape)\n",
    "for i,data in enumerate(testloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    FCLayer=net.get_first_FC_Layer(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Test=np.append(X_Test,FCLayer,axis=0)\n",
    "    Y_Test=np.append(Y_Test,labels.numpy())\n",
    "print(X_Test.shape,Y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 18432)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "Done with the batch: 405\n",
      "Done with the batch: 406\n",
      "Done with the batch: 407\n",
      "Done with the batch: 408\n",
      "Done with the batch: 409\n",
      "Done with the batch: 410\n",
      "Done with the batch: 411\n",
      "Done with the batch: 412\n",
      "Done with the batch: 413\n",
      "Done with the batch: 414\n",
      "Done with the batch: 415\n",
      "Done with the batch: 416\n",
      "Done with the batch: 417\n",
      "Done with the batch: 418\n",
      "Done with the batch: 419\n",
      "Done with the batch: 420\n",
      "Done with the batch: 421\n",
      "Done with the batch: 422\n",
      "Done with the batch: 423\n",
      "Done with the batch: 424\n",
      "Done with the batch: 425\n",
      "Done with the batch: 426\n",
      "Done with the batch: 427\n",
      "Done with the batch: 428\n",
      "Done with the batch: 429\n",
      "Done with the batch: 430\n",
      "Done with the batch: 431\n",
      "Done with the batch: 432\n",
      "Done with the batch: 433\n",
      "Done with the batch: 434\n",
      "Done with the batch: 435\n",
      "Done with the batch: 436\n",
      "Done with the batch: 437\n",
      "Done with the batch: 438\n",
      "Done with the batch: 439\n",
      "Done with the batch: 440\n",
      "Done with the batch: 441\n",
      "Done with the batch: 442\n",
      "Done with the batch: 443\n",
      "Done with the batch: 444\n",
      "Done with the batch: 445\n",
      "Done with the batch: 446\n",
      "Done with the batch: 447\n",
      "Done with the batch: 448\n",
      "Done with the batch: 449\n",
      "Done with the batch: 450\n",
      "Done with the batch: 451\n",
      "Done with the batch: 452\n",
      "Done with the batch: 453\n",
      "Done with the batch: 454\n",
      "Done with the batch: 455\n",
      "Done with the batch: 456\n",
      "Done with the batch: 457\n",
      "Done with the batch: 458\n",
      "Done with the batch: 459\n",
      "Done with the batch: 460\n",
      "Done with the batch: 461\n",
      "Done with the batch: 462\n",
      "Done with the batch: 463\n",
      "Done with the batch: 464\n",
      "Done with the batch: 465\n",
      "Done with the batch: 466\n",
      "Done with the batch: 467\n",
      "Done with the batch: 468\n",
      "Done with the batch: 469\n",
      "Done with the batch: 470\n",
      "Done with the batch: 471\n",
      "Done with the batch: 472\n",
      "Done with the batch: 473\n",
      "Done with the batch: 474\n",
      "Done with the batch: 475\n",
      "Done with the batch: 476\n",
      "Done with the batch: 477\n",
      "Done with the batch: 478\n",
      "Done with the batch: 479\n",
      "Done with the batch: 480\n",
      "Done with the batch: 481\n",
      "Done with the batch: 482\n",
      "Done with the batch: 483\n",
      "Done with the batch: 484\n",
      "Done with the batch: 485\n",
      "Done with the batch: 486\n",
      "Done with the batch: 487\n",
      "Done with the batch: 488\n",
      "Done with the batch: 489\n",
      "Done with the batch: 490\n",
      "Done with the batch: 491\n",
      "Done with the batch: 492\n",
      "Done with the batch: 493\n",
      "Done with the batch: 494\n",
      "Done with the batch: 495\n",
      "Done with the batch: 496\n",
      "Done with the batch: 497\n",
      "Done with the batch: 498\n",
      "Done with the batch: 499\n",
      "Done with the batch: 500\n",
      "Done with the batch: 501\n",
      "Done with the batch: 502\n",
      "Done with the batch: 503\n",
      "Done with the batch: 504\n",
      "Done with the batch: 505\n",
      "Done with the batch: 506\n",
      "Done with the batch: 507\n",
      "Done with the batch: 508\n",
      "Done with the batch: 509\n",
      "Done with the batch: 510\n",
      "Done with the batch: 511\n",
      "Done with the batch: 512\n",
      "Done with the batch: 513\n",
      "Done with the batch: 514\n",
      "Done with the batch: 515\n",
      "Done with the batch: 516\n",
      "Done with the batch: 517\n",
      "Done with the batch: 518\n",
      "Done with the batch: 519\n",
      "Done with the batch: 520\n",
      "Done with the batch: 521\n",
      "Done with the batch: 522\n",
      "Done with the batch: 523\n",
      "Done with the batch: 524\n",
      "Done with the batch: 525\n",
      "Done with the batch: 526\n",
      "Done with the batch: 527\n",
      "Done with the batch: 528\n",
      "Done with the batch: 529\n",
      "Done with the batch: 530\n",
      "Done with the batch: 531\n",
      "Done with the batch: 532\n",
      "Done with the batch: 533\n",
      "Done with the batch: 534\n",
      "Done with the batch: 535\n",
      "Done with the batch: 536\n",
      "Done with the batch: 537\n",
      "Done with the batch: 538\n",
      "Done with the batch: 539\n",
      "Done with the batch: 540\n",
      "Done with the batch: 541\n",
      "Done with the batch: 542\n",
      "Done with the batch: 543\n",
      "Done with the batch: 544\n",
      "Done with the batch: 545\n",
      "Done with the batch: 546\n",
      "Done with the batch: 547\n",
      "Done with the batch: 548\n",
      "Done with the batch: 549\n",
      "Done with the batch: 550\n",
      "Done with the batch: 551\n",
      "Done with the batch: 552\n",
      "Done with the batch: 553\n",
      "Done with the batch: 554\n",
      "Done with the batch: 555\n",
      "Done with the batch: 556\n",
      "Done with the batch: 557\n",
      "Done with the batch: 558\n",
      "Done with the batch: 559\n",
      "Done with the batch: 560\n",
      "Done with the batch: 561\n",
      "Done with the batch: 562\n",
      "Done with the batch: 563\n",
      "Done with the batch: 564\n",
      "Done with the batch: 565\n",
      "Done with the batch: 566\n",
      "Done with the batch: 567\n",
      "Done with the batch: 568\n",
      "Done with the batch: 569\n",
      "Done with the batch: 570\n",
      "Done with the batch: 571\n",
      "Done with the batch: 572\n",
      "Done with the batch: 573\n",
      "Done with the batch: 574\n",
      "Done with the batch: 575\n",
      "Done with the batch: 576\n",
      "Done with the batch: 577\n",
      "Done with the batch: 578\n",
      "Done with the batch: 579\n",
      "Done with the batch: 580\n",
      "Done with the batch: 581\n",
      "Done with the batch: 582\n",
      "Done with the batch: 583\n",
      "Done with the batch: 584\n",
      "Done with the batch: 585\n",
      "Done with the batch: 586\n",
      "Done with the batch: 587\n",
      "Done with the batch: 588\n",
      "Done with the batch: 589\n",
      "Done with the batch: 590\n",
      "Done with the batch: 591\n",
      "Done with the batch: 592\n",
      "Done with the batch: 593\n",
      "Done with the batch: 594\n",
      "Done with the batch: 595\n",
      "Done with the batch: 596\n",
      "Done with the batch: 597\n",
      "Done with the batch: 598\n",
      "Done with the batch: 599\n",
      "Done with the batch: 600\n",
      "Done with the batch: 601\n",
      "Done with the batch: 602\n",
      "Done with the batch: 603\n",
      "Done with the batch: 604\n",
      "Done with the batch: 605\n",
      "Done with the batch: 606\n",
      "Done with the batch: 607\n",
      "Done with the batch: 608\n",
      "Done with the batch: 609\n",
      "Done with the batch: 610\n",
      "Done with the batch: 611\n",
      "Done with the batch: 612\n",
      "Done with the batch: 613\n",
      "Done with the batch: 614\n",
      "Done with the batch: 615\n",
      "Done with the batch: 616\n",
      "Done with the batch: 617\n",
      "Done with the batch: 618\n",
      "Done with the batch: 619\n",
      "Done with the batch: 620\n",
      "Done with the batch: 621\n",
      "Done with the batch: 622\n",
      "Done with the batch: 623\n",
      "Done with the batch: 624\n",
      "Done with the batch: 625\n",
      "Done with the batch: 626\n",
      "Done with the batch: 627\n",
      "Done with the batch: 628\n",
      "Done with the batch: 629\n",
      "Done with the batch: 630\n",
      "Done with the batch: 631\n",
      "Done with the batch: 632\n",
      "Done with the batch: 633\n",
      "Done with the batch: 634\n",
      "Done with the batch: 635\n",
      "Done with the batch: 636\n",
      "Done with the batch: 637\n",
      "Done with the batch: 638\n",
      "Done with the batch: 639\n",
      "Done with the batch: 640\n",
      "Done with the batch: 641\n",
      "Done with the batch: 642\n",
      "Done with the batch: 643\n",
      "Done with the batch: 644\n",
      "Done with the batch: 645\n",
      "Done with the batch: 646\n",
      "Done with the batch: 647\n",
      "Done with the batch: 648\n",
      "Done with the batch: 649\n",
      "Done with the batch: 650\n",
      "Done with the batch: 651\n",
      "Done with the batch: 652\n",
      "Done with the batch: 653\n",
      "Done with the batch: 654\n",
      "Done with the batch: 655\n",
      "Done with the batch: 656\n",
      "Done with the batch: 657\n",
      "Done with the batch: 658\n",
      "Done with the batch: 659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 660\n",
      "Done with the batch: 661\n",
      "Done with the batch: 662\n",
      "Done with the batch: 663\n",
      "Done with the batch: 664\n",
      "Done with the batch: 665\n",
      "Done with the batch: 666\n",
      "Done with the batch: 667\n",
      "Done with the batch: 668\n",
      "Done with the batch: 669\n",
      "Done with the batch: 670\n",
      "Done with the batch: 671\n",
      "Done with the batch: 672\n",
      "Done with the batch: 673\n",
      "Done with the batch: 674\n",
      "Done with the batch: 675\n",
      "Done with the batch: 676\n",
      "Done with the batch: 677\n",
      "Done with the batch: 678\n",
      "Done with the batch: 679\n",
      "Done with the batch: 680\n",
      "Done with the batch: 681\n",
      "Done with the batch: 682\n",
      "Done with the batch: 683\n",
      "Done with the batch: 684\n",
      "Done with the batch: 685\n",
      "Done with the batch: 686\n",
      "Done with the batch: 687\n",
      "Done with the batch: 688\n",
      "Done with the batch: 689\n",
      "Done with the batch: 690\n",
      "Done with the batch: 691\n",
      "Done with the batch: 692\n",
      "Done with the batch: 693\n",
      "Done with the batch: 694\n",
      "Done with the batch: 695\n",
      "Done with the batch: 696\n",
      "Done with the batch: 697\n",
      "Done with the batch: 698\n",
      "Done with the batch: 699\n",
      "Done with the batch: 700\n",
      "Done with the batch: 701\n",
      "Done with the batch: 702\n",
      "Done with the batch: 703\n",
      "Done with the batch: 704\n",
      "Done with the batch: 705\n",
      "Done with the batch: 706\n",
      "Done with the batch: 707\n",
      "Done with the batch: 708\n",
      "Done with the batch: 709\n",
      "Done with the batch: 710\n",
      "Done with the batch: 711\n",
      "Done with the batch: 712\n",
      "Done with the batch: 713\n",
      "Done with the batch: 714\n",
      "Done with the batch: 715\n",
      "Done with the batch: 716\n",
      "Done with the batch: 717\n",
      "Done with the batch: 718\n",
      "Done with the batch: 719\n",
      "Done with the batch: 720\n",
      "Done with the batch: 721\n",
      "Done with the batch: 722\n",
      "Done with the batch: 723\n",
      "Done with the batch: 724\n",
      "Done with the batch: 725\n",
      "Done with the batch: 726\n",
      "Done with the batch: 727\n",
      "Done with the batch: 728\n",
      "Done with the batch: 729\n",
      "Done with the batch: 730\n",
      "Done with the batch: 731\n",
      "Done with the batch: 732\n",
      "Done with the batch: 733\n",
      "Done with the batch: 734\n",
      "Done with the batch: 735\n",
      "Done with the batch: 736\n",
      "Done with the batch: 737\n",
      "Done with the batch: 738\n",
      "Done with the batch: 739\n",
      "Done with the batch: 740\n",
      "Done with the batch: 741\n",
      "Done with the batch: 742\n",
      "Done with the batch: 743\n",
      "Done with the batch: 744\n",
      "Done with the batch: 745\n",
      "Done with the batch: 746\n",
      "Done with the batch: 747\n",
      "Done with the batch: 748\n",
      "Done with the batch: 749\n",
      "Done with the batch: 750\n",
      "Done with the batch: 751\n",
      "Done with the batch: 752\n",
      "Done with the batch: 753\n",
      "Done with the batch: 754\n",
      "Done with the batch: 755\n",
      "Done with the batch: 756\n",
      "Done with the batch: 757\n",
      "Done with the batch: 758\n",
      "Done with the batch: 759\n",
      "Done with the batch: 760\n",
      "Done with the batch: 761\n",
      "Done with the batch: 762\n",
      "Done with the batch: 763\n",
      "Done with the batch: 764\n",
      "Done with the batch: 765\n",
      "Done with the batch: 766\n",
      "Done with the batch: 767\n",
      "Done with the batch: 768\n",
      "Done with the batch: 769\n",
      "Done with the batch: 770\n",
      "Done with the batch: 771\n",
      "Done with the batch: 772\n",
      "Done with the batch: 773\n",
      "Done with the batch: 774\n",
      "Done with the batch: 775\n",
      "Done with the batch: 776\n",
      "Done with the batch: 777\n",
      "Done with the batch: 778\n",
      "Done with the batch: 779\n",
      "Done with the batch: 780\n",
      "Done with the batch: 781\n",
      "Done with the batch: 782\n",
      "Done with the batch: 783\n",
      "Done with the batch: 784\n",
      "Done with the batch: 785\n",
      "Done with the batch: 786\n",
      "Done with the batch: 787\n",
      "Done with the batch: 788\n",
      "Done with the batch: 789\n",
      "Done with the batch: 790\n",
      "Done with the batch: 791\n",
      "Done with the batch: 792\n",
      "Done with the batch: 793\n",
      "Done with the batch: 794\n",
      "Done with the batch: 795\n",
      "Done with the batch: 796\n",
      "Done with the batch: 797\n",
      "Done with the batch: 798\n",
      "Done with the batch: 799\n",
      "Done with the batch: 800\n",
      "Done with the batch: 801\n",
      "Done with the batch: 802\n",
      "Done with the batch: 803\n",
      "Done with the batch: 804\n",
      "Done with the batch: 805\n",
      "Done with the batch: 806\n",
      "Done with the batch: 807\n",
      "Done with the batch: 808\n",
      "Done with the batch: 809\n",
      "Done with the batch: 810\n",
      "Done with the batch: 811\n",
      "Done with the batch: 812\n",
      "Done with the batch: 813\n",
      "Done with the batch: 814\n",
      "Done with the batch: 815\n",
      "Done with the batch: 816\n",
      "Done with the batch: 817\n",
      "Done with the batch: 818\n",
      "Done with the batch: 819\n",
      "Done with the batch: 820\n",
      "Done with the batch: 821\n",
      "Done with the batch: 822\n",
      "Done with the batch: 823\n",
      "Done with the batch: 824\n",
      "Done with the batch: 825\n",
      "Done with the batch: 826\n",
      "Done with the batch: 827\n",
      "Done with the batch: 828\n",
      "Done with the batch: 829\n",
      "Done with the batch: 830\n",
      "Done with the batch: 831\n",
      "Done with the batch: 832\n",
      "Done with the batch: 833\n",
      "Done with the batch: 834\n",
      "Done with the batch: 835\n",
      "Done with the batch: 836\n",
      "Done with the batch: 837\n",
      "Done with the batch: 838\n",
      "Done with the batch: 839\n",
      "Done with the batch: 840\n",
      "Done with the batch: 841\n",
      "Done with the batch: 842\n",
      "Done with the batch: 843\n",
      "Done with the batch: 844\n",
      "Done with the batch: 845\n",
      "Done with the batch: 846\n",
      "Done with the batch: 847\n",
      "Done with the batch: 848\n",
      "Done with the batch: 849\n",
      "Done with the batch: 850\n",
      "Done with the batch: 851\n",
      "Done with the batch: 852\n",
      "Done with the batch: 853\n",
      "Done with the batch: 854\n",
      "Done with the batch: 855\n",
      "Done with the batch: 856\n",
      "Done with the batch: 857\n",
      "Done with the batch: 858\n",
      "Done with the batch: 859\n",
      "Done with the batch: 860\n",
      "Done with the batch: 861\n",
      "Done with the batch: 862\n",
      "Done with the batch: 863\n",
      "Done with the batch: 864\n",
      "Done with the batch: 865\n",
      "Done with the batch: 866\n",
      "Done with the batch: 867\n",
      "Done with the batch: 868\n",
      "Done with the batch: 869\n",
      "Done with the batch: 870\n",
      "Done with the batch: 871\n",
      "Done with the batch: 872\n",
      "Done with the batch: 873\n",
      "Done with the batch: 874\n",
      "Done with the batch: 875\n",
      "Done with the batch: 876\n",
      "Done with the batch: 877\n",
      "Done with the batch: 878\n",
      "Done with the batch: 879\n",
      "Done with the batch: 880\n",
      "Done with the batch: 881\n",
      "Done with the batch: 882\n",
      "Done with the batch: 883\n",
      "Done with the batch: 884\n",
      "Done with the batch: 885\n",
      "Done with the batch: 886\n",
      "Done with the batch: 887\n",
      "Done with the batch: 888\n",
      "Done with the batch: 889\n",
      "Done with the batch: 890\n",
      "Done with the batch: 891\n",
      "Done with the batch: 892\n",
      "Done with the batch: 893\n",
      "Done with the batch: 894\n",
      "Done with the batch: 895\n",
      "Done with the batch: 896\n",
      "Done with the batch: 897\n",
      "Done with the batch: 898\n",
      "Done with the batch: 899\n",
      "Done with the batch: 900\n",
      "Done with the batch: 901\n",
      "Done with the batch: 902\n",
      "Done with the batch: 903\n",
      "Done with the batch: 904\n",
      "Done with the batch: 905\n",
      "Done with the batch: 906\n",
      "Done with the batch: 907\n",
      "Done with the batch: 908\n",
      "Done with the batch: 909\n",
      "Done with the batch: 910\n",
      "Done with the batch: 911\n",
      "Done with the batch: 912\n",
      "Done with the batch: 913\n",
      "Done with the batch: 914\n",
      "Done with the batch: 915\n",
      "Done with the batch: 916\n",
      "Done with the batch: 917\n",
      "Done with the batch: 918\n",
      "Done with the batch: 919\n",
      "Done with the batch: 920\n",
      "Done with the batch: 921\n",
      "Done with the batch: 922\n",
      "Done with the batch: 923\n",
      "Done with the batch: 924\n",
      "Done with the batch: 925\n",
      "Done with the batch: 926\n",
      "Done with the batch: 927\n",
      "Done with the batch: 928\n",
      "Done with the batch: 929\n",
      "Done with the batch: 930\n",
      "Done with the batch: 931\n",
      "Done with the batch: 932\n",
      "Done with the batch: 933\n",
      "Done with the batch: 934\n",
      "Done with the batch: 935\n",
      "Done with the batch: 936\n",
      "Done with the batch: 937\n",
      "Done with the batch: 938\n",
      "Done with the batch: 939\n",
      "Done with the batch: 940\n",
      "Done with the batch: 941\n",
      "Done with the batch: 942\n",
      "Done with the batch: 943\n",
      "Done with the batch: 944\n",
      "Done with the batch: 945\n",
      "Done with the batch: 946\n",
      "Done with the batch: 947\n",
      "Done with the batch: 948\n",
      "Done with the batch: 949\n",
      "Done with the batch: 950\n",
      "Done with the batch: 951\n",
      "Done with the batch: 952\n",
      "Done with the batch: 953\n",
      "Done with the batch: 954\n",
      "Done with the batch: 955\n",
      "Done with the batch: 956\n",
      "Done with the batch: 957\n",
      "Done with the batch: 958\n",
      "Done with the batch: 959\n",
      "Done with the batch: 960\n",
      "Done with the batch: 961\n",
      "Done with the batch: 962\n",
      "Done with the batch: 963\n",
      "Done with the batch: 964\n",
      "Done with the batch: 965\n",
      "Done with the batch: 966\n",
      "Done with the batch: 967\n",
      "Done with the batch: 968\n",
      "Done with the batch: 969\n",
      "Done with the batch: 970\n",
      "Done with the batch: 971\n",
      "Done with the batch: 972\n",
      "Done with the batch: 973\n",
      "Done with the batch: 974\n",
      "Done with the batch: 975\n",
      "Done with the batch: 976\n",
      "Done with the batch: 977\n",
      "Done with the batch: 978\n",
      "Done with the batch: 979\n",
      "Done with the batch: 980\n",
      "Done with the batch: 981\n",
      "Done with the batch: 982\n",
      "Done with the batch: 983\n",
      "Done with the batch: 984\n",
      "Done with the batch: 985\n",
      "Done with the batch: 986\n",
      "Done with the batch: 987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 988\n",
      "Done with the batch: 989\n",
      "Done with the batch: 990\n",
      "Done with the batch: 991\n",
      "Done with the batch: 992\n",
      "Done with the batch: 993\n",
      "Done with the batch: 994\n",
      "Done with the batch: 995\n",
      "Done with the batch: 996\n",
      "Done with the batch: 997\n",
      "Done with the batch: 998\n",
      "Done with the batch: 999\n",
      "Done with the batch: 1000\n",
      "Done with the batch: 1001\n",
      "Done with the batch: 1002\n",
      "Done with the batch: 1003\n",
      "Done with the batch: 1004\n",
      "Done with the batch: 1005\n",
      "Done with the batch: 1006\n",
      "Done with the batch: 1007\n",
      "Done with the batch: 1008\n",
      "Done with the batch: 1009\n",
      "Done with the batch: 1010\n",
      "Done with the batch: 1011\n",
      "Done with the batch: 1012\n",
      "Done with the batch: 1013\n",
      "Done with the batch: 1014\n",
      "Done with the batch: 1015\n",
      "Done with the batch: 1016\n",
      "Done with the batch: 1017\n",
      "Done with the batch: 1018\n",
      "Done with the batch: 1019\n",
      "Done with the batch: 1020\n",
      "Done with the batch: 1021\n",
      "Done with the batch: 1022\n",
      "Done with the batch: 1023\n",
      "Done with the batch: 1024\n",
      "Done with the batch: 1025\n",
      "Done with the batch: 1026\n",
      "Done with the batch: 1027\n",
      "Done with the batch: 1028\n",
      "Done with the batch: 1029\n",
      "Done with the batch: 1030\n",
      "Done with the batch: 1031\n",
      "Done with the batch: 1032\n",
      "Done with the batch: 1033\n",
      "Done with the batch: 1034\n",
      "Done with the batch: 1035\n",
      "Done with the batch: 1036\n",
      "Done with the batch: 1037\n",
      "Done with the batch: 1038\n",
      "Done with the batch: 1039\n",
      "Done with the batch: 1040\n",
      "Done with the batch: 1041\n",
      "Done with the batch: 1042\n",
      "Done with the batch: 1043\n",
      "Done with the batch: 1044\n",
      "Done with the batch: 1045\n",
      "Done with the batch: 1046\n",
      "Done with the batch: 1047\n",
      "Done with the batch: 1048\n",
      "Done with the batch: 1049\n",
      "Done with the batch: 1050\n",
      "Done with the batch: 1051\n",
      "Done with the batch: 1052\n",
      "Done with the batch: 1053\n",
      "Done with the batch: 1054\n",
      "Done with the batch: 1055\n",
      "Done with the batch: 1056\n",
      "Done with the batch: 1057\n",
      "Done with the batch: 1058\n",
      "Done with the batch: 1059\n",
      "Done with the batch: 1060\n",
      "Done with the batch: 1061\n",
      "Done with the batch: 1062\n",
      "Done with the batch: 1063\n",
      "Done with the batch: 1064\n",
      "Done with the batch: 1065\n",
      "Done with the batch: 1066\n",
      "Done with the batch: 1067\n",
      "Done with the batch: 1068\n",
      "Done with the batch: 1069\n",
      "Done with the batch: 1070\n",
      "Done with the batch: 1071\n",
      "Done with the batch: 1072\n",
      "Done with the batch: 1073\n",
      "Done with the batch: 1074\n",
      "Done with the batch: 1075\n",
      "Done with the batch: 1076\n",
      "Done with the batch: 1077\n",
      "Done with the batch: 1078\n",
      "Done with the batch: 1079\n",
      "Done with the batch: 1080\n",
      "Done with the batch: 1081\n",
      "Done with the batch: 1082\n",
      "Done with the batch: 1083\n",
      "Done with the batch: 1084\n",
      "Done with the batch: 1085\n",
      "Done with the batch: 1086\n",
      "Done with the batch: 1087\n",
      "Done with the batch: 1088\n",
      "Done with the batch: 1089\n",
      "Done with the batch: 1090\n",
      "Done with the batch: 1091\n",
      "Done with the batch: 1092\n",
      "Done with the batch: 1093\n",
      "Done with the batch: 1094\n",
      "Done with the batch: 1095\n",
      "Done with the batch: 1096\n",
      "Done with the batch: 1097\n",
      "Done with the batch: 1098\n",
      "Done with the batch: 1099\n",
      "Done with the batch: 1100\n",
      "Done with the batch: 1101\n",
      "Done with the batch: 1102\n",
      "Done with the batch: 1103\n",
      "Done with the batch: 1104\n",
      "Done with the batch: 1105\n",
      "Done with the batch: 1106\n",
      "Done with the batch: 1107\n",
      "Done with the batch: 1108\n",
      "Done with the batch: 1109\n",
      "Done with the batch: 1110\n",
      "Done with the batch: 1111\n",
      "Done with the batch: 1112\n",
      "Done with the batch: 1113\n",
      "Done with the batch: 1114\n",
      "Done with the batch: 1115\n",
      "Done with the batch: 1116\n",
      "Done with the batch: 1117\n",
      "Done with the batch: 1118\n",
      "Done with the batch: 1119\n",
      "Done with the batch: 1120\n",
      "Done with the batch: 1121\n",
      "Done with the batch: 1122\n",
      "Done with the batch: 1123\n",
      "Done with the batch: 1124\n",
      "Done with the batch: 1125\n",
      "Done with the batch: 1126\n",
      "Done with the batch: 1127\n",
      "Done with the batch: 1128\n",
      "Done with the batch: 1129\n",
      "Done with the batch: 1130\n",
      "Done with the batch: 1131\n",
      "Done with the batch: 1132\n",
      "Done with the batch: 1133\n",
      "Done with the batch: 1134\n",
      "Done with the batch: 1135\n",
      "Done with the batch: 1136\n",
      "Done with the batch: 1137\n",
      "Done with the batch: 1138\n",
      "Done with the batch: 1139\n",
      "Done with the batch: 1140\n",
      "Done with the batch: 1141\n",
      "Done with the batch: 1142\n",
      "Done with the batch: 1143\n",
      "Done with the batch: 1144\n",
      "Done with the batch: 1145\n",
      "Done with the batch: 1146\n",
      "Done with the batch: 1147\n",
      "Done with the batch: 1148\n",
      "Done with the batch: 1149\n",
      "Done with the batch: 1150\n",
      "Done with the batch: 1151\n",
      "Done with the batch: 1152\n",
      "Done with the batch: 1153\n",
      "Done with the batch: 1154\n",
      "Done with the batch: 1155\n",
      "Done with the batch: 1156\n",
      "Done with the batch: 1157\n",
      "Done with the batch: 1158\n",
      "Done with the batch: 1159\n",
      "Done with the batch: 1160\n",
      "Done with the batch: 1161\n",
      "Done with the batch: 1162\n",
      "Done with the batch: 1163\n",
      "Done with the batch: 1164\n",
      "Done with the batch: 1165\n",
      "Done with the batch: 1166\n",
      "Done with the batch: 1167\n",
      "Done with the batch: 1168\n",
      "Done with the batch: 1169\n",
      "Done with the batch: 1170\n",
      "Done with the batch: 1171\n",
      "Done with the batch: 1172\n",
      "Done with the batch: 1173\n",
      "Done with the batch: 1174\n",
      "Done with the batch: 1175\n",
      "Done with the batch: 1176\n",
      "Done with the batch: 1177\n",
      "Done with the batch: 1178\n",
      "Done with the batch: 1179\n",
      "Done with the batch: 1180\n",
      "Done with the batch: 1181\n",
      "Done with the batch: 1182\n",
      "Done with the batch: 1183\n",
      "Done with the batch: 1184\n",
      "Done with the batch: 1185\n",
      "Done with the batch: 1186\n",
      "Done with the batch: 1187\n",
      "Done with the batch: 1188\n",
      "Done with the batch: 1189\n",
      "Done with the batch: 1190\n",
      "Done with the batch: 1191\n",
      "Done with the batch: 1192\n",
      "Done with the batch: 1193\n",
      "Done with the batch: 1194\n",
      "Done with the batch: 1195\n",
      "Done with the batch: 1196\n",
      "Done with the batch: 1197\n",
      "Done with the batch: 1198\n",
      "Done with the batch: 1199\n",
      "Done with the batch: 1200\n",
      "Done with the batch: 1201\n",
      "Done with the batch: 1202\n",
      "Done with the batch: 1203\n",
      "Done with the batch: 1204\n",
      "Done with the batch: 1205\n",
      "Done with the batch: 1206\n",
      "Done with the batch: 1207\n",
      "Done with the batch: 1208\n",
      "Done with the batch: 1209\n",
      "Done with the batch: 1210\n",
      "Done with the batch: 1211\n",
      "Done with the batch: 1212\n",
      "Done with the batch: 1213\n",
      "Done with the batch: 1214\n",
      "Done with the batch: 1215\n",
      "Done with the batch: 1216\n",
      "Done with the batch: 1217\n",
      "Done with the batch: 1218\n",
      "Done with the batch: 1219\n",
      "Done with the batch: 1220\n",
      "Done with the batch: 1221\n",
      "Done with the batch: 1222\n",
      "Done with the batch: 1223\n",
      "Done with the batch: 1224\n",
      "Done with the batch: 1225\n",
      "Done with the batch: 1226\n",
      "Done with the batch: 1227\n",
      "Done with the batch: 1228\n",
      "Done with the batch: 1229\n",
      "Done with the batch: 1230\n",
      "Done with the batch: 1231\n",
      "Done with the batch: 1232\n",
      "Done with the batch: 1233\n",
      "Done with the batch: 1234\n",
      "Done with the batch: 1235\n",
      "Done with the batch: 1236\n",
      "Done with the batch: 1237\n",
      "Done with the batch: 1238\n",
      "Done with the batch: 1239\n",
      "Done with the batch: 1240\n",
      "Done with the batch: 1241\n",
      "Done with the batch: 1242\n",
      "Done with the batch: 1243\n",
      "Done with the batch: 1244\n",
      "Done with the batch: 1245\n",
      "Done with the batch: 1246\n",
      "Done with the batch: 1247\n",
      "Done with the batch: 1248\n",
      "Done with the batch: 1249\n",
      "Done with the batch: 1250\n",
      "Done with the batch: 1251\n",
      "Done with the batch: 1252\n",
      "Done with the batch: 1253\n",
      "Done with the batch: 1254\n",
      "Done with the batch: 1255\n",
      "Done with the batch: 1256\n",
      "Done with the batch: 1257\n",
      "Done with the batch: 1258\n",
      "Done with the batch: 1259\n",
      "Done with the batch: 1260\n",
      "Done with the batch: 1261\n",
      "Done with the batch: 1262\n",
      "Done with the batch: 1263\n",
      "Done with the batch: 1264\n",
      "Done with the batch: 1265\n",
      "Done with the batch: 1266\n",
      "Done with the batch: 1267\n",
      "Done with the batch: 1268\n",
      "Done with the batch: 1269\n",
      "Done with the batch: 1270\n",
      "Done with the batch: 1271\n",
      "Done with the batch: 1272\n",
      "Done with the batch: 1273\n",
      "Done with the batch: 1274\n",
      "Done with the batch: 1275\n",
      "Done with the batch: 1276\n",
      "Done with the batch: 1277\n",
      "Done with the batch: 1278\n",
      "Done with the batch: 1279\n",
      "Done with the batch: 1280\n",
      "Done with the batch: 1281\n",
      "Done with the batch: 1282\n",
      "Done with the batch: 1283\n",
      "Done with the batch: 1284\n",
      "Done with the batch: 1285\n",
      "Done with the batch: 1286\n",
      "Done with the batch: 1287\n",
      "Done with the batch: 1288\n",
      "Done with the batch: 1289\n",
      "Done with the batch: 1290\n",
      "Done with the batch: 1291\n",
      "Done with the batch: 1292\n",
      "Done with the batch: 1293\n",
      "Done with the batch: 1294\n",
      "Done with the batch: 1295\n",
      "Done with the batch: 1296\n",
      "Done with the batch: 1297\n",
      "Done with the batch: 1298\n",
      "Done with the batch: 1299\n",
      "Done with the batch: 1300\n",
      "Done with the batch: 1301\n",
      "Done with the batch: 1302\n",
      "Done with the batch: 1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 1304\n",
      "Done with the batch: 1305\n",
      "Done with the batch: 1306\n",
      "Done with the batch: 1307\n",
      "Done with the batch: 1308\n",
      "Done with the batch: 1309\n",
      "Done with the batch: 1310\n",
      "Done with the batch: 1311\n",
      "Done with the batch: 1312\n",
      "Done with the batch: 1313\n",
      "Done with the batch: 1314\n",
      "Done with the batch: 1315\n",
      "Done with the batch: 1316\n",
      "Done with the batch: 1317\n",
      "Done with the batch: 1318\n",
      "Done with the batch: 1319\n",
      "Done with the batch: 1320\n",
      "Done with the batch: 1321\n",
      "Done with the batch: 1322\n",
      "Done with the batch: 1323\n",
      "Done with the batch: 1324\n",
      "Done with the batch: 1325\n",
      "Done with the batch: 1326\n",
      "Done with the batch: 1327\n",
      "Done with the batch: 1328\n",
      "Done with the batch: 1329\n",
      "Done with the batch: 1330\n",
      "Done with the batch: 1331\n",
      "Done with the batch: 1332\n",
      "Done with the batch: 1333\n",
      "Done with the batch: 1334\n",
      "Done with the batch: 1335\n",
      "Done with the batch: 1336\n",
      "Done with the batch: 1337\n",
      "Done with the batch: 1338\n",
      "Done with the batch: 1339\n",
      "Done with the batch: 1340\n",
      "Done with the batch: 1341\n",
      "Done with the batch: 1342\n",
      "Done with the batch: 1343\n",
      "Done with the batch: 1344\n",
      "Done with the batch: 1345\n",
      "Done with the batch: 1346\n",
      "Done with the batch: 1347\n",
      "Done with the batch: 1348\n",
      "Done with the batch: 1349\n",
      "Done with the batch: 1350\n",
      "Done with the batch: 1351\n",
      "Done with the batch: 1352\n",
      "Done with the batch: 1353\n",
      "Done with the batch: 1354\n",
      "Done with the batch: 1355\n",
      "Done with the batch: 1356\n",
      "Done with the batch: 1357\n",
      "Done with the batch: 1358\n",
      "Done with the batch: 1359\n",
      "Done with the batch: 1360\n",
      "Done with the batch: 1361\n",
      "Done with the batch: 1362\n",
      "Done with the batch: 1363\n",
      "Done with the batch: 1364\n",
      "Done with the batch: 1365\n",
      "Done with the batch: 1366\n",
      "Done with the batch: 1367\n",
      "Done with the batch: 1368\n",
      "Done with the batch: 1369\n",
      "Done with the batch: 1370\n",
      "Done with the batch: 1371\n",
      "Done with the batch: 1372\n",
      "Done with the batch: 1373\n",
      "Done with the batch: 1374\n",
      "Done with the batch: 1375\n",
      "Done with the batch: 1376\n",
      "Done with the batch: 1377\n",
      "Done with the batch: 1378\n",
      "Done with the batch: 1379\n",
      "Done with the batch: 1380\n",
      "Done with the batch: 1381\n",
      "Done with the batch: 1382\n",
      "Done with the batch: 1383\n",
      "Done with the batch: 1384\n",
      "Done with the batch: 1385\n",
      "Done with the batch: 1386\n",
      "Done with the batch: 1387\n",
      "Done with the batch: 1388\n",
      "Done with the batch: 1389\n",
      "Done with the batch: 1390\n",
      "Done with the batch: 1391\n",
      "Done with the batch: 1392\n",
      "Done with the batch: 1393\n",
      "Done with the batch: 1394\n",
      "Done with the batch: 1395\n",
      "Done with the batch: 1396\n",
      "Done with the batch: 1397\n",
      "Done with the batch: 1398\n",
      "Done with the batch: 1399\n",
      "Done with the batch: 1400\n",
      "Done with the batch: 1401\n",
      "Done with the batch: 1402\n",
      "Done with the batch: 1403\n",
      "Done with the batch: 1404\n",
      "Done with the batch: 1405\n",
      "Done with the batch: 1406\n",
      "Done with the batch: 1407\n",
      "Done with the batch: 1408\n",
      "Done with the batch: 1409\n",
      "Done with the batch: 1410\n",
      "Done with the batch: 1411\n",
      "Done with the batch: 1412\n",
      "Done with the batch: 1413\n",
      "Done with the batch: 1414\n",
      "Done with the batch: 1415\n",
      "Done with the batch: 1416\n",
      "Done with the batch: 1417\n",
      "Done with the batch: 1418\n",
      "Done with the batch: 1419\n",
      "Done with the batch: 1420\n",
      "Done with the batch: 1421\n",
      "Done with the batch: 1422\n",
      "Done with the batch: 1423\n",
      "Done with the batch: 1424\n",
      "Done with the batch: 1425\n",
      "Done with the batch: 1426\n",
      "Done with the batch: 1427\n",
      "Done with the batch: 1428\n",
      "Done with the batch: 1429\n",
      "Done with the batch: 1430\n",
      "Done with the batch: 1431\n",
      "Done with the batch: 1432\n",
      "Done with the batch: 1433\n",
      "Done with the batch: 1434\n",
      "Done with the batch: 1435\n",
      "Done with the batch: 1436\n",
      "Done with the batch: 1437\n",
      "Done with the batch: 1438\n",
      "Done with the batch: 1439\n",
      "Done with the batch: 1440\n",
      "Done with the batch: 1441\n",
      "Done with the batch: 1442\n",
      "Done with the batch: 1443\n",
      "Done with the batch: 1444\n",
      "Done with the batch: 1445\n",
      "Done with the batch: 1446\n",
      "Done with the batch: 1447\n",
      "Done with the batch: 1448\n",
      "Done with the batch: 1449\n",
      "Done with the batch: 1450\n",
      "Done with the batch: 1451\n",
      "Done with the batch: 1452\n",
      "Done with the batch: 1453\n",
      "Done with the batch: 1454\n",
      "Done with the batch: 1455\n",
      "Done with the batch: 1456\n",
      "Done with the batch: 1457\n",
      "Done with the batch: 1458\n",
      "Done with the batch: 1459\n",
      "Done with the batch: 1460\n",
      "Done with the batch: 1461\n",
      "Done with the batch: 1462\n",
      "Done with the batch: 1463\n",
      "Done with the batch: 1464\n",
      "Done with the batch: 1465\n",
      "Done with the batch: 1466\n",
      "Done with the batch: 1467\n",
      "Done with the batch: 1468\n",
      "Done with the batch: 1469\n",
      "Done with the batch: 1470\n",
      "Done with the batch: 1471\n",
      "Done with the batch: 1472\n",
      "Done with the batch: 1473\n",
      "Done with the batch: 1474\n",
      "Done with the batch: 1475\n",
      "Done with the batch: 1476\n",
      "Done with the batch: 1477\n",
      "Done with the batch: 1478\n",
      "Done with the batch: 1479\n",
      "Done with the batch: 1480\n",
      "Done with the batch: 1481\n",
      "Done with the batch: 1482\n",
      "Done with the batch: 1483\n",
      "Done with the batch: 1484\n",
      "Done with the batch: 1485\n",
      "Done with the batch: 1486\n",
      "Done with the batch: 1487\n",
      "Done with the batch: 1488\n",
      "Done with the batch: 1489\n",
      "Done with the batch: 1490\n",
      "Done with the batch: 1491\n",
      "Done with the batch: 1492\n",
      "Done with the batch: 1493\n",
      "Done with the batch: 1494\n",
      "Done with the batch: 1495\n",
      "Done with the batch: 1496\n",
      "Done with the batch: 1497\n",
      "Done with the batch: 1498\n",
      "Done with the batch: 1499\n",
      "Done with the batch: 1500\n",
      "Done with the batch: 1501\n",
      "Done with the batch: 1502\n",
      "Done with the batch: 1503\n",
      "Done with the batch: 1504\n",
      "Done with the batch: 1505\n",
      "Done with the batch: 1506\n",
      "Done with the batch: 1507\n",
      "Done with the batch: 1508\n",
      "Done with the batch: 1509\n",
      "Done with the batch: 1510\n",
      "Done with the batch: 1511\n",
      "Done with the batch: 1512\n",
      "Done with the batch: 1513\n",
      "Done with the batch: 1514\n",
      "Done with the batch: 1515\n",
      "Done with the batch: 1516\n",
      "Done with the batch: 1517\n",
      "Done with the batch: 1518\n",
      "Done with the batch: 1519\n",
      "Done with the batch: 1520\n",
      "Done with the batch: 1521\n",
      "Done with the batch: 1522\n",
      "Done with the batch: 1523\n",
      "Done with the batch: 1524\n",
      "Done with the batch: 1525\n",
      "Done with the batch: 1526\n",
      "Done with the batch: 1527\n",
      "Done with the batch: 1528\n",
      "Done with the batch: 1529\n",
      "Done with the batch: 1530\n",
      "Done with the batch: 1531\n",
      "Done with the batch: 1532\n",
      "Done with the batch: 1533\n",
      "Done with the batch: 1534\n",
      "Done with the batch: 1535\n",
      "Done with the batch: 1536\n",
      "Done with the batch: 1537\n",
      "Done with the batch: 1538\n",
      "Done with the batch: 1539\n",
      "Done with the batch: 1540\n",
      "Done with the batch: 1541\n",
      "Done with the batch: 1542\n",
      "Done with the batch: 1543\n",
      "Done with the batch: 1544\n",
      "Done with the batch: 1545\n",
      "Done with the batch: 1546\n",
      "Done with the batch: 1547\n",
      "Done with the batch: 1548\n",
      "Done with the batch: 1549\n",
      "Done with the batch: 1550\n",
      "Done with the batch: 1551\n",
      "Done with the batch: 1552\n",
      "Done with the batch: 1553\n",
      "Done with the batch: 1554\n",
      "Done with the batch: 1555\n",
      "Done with the batch: 1556\n",
      "Done with the batch: 1557\n",
      "Done with the batch: 1558\n",
      "Done with the batch: 1559\n",
      "Done with the batch: 1560\n",
      "Done with the batch: 1561\n",
      "Done with the batch: 1562\n",
      "Done with the batch: 1563\n",
      "Done with the batch: 1564\n",
      "Done with the batch: 1565\n",
      "Done with the batch: 1566\n",
      "Done with the batch: 1567\n",
      "Done with the batch: 1568\n",
      "Done with the batch: 1569\n",
      "Done with the batch: 1570\n",
      "Done with the batch: 1571\n",
      "Done with the batch: 1572\n",
      "Done with the batch: 1573\n",
      "Done with the batch: 1574\n",
      "Done with the batch: 1575\n",
      "Done with the batch: 1576\n",
      "Done with the batch: 1577\n",
      "Done with the batch: 1578\n",
      "Done with the batch: 1579\n",
      "Done with the batch: 1580\n",
      "Done with the batch: 1581\n",
      "Done with the batch: 1582\n",
      "Done with the batch: 1583\n",
      "Done with the batch: 1584\n",
      "Done with the batch: 1585\n",
      "Done with the batch: 1586\n",
      "Done with the batch: 1587\n",
      "Done with the batch: 1588\n",
      "Done with the batch: 1589\n",
      "Done with the batch: 1590\n",
      "Done with the batch: 1591\n",
      "Done with the batch: 1592\n",
      "Done with the batch: 1593\n",
      "Done with the batch: 1594\n",
      "Done with the batch: 1595\n",
      "Done with the batch: 1596\n",
      "Done with the batch: 1597\n",
      "Done with the batch: 1598\n",
      "Done with the batch: 1599\n",
      "Done with the batch: 1600\n",
      "Done with the batch: 1601\n",
      "Done with the batch: 1602\n",
      "Done with the batch: 1603\n",
      "Done with the batch: 1604\n",
      "Done with the batch: 1605\n",
      "Done with the batch: 1606\n",
      "Done with the batch: 1607\n",
      "Done with the batch: 1608\n",
      "Done with the batch: 1609\n",
      "Done with the batch: 1610\n",
      "Done with the batch: 1611\n",
      "Done with the batch: 1612\n",
      "Done with the batch: 1613\n",
      "Done with the batch: 1614\n",
      "Done with the batch: 1615\n",
      "Done with the batch: 1616\n",
      "Done with the batch: 1617\n",
      "(6470, 18432) (6470,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"aa9e05ff-014b-428e-9ffd-8aedcddde677\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"aa9e05ff-014b-428e-9ffd-8aedcddde677\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "X_Train_FeatureMap=np.empty((0,18432))\n",
    "Y_Train_FeatureMap=np.empty((0,batch_size))\n",
    "print(X_Train_FeatureMap.shape)\n",
    "for i,data in enumerate(trainloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    featureMap=net.get_Representation_Net(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Train_FeatureMap=np.append(X_Train_FeatureMap,featureMap,axis=0)\n",
    "    Y_Train_FeatureMap=np.append(Y_Train_FeatureMap,labels.numpy())\n",
    "print(X_Train_FeatureMap.shape,Y_Train_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 18432)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "(1618, 18432) (1618,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"575b0136-bde4-4a0c-b795-78f2cb2b83fd\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"575b0136-bde4-4a0c-b795-78f2cb2b83fd\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "X_Test_FeatureMap=np.empty((0,18432))\n",
    "Y_Test_FeatureMap=np.empty((0,batch_size))\n",
    "print(X_Test_FeatureMap.shape)\n",
    "for i,data in enumerate(testloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    featuremap=net.get_Representation_Net(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Test_FeatureMap=np.append(X_Test_FeatureMap,featuremap,axis=0)\n",
    "    Y_Test_FeatureMap=np.append(Y_Test_FeatureMap,labels.numpy())\n",
    "print(X_Test_FeatureMap.shape,Y_Test_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 1/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.662 total time=   4.0s\n",
      "[CV 2/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 2/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.662 total time=   4.0s\n",
      "[CV 3/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 3/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.668 total time=   4.0s\n",
      "[CV 4/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 4/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.662 total time=   4.1s\n",
      "[CV 5/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 5/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.657 total time=   4.0s\n",
      "[CV 1/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 1/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.501 total time=   3.9s\n",
      "[CV 2/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 2/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 3/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 3/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 4/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 4/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=   3.9s\n",
      "[CV 5/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 5/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 1/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 1/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.501 total time=   4.1s\n",
      "[CV 2/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 2/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=   4.1s\n",
      "[CV 3/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 3/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 4/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 4/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 5/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 5/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=   3.9s\n",
      "[CV 1/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 1/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.501 total time=   5.0s\n",
      "[CV 2/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 2/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=   4.9s\n",
      "[CV 3/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 3/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=   4.8s\n",
      "[CV 4/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 4/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=   4.9s\n",
      "[CV 5/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 5/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=   4.8s\n",
      "[CV 1/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 1/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.501 total time=   4.9s\n",
      "[CV 2/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 2/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=   5.0s\n",
      "[CV 3/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 3/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=   4.9s\n",
      "[CV 4/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 4/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=   4.9s\n",
      "[CV 5/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 5/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=   4.8s\n",
      "[CV 1/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 1/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.943 total time=   1.2s\n",
      "[CV 2/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 2/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.947 total time=   1.2s\n",
      "[CV 3/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 3/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.942 total time=   1.1s\n",
      "[CV 4/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 4/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.933 total time=   1.1s\n",
      "[CV 5/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 5/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.938 total time=   1.2s\n",
      "[CV 1/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 1/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.747 total time=   3.5s\n",
      "[CV 2/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 2/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.784 total time=   3.6s\n",
      "[CV 3/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 3/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.773 total time=   3.6s\n",
      "[CV 4/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 4/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.777 total time=   3.6s\n",
      "[CV 5/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 5/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.783 total time=   3.6s\n",
      "[CV 1/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 1/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.501 total time=   4.1s\n",
      "[CV 2/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 2/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=   3.9s\n",
      "[CV 3/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 3/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 4/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 4/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 5/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 5/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=   4.0s\n",
      "[CV 1/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 1/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.501 total time=   5.1s\n",
      "[CV 2/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 2/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 3/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=   4.9s\n",
      "[CV 4/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 4/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=   5.0s\n",
      "[CV 5/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 5/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=   4.8s\n",
      "[CV 1/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 1/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.501 total time=   5.1s\n",
      "[CV 2/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 2/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 3/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=   5.2s\n",
      "[CV 4/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 4/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=   5.1s\n",
      "[CV 5/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 5/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=   5.4s\n",
      "[CV 1/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.951 total time=   0.8s\n",
      "[CV 2/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 2/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.964 total time=   0.8s\n",
      "[CV 3/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 3/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 4/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.951 total time=   0.8s\n",
      "[CV 5/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 5/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.958 total time=   0.9s\n",
      "[CV 1/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 1/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.920 total time=   3.9s\n",
      "[CV 2/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 2/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.911 total time=   3.7s\n",
      "[CV 3/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 3/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.912 total time=   3.9s\n",
      "[CV 4/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 4/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.896 total time=   3.6s\n",
      "[CV 5/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 5/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.900 total time=   3.5s\n",
      "[CV 1/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 1/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.580 total time=   4.6s\n",
      "[CV 2/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 2/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.577 total time=   4.5s\n",
      "[CV 3/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 3/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.570 total time=   4.5s\n",
      "[CV 4/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 4/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.572 total time=   4.6s\n",
      "[CV 5/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 5/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.572 total time=   5.0s\n",
      "[CV 1/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 1/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.501 total time=   5.2s\n",
      "[CV 2/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 2/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.502 total time=   5.2s\n",
      "[CV 3/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 3/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.499 total time=   5.2s\n",
      "[CV 4/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 4/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.500 total time=   5.1s\n",
      "[CV 5/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 5/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.498 total time=   5.1s\n",
      "[CV 1/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 1/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.501 total time=   5.1s\n",
      "[CV 2/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 2/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=   5.2s\n",
      "[CV 3/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 3/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=   5.2s\n",
      "[CV 4/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 4/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=   5.1s\n",
      "[CV 5/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 5/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=   5.4s\n",
      "[CV 1/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 1/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.956 total time=   0.8s\n",
      "[CV 2/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 2/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.964 total time=   0.8s\n",
      "[CV 3/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 3/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.956 total time=   0.7s\n",
      "[CV 4/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 4/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.7s\n",
      "[CV 5/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 5/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.954 total time=   0.7s\n",
      "[CV 1/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 1/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.926 total time=   3.6s\n",
      "[CV 2/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 2/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.918 total time=   3.6s\n",
      "[CV 3/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 3/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.912 total time=   3.6s\n",
      "[CV 4/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 4/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.894 total time=   3.6s\n",
      "[CV 5/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 5/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.896 total time=   3.5s\n",
      "[CV 1/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 1/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.590 total time=   4.1s\n",
      "[CV 2/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 2/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.587 total time=   4.2s\n",
      "[CV 3/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 3/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.578 total time=   4.1s\n",
      "[CV 4/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 4/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.585 total time=   4.2s\n",
      "[CV 5/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 5/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.577 total time=   4.0s\n",
      "[CV 1/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 1/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.501 total time=   5.0s\n",
      "[CV 2/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 2/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 3/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.499 total time=   5.1s\n",
      "[CV 4/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 4/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.499 total time=   5.1s\n",
      "[CV 5/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 5/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.498 total time=   5.1s\n",
      "[CV 1/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 1/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.501 total time=   5.3s\n",
      "[CV 2/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 2/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 3/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=   5.2s\n",
      "[CV 4/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 4/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=   5.2s\n",
      "[CV 5/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 5/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=   5.2s\n",
      "[CV 1/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 1/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.946 total time=   0.8s\n",
      "[CV 2/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.955 total time=   0.8s\n",
      "[CV 3/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 3/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.949 total time=   0.8s\n",
      "[CV 4/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 4/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.941 total time=   0.8s\n",
      "[CV 5/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 5/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.939 total time=   0.8s\n",
      "[CV 1/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 1/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.920 total time=   3.5s\n",
      "[CV 2/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 2/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.914 total time=   3.6s\n",
      "[CV 3/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 3/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.911 total time=   3.6s\n",
      "[CV 4/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 4/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.894 total time=   3.6s\n",
      "[CV 5/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 5/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.889 total time=   3.6s\n",
      "[CV 1/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 1/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.590 total time=   4.3s\n",
      "[CV 2/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 2/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.587 total time=   4.1s\n",
      "[CV 3/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 3/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.578 total time=   4.3s\n",
      "[CV 4/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 4/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.585 total time=   4.1s\n",
      "[CV 5/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 5/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.577 total time=   4.1s\n",
      "[CV 1/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 1/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.501 total time=   5.0s\n",
      "[CV 2/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 2/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.502 total time=   5.0s\n",
      "[CV 3/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 3/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.499 total time=   5.2s\n",
      "[CV 4/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 4/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.499 total time=   5.2s\n",
      "[CV 5/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 5/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.498 total time=   5.0s\n",
      "[CV 1/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 1/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.501 total time=   5.1s\n",
      "[CV 2/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 2/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=   5.4s\n",
      "[CV 3/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 3/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=   5.3s\n",
      "[CV 4/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 4/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=   5.5s\n",
      "[CV 5/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 5/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=   5.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.001, 0.1, 1, 10, 100],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'kernel': ['rbf']},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-2,0.1,1,10],\n",
    "                     'C': [0.001,0.1,1, 10, 100],\n",
    "}\n",
    "# tuned_parameters = {'kernel': ['rbf'], 'gamma': [1e-3],\n",
    "#                      'C': [0.001],\n",
    "#                    }\n",
    "clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring= 'accuracy',verbose=10\n",
    "    )\n",
    "clf.fit(X_Train, Y_Train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_svm(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        clf=SVC(C=1,kernel='rbf',gamma=0.001)\n",
    "        clf.fit(X_train,y_train.ravel())\n",
    "        y_pred = clf.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del clf\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 94.66769706336939\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 95.6723338485317\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 95.44049459041732\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 95.5950540958269\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 95.13137557959814\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.66769706336939 %\n",
      "Fold 1: 95.6723338485317 %\n",
      "Fold 2: 95.44049459041732 %\n",
      "Fold 3: 95.5950540958269 %\n",
      "Fold 4: 95.13137557959814 %\n",
      "Average: 95.30139103554868 %\n",
      "Accuracy:  0.9252163164400494\n",
      "Precision:  0.9234507897934386\n",
      "Recall:  0.9290953545232273\n",
      "F1-Score:  0.9262644728823888\n",
      "AUC:  0.9251726772616137\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_svm(X_Train,Y_Train.ravel())\n",
    "y_pred=clf.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test,y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test,y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test,y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test,y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_dtree(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        decision_tree = DecisionTreeClassifier(random_state=102)\n",
    "        decision_tree = decision_tree.fit(X_train, y_train.ravel())\n",
    "        y_pred = decision_tree.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del decision_tree\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 92.50386398763524\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 91.80834621329211\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 91.57650695517773\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 92.19474497681608\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 90.49459041731066\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 92.50386398763524 %\n",
      "Fold 1: 91.80834621329211 %\n",
      "Fold 2: 91.57650695517773 %\n",
      "Fold 3: 92.19474497681608 %\n",
      "Fold 4: 90.49459041731066 %\n",
      "Average: 91.71561051004637 %\n",
      "Accuracy:  0.8751545117428925\n",
      "Precision:  0.8746958637469586\n",
      "Recall:  0.8789731051344744\n",
      "F1-Score:  0.8768292682926829\n",
      "AUC:  0.875111552567237\n"
     ]
    }
   ],
   "source": [
    "dtree=k_fold_cv_dtree(X_Train,Y_Train.ravel())\n",
    "y_pred=dtree.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test,y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test,y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test,y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test,y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_rforest(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        random_forest = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=102)\n",
    "        random_forest = random_forest.fit(X_train, y_train.ravel())\n",
    "        y_pred = random_forest.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del random_forest\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 94.97681607418856\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 96.21329211746522\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 95.5177743431221\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 96.05873261205564\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 95.28593508500772\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.97681607418856 %\n",
      "Fold 1: 96.21329211746522 %\n",
      "Fold 2: 95.5177743431221 %\n",
      "Fold 3: 96.05873261205564 %\n",
      "Fold 4: 95.28593508500772 %\n",
      "Average: 95.61051004636785 %\n",
      "Accuracy:  0.9239802224969098\n",
      "Precision:  0.9222357229647631\n",
      "Recall:  0.9278728606356969\n",
      "F1-Score:  0.9250457038391224\n",
      "AUC:  0.9239364303178484\n"
     ]
    }
   ],
   "source": [
    "random_forest=k_fold_cv_rforest(X_Train,Y_Train.ravel())\n",
    "y_pred=random_forest.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test,y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test,y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test,y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test,y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_xgb(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        eval_set = [(X_train, y_train.ravel()), (X_test, y_test)]\n",
    "        xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, seed=102,use_label_encoder=False)\n",
    "        xg_cl.fit(X_train,y_train.ravel())\n",
    "        y_pred = xg_cl.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del xg_cl\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return xg_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "[16:14:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 96.29057187017001\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "[16:14:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 95.5950540958269\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "[16:14:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 96.05873261205564\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "[16:14:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 96.83153013910355\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "[16:14:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 95.13137557959814\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 96.29057187017001 %\n",
      "Fold 1: 95.5950540958269 %\n",
      "Fold 2: 96.05873261205564 %\n",
      "Fold 3: 96.83153013910355 %\n",
      "Fold 4: 95.13137557959814 %\n",
      "Average: 95.98145285935084 %\n",
      "Accuracy:  0.9134734239802225\n",
      "Precision:  0.9094202898550725\n",
      "Recall:  0.9205378973105135\n",
      "F1-Score:  0.9149453219927095\n",
      "AUC:  0.9133939486552567\n"
     ]
    }
   ],
   "source": [
    "xg=k_fold_cv_xgb(X_Train,Y_Train.ravel())\n",
    "y_pred=xg.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test,y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test,y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test,y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test,y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_mlp(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        clf = MLPClassifier(random_state=102, max_iter=3000, verbose=True).fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del clf\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.35446344\n",
      "Iteration 2, loss = 0.19986715\n",
      "Iteration 3, loss = 0.16539245\n",
      "Iteration 4, loss = 0.15076069\n",
      "Iteration 5, loss = 0.13701297\n",
      "Iteration 6, loss = 0.12803875\n",
      "Iteration 7, loss = 0.12197622\n",
      "Iteration 8, loss = 0.11623740\n",
      "Iteration 9, loss = 0.11166087\n",
      "Iteration 10, loss = 0.10750488\n",
      "Iteration 11, loss = 0.10751888\n",
      "Iteration 12, loss = 0.10077622\n",
      "Iteration 13, loss = 0.09998649\n",
      "Iteration 14, loss = 0.09618960\n",
      "Iteration 15, loss = 0.09507172\n",
      "Iteration 16, loss = 0.09052803\n",
      "Iteration 17, loss = 0.08977280\n",
      "Iteration 18, loss = 0.08726004\n",
      "Iteration 19, loss = 0.08490146\n",
      "Iteration 20, loss = 0.08341297\n",
      "Iteration 21, loss = 0.08340098\n",
      "Iteration 22, loss = 0.07912934\n",
      "Iteration 23, loss = 0.07891561\n",
      "Iteration 24, loss = 0.07833199\n",
      "Iteration 25, loss = 0.07749519\n",
      "Iteration 26, loss = 0.07227590\n",
      "Iteration 27, loss = 0.07705442\n",
      "Iteration 28, loss = 0.06854013\n",
      "Iteration 29, loss = 0.06961432\n",
      "Iteration 30, loss = 0.06889640\n",
      "Iteration 31, loss = 0.06646751\n",
      "Iteration 32, loss = 0.06794467\n",
      "Iteration 33, loss = 0.06514731\n",
      "Iteration 34, loss = 0.06141442\n",
      "Iteration 35, loss = 0.06349680\n",
      "Iteration 36, loss = 0.06120620\n",
      "Iteration 37, loss = 0.06065174\n",
      "Iteration 38, loss = 0.06085606\n",
      "Iteration 39, loss = 0.06358360\n",
      "Iteration 40, loss = 0.06492019\n",
      "Iteration 41, loss = 0.05664330\n",
      "Iteration 42, loss = 0.05655825\n",
      "Iteration 43, loss = 0.05505008\n",
      "Iteration 44, loss = 0.05661099\n",
      "Iteration 45, loss = 0.05235002\n",
      "Iteration 46, loss = 0.05167459\n",
      "Iteration 47, loss = 0.05083519\n",
      "Iteration 48, loss = 0.05063584\n",
      "Iteration 49, loss = 0.04952587\n",
      "Iteration 50, loss = 0.04974617\n",
      "Iteration 51, loss = 0.04936091\n",
      "Iteration 52, loss = 0.04742784\n",
      "Iteration 53, loss = 0.04583480\n",
      "Iteration 54, loss = 0.04558425\n",
      "Iteration 55, loss = 0.04805132\n",
      "Iteration 56, loss = 0.04518635\n",
      "Iteration 57, loss = 0.04421597\n",
      "Iteration 58, loss = 0.04937253\n",
      "Iteration 59, loss = 0.04408719\n",
      "Iteration 60, loss = 0.04179001\n",
      "Iteration 61, loss = 0.04196484\n",
      "Iteration 62, loss = 0.04239734\n",
      "Iteration 63, loss = 0.04089789\n",
      "Iteration 64, loss = 0.03906734\n",
      "Iteration 65, loss = 0.03834224\n",
      "Iteration 66, loss = 0.03817490\n",
      "Iteration 67, loss = 0.03651318\n",
      "Iteration 68, loss = 0.03773584\n",
      "Iteration 69, loss = 0.03820190\n",
      "Iteration 70, loss = 0.03629596\n",
      "Iteration 71, loss = 0.03627059\n",
      "Iteration 72, loss = 0.03656524\n",
      "Iteration 73, loss = 0.03847132\n",
      "Iteration 74, loss = 0.03571954\n",
      "Iteration 75, loss = 0.03491199\n",
      "Iteration 76, loss = 0.03273099\n",
      "Iteration 77, loss = 0.03284446\n",
      "Iteration 78, loss = 0.03191275\n",
      "Iteration 79, loss = 0.03303495\n",
      "Iteration 80, loss = 0.03392481\n",
      "Iteration 81, loss = 0.03111622\n",
      "Iteration 82, loss = 0.03086889\n",
      "Iteration 83, loss = 0.03223805\n",
      "Iteration 84, loss = 0.03012799\n",
      "Iteration 85, loss = 0.02846493\n",
      "Iteration 86, loss = 0.03026910\n",
      "Iteration 87, loss = 0.02910773\n",
      "Iteration 88, loss = 0.02779350\n",
      "Iteration 89, loss = 0.02806980\n",
      "Iteration 90, loss = 0.02749184\n",
      "Iteration 91, loss = 0.02945516\n",
      "Iteration 92, loss = 0.02762665\n",
      "Iteration 93, loss = 0.02695127\n",
      "Iteration 94, loss = 0.02701468\n",
      "Iteration 95, loss = 0.02634295\n",
      "Iteration 96, loss = 0.02539087\n",
      "Iteration 97, loss = 0.02600281\n",
      "Iteration 98, loss = 0.02534849\n",
      "Iteration 99, loss = 0.02526421\n",
      "Iteration 100, loss = 0.02316082\n",
      "Iteration 101, loss = 0.02912582\n",
      "Iteration 102, loss = 0.02502585\n",
      "Iteration 103, loss = 0.02402899\n",
      "Iteration 104, loss = 0.02483968\n",
      "Iteration 105, loss = 0.02223543\n",
      "Iteration 106, loss = 0.02178195\n",
      "Iteration 107, loss = 0.02334175\n",
      "Iteration 108, loss = 0.02258717\n",
      "Iteration 109, loss = 0.02102087\n",
      "Iteration 110, loss = 0.02257649\n",
      "Iteration 111, loss = 0.02462124\n",
      "Iteration 112, loss = 0.02423347\n",
      "Iteration 113, loss = 0.02198722\n",
      "Iteration 114, loss = 0.01938682\n",
      "Iteration 115, loss = 0.01928528\n",
      "Iteration 116, loss = 0.01967438\n",
      "Iteration 117, loss = 0.02046371\n",
      "Iteration 118, loss = 0.02223007\n",
      "Iteration 119, loss = 0.01894224\n",
      "Iteration 120, loss = 0.02149906\n",
      "Iteration 121, loss = 0.02432548\n",
      "Iteration 122, loss = 0.02166556\n",
      "Iteration 123, loss = 0.01950815\n",
      "Iteration 124, loss = 0.01777152\n",
      "Iteration 125, loss = 0.01636177\n",
      "Iteration 126, loss = 0.01645044\n",
      "Iteration 127, loss = 0.01802460\n",
      "Iteration 128, loss = 0.02094878\n",
      "Iteration 129, loss = 0.01851008\n",
      "Iteration 130, loss = 0.02037386\n",
      "Iteration 131, loss = 0.02011922\n",
      "Iteration 132, loss = 0.01595091\n",
      "Iteration 133, loss = 0.01559144\n",
      "Iteration 134, loss = 0.01634401\n",
      "Iteration 135, loss = 0.01687744\n",
      "Iteration 136, loss = 0.01667815\n",
      "Iteration 137, loss = 0.01889564\n",
      "Iteration 138, loss = 0.01645027\n",
      "Iteration 139, loss = 0.01443996\n",
      "Iteration 140, loss = 0.01479575\n",
      "Iteration 141, loss = 0.02022914\n",
      "Iteration 142, loss = 0.01758513\n",
      "Iteration 143, loss = 0.01391271\n",
      "Iteration 144, loss = 0.01347523\n",
      "Iteration 145, loss = 0.01358791\n",
      "Iteration 146, loss = 0.01316929\n",
      "Iteration 147, loss = 0.01508858\n",
      "Iteration 148, loss = 0.01623931\n",
      "Iteration 149, loss = 0.01521453\n",
      "Iteration 150, loss = 0.01346423\n",
      "Iteration 151, loss = 0.01247610\n",
      "Iteration 152, loss = 0.01208906\n",
      "Iteration 153, loss = 0.01174519\n",
      "Iteration 154, loss = 0.01102240\n",
      "Iteration 155, loss = 0.01235246\n",
      "Iteration 156, loss = 0.01183978\n",
      "Iteration 157, loss = 0.01101215\n",
      "Iteration 158, loss = 0.01127609\n",
      "Iteration 159, loss = 0.01238865\n",
      "Iteration 160, loss = 0.01308379\n",
      "Iteration 161, loss = 0.01175855\n",
      "Iteration 162, loss = 0.01068168\n",
      "Iteration 163, loss = 0.01049805\n",
      "Iteration 164, loss = 0.01014954\n",
      "Iteration 165, loss = 0.01102980\n",
      "Iteration 166, loss = 0.01069876\n",
      "Iteration 167, loss = 0.00986000\n",
      "Iteration 168, loss = 0.01022434\n",
      "Iteration 169, loss = 0.00952457\n",
      "Iteration 170, loss = 0.00918604\n",
      "Iteration 171, loss = 0.00948345\n",
      "Iteration 172, loss = 0.00906273\n",
      "Iteration 173, loss = 0.00935550\n",
      "Iteration 174, loss = 0.00911320\n",
      "Iteration 175, loss = 0.00863260\n",
      "Iteration 176, loss = 0.00865076\n",
      "Iteration 177, loss = 0.00882168\n",
      "Iteration 178, loss = 0.01080671\n",
      "Iteration 179, loss = 0.01116322\n",
      "Iteration 180, loss = 0.01202462\n",
      "Iteration 181, loss = 0.01092027\n",
      "Iteration 182, loss = 0.00855221\n",
      "Iteration 183, loss = 0.00823109\n",
      "Iteration 184, loss = 0.00853570\n",
      "Iteration 185, loss = 0.01708441\n",
      "Iteration 186, loss = 0.02493799\n",
      "Iteration 187, loss = 0.01639346\n",
      "Iteration 188, loss = 0.01309138\n",
      "Iteration 189, loss = 0.01246845\n",
      "Iteration 190, loss = 0.01277918\n",
      "Iteration 191, loss = 0.01198366\n",
      "Iteration 192, loss = 0.01096581\n",
      "Iteration 193, loss = 0.01044408\n",
      "Iteration 194, loss = 0.00820220\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 95.44049459041732\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.35703695\n",
      "Iteration 2, loss = 0.20471455\n",
      "Iteration 3, loss = 0.16734999\n",
      "Iteration 4, loss = 0.14995001\n",
      "Iteration 5, loss = 0.13376358\n",
      "Iteration 6, loss = 0.12667285\n",
      "Iteration 7, loss = 0.12026852\n",
      "Iteration 8, loss = 0.12008939\n",
      "Iteration 9, loss = 0.11592321\n",
      "Iteration 10, loss = 0.10836857\n",
      "Iteration 11, loss = 0.10379690\n",
      "Iteration 12, loss = 0.10278509\n",
      "Iteration 13, loss = 0.09993258\n",
      "Iteration 14, loss = 0.09645805\n",
      "Iteration 15, loss = 0.09178628\n",
      "Iteration 16, loss = 0.09389870\n",
      "Iteration 17, loss = 0.08674785\n",
      "Iteration 18, loss = 0.08822892\n",
      "Iteration 19, loss = 0.08711744\n",
      "Iteration 20, loss = 0.08282954\n",
      "Iteration 21, loss = 0.08023960\n",
      "Iteration 22, loss = 0.08069856\n",
      "Iteration 23, loss = 0.07966439\n",
      "Iteration 24, loss = 0.07852120\n",
      "Iteration 25, loss = 0.07745086\n",
      "Iteration 26, loss = 0.07544534\n",
      "Iteration 27, loss = 0.07227231\n",
      "Iteration 28, loss = 0.07199222\n",
      "Iteration 29, loss = 0.07030050\n",
      "Iteration 30, loss = 0.06901809\n",
      "Iteration 31, loss = 0.06644586\n",
      "Iteration 32, loss = 0.06683924\n",
      "Iteration 33, loss = 0.06642265\n",
      "Iteration 34, loss = 0.07052244\n",
      "Iteration 35, loss = 0.06374318\n",
      "Iteration 36, loss = 0.06276261\n",
      "Iteration 37, loss = 0.06432004\n",
      "Iteration 38, loss = 0.05981809\n",
      "Iteration 39, loss = 0.05944279\n",
      "Iteration 40, loss = 0.06262812\n",
      "Iteration 41, loss = 0.05988827\n",
      "Iteration 42, loss = 0.06010292\n",
      "Iteration 43, loss = 0.05593118\n",
      "Iteration 44, loss = 0.05506463\n",
      "Iteration 45, loss = 0.05622076\n",
      "Iteration 46, loss = 0.05434543\n",
      "Iteration 47, loss = 0.05152194\n",
      "Iteration 48, loss = 0.05263866\n",
      "Iteration 49, loss = 0.05266276\n",
      "Iteration 50, loss = 0.05134261\n",
      "Iteration 51, loss = 0.05103247\n",
      "Iteration 52, loss = 0.04938053\n",
      "Iteration 53, loss = 0.04944242\n",
      "Iteration 54, loss = 0.04708691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 55, loss = 0.04795027\n",
      "Iteration 56, loss = 0.04847133\n",
      "Iteration 57, loss = 0.04610166\n",
      "Iteration 58, loss = 0.04761548\n",
      "Iteration 59, loss = 0.04995240\n",
      "Iteration 60, loss = 0.04690766\n",
      "Iteration 61, loss = 0.04832742\n",
      "Iteration 62, loss = 0.04174305\n",
      "Iteration 63, loss = 0.04159104\n",
      "Iteration 64, loss = 0.04030367\n",
      "Iteration 65, loss = 0.04043935\n",
      "Iteration 66, loss = 0.04025891\n",
      "Iteration 67, loss = 0.03981869\n",
      "Iteration 68, loss = 0.04175576\n",
      "Iteration 69, loss = 0.04238040\n",
      "Iteration 70, loss = 0.03972514\n",
      "Iteration 71, loss = 0.03711967\n",
      "Iteration 72, loss = 0.04184303\n",
      "Iteration 73, loss = 0.04220345\n",
      "Iteration 74, loss = 0.03902865\n",
      "Iteration 75, loss = 0.03567591\n",
      "Iteration 76, loss = 0.03741101\n",
      "Iteration 77, loss = 0.03775305\n",
      "Iteration 78, loss = 0.03472754\n",
      "Iteration 79, loss = 0.03279748\n",
      "Iteration 80, loss = 0.03418811\n",
      "Iteration 81, loss = 0.03258143\n",
      "Iteration 82, loss = 0.03504288\n",
      "Iteration 83, loss = 0.03218853\n",
      "Iteration 84, loss = 0.03044157\n",
      "Iteration 85, loss = 0.02992017\n",
      "Iteration 86, loss = 0.03118272\n",
      "Iteration 87, loss = 0.03249468\n",
      "Iteration 88, loss = 0.03247028\n",
      "Iteration 89, loss = 0.03140625\n",
      "Iteration 90, loss = 0.03111501\n",
      "Iteration 91, loss = 0.02866885\n",
      "Iteration 92, loss = 0.03197812\n",
      "Iteration 93, loss = 0.03415808\n",
      "Iteration 94, loss = 0.02815411\n",
      "Iteration 95, loss = 0.02686209\n",
      "Iteration 96, loss = 0.02727881\n",
      "Iteration 97, loss = 0.02585272\n",
      "Iteration 98, loss = 0.02779981\n",
      "Iteration 99, loss = 0.02762711\n",
      "Iteration 100, loss = 0.02683304\n",
      "Iteration 101, loss = 0.02621665\n",
      "Iteration 102, loss = 0.02520625\n",
      "Iteration 103, loss = 0.02875758\n",
      "Iteration 104, loss = 0.02921523\n",
      "Iteration 105, loss = 0.02900634\n",
      "Iteration 106, loss = 0.02955266\n",
      "Iteration 107, loss = 0.02530242\n",
      "Iteration 108, loss = 0.02363157\n",
      "Iteration 109, loss = 0.02200462\n",
      "Iteration 110, loss = 0.02294374\n",
      "Iteration 111, loss = 0.02294940\n",
      "Iteration 112, loss = 0.02598828\n",
      "Iteration 113, loss = 0.02585077\n",
      "Iteration 114, loss = 0.02265307\n",
      "Iteration 115, loss = 0.02432427\n",
      "Iteration 116, loss = 0.02705463\n",
      "Iteration 117, loss = 0.02112308\n",
      "Iteration 118, loss = 0.02148678\n",
      "Iteration 119, loss = 0.02013409\n",
      "Iteration 120, loss = 0.01982732\n",
      "Iteration 121, loss = 0.02008384\n",
      "Iteration 122, loss = 0.01997302\n",
      "Iteration 123, loss = 0.01872942\n",
      "Iteration 124, loss = 0.01878180\n",
      "Iteration 125, loss = 0.02014693\n",
      "Iteration 126, loss = 0.02405623\n",
      "Iteration 127, loss = 0.02350394\n",
      "Iteration 128, loss = 0.02412219\n",
      "Iteration 129, loss = 0.01819253\n",
      "Iteration 130, loss = 0.01726958\n",
      "Iteration 131, loss = 0.01779522\n",
      "Iteration 132, loss = 0.01672039\n",
      "Iteration 133, loss = 0.01944546\n",
      "Iteration 134, loss = 0.01724140\n",
      "Iteration 135, loss = 0.01703334\n",
      "Iteration 136, loss = 0.01560936\n",
      "Iteration 137, loss = 0.01673158\n",
      "Iteration 138, loss = 0.01722123\n",
      "Iteration 139, loss = 0.01580069\n",
      "Iteration 140, loss = 0.01586388\n",
      "Iteration 141, loss = 0.01547881\n",
      "Iteration 142, loss = 0.01505061\n",
      "Iteration 143, loss = 0.01585063\n",
      "Iteration 144, loss = 0.01661279\n",
      "Iteration 145, loss = 0.01541645\n",
      "Iteration 146, loss = 0.01499328\n",
      "Iteration 147, loss = 0.01557274\n",
      "Iteration 148, loss = 0.01802093\n",
      "Iteration 149, loss = 0.01764433\n",
      "Iteration 150, loss = 0.01669035\n",
      "Iteration 151, loss = 0.01580293\n",
      "Iteration 152, loss = 0.01370553\n",
      "Iteration 153, loss = 0.01305516\n",
      "Iteration 154, loss = 0.01626992\n",
      "Iteration 155, loss = 0.01407820\n",
      "Iteration 156, loss = 0.01569920\n",
      "Iteration 157, loss = 0.01350508\n",
      "Iteration 158, loss = 0.01338230\n",
      "Iteration 159, loss = 0.01305024\n",
      "Iteration 160, loss = 0.01320011\n",
      "Iteration 161, loss = 0.01285072\n",
      "Iteration 162, loss = 0.01242712\n",
      "Iteration 163, loss = 0.01230983\n",
      "Iteration 164, loss = 0.01383592\n",
      "Iteration 165, loss = 0.01429549\n",
      "Iteration 166, loss = 0.01319232\n",
      "Iteration 167, loss = 0.01180291\n",
      "Iteration 168, loss = 0.01237965\n",
      "Iteration 169, loss = 0.01158390\n",
      "Iteration 170, loss = 0.01176660\n",
      "Iteration 171, loss = 0.01117062\n",
      "Iteration 172, loss = 0.01168212\n",
      "Iteration 173, loss = 0.01054892\n",
      "Iteration 174, loss = 0.01065315\n",
      "Iteration 175, loss = 0.01154230\n",
      "Iteration 176, loss = 0.01339040\n",
      "Iteration 177, loss = 0.01846774\n",
      "Iteration 178, loss = 0.01774436\n",
      "Iteration 179, loss = 0.01825914\n",
      "Iteration 180, loss = 0.01614878\n",
      "Iteration 181, loss = 0.01340223\n",
      "Iteration 182, loss = 0.01171585\n",
      "Iteration 183, loss = 0.01109820\n",
      "Iteration 184, loss = 0.01322168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 95.20865533230294\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.36043739\n",
      "Iteration 2, loss = 0.20458334\n",
      "Iteration 3, loss = 0.16480226\n",
      "Iteration 4, loss = 0.14668737\n",
      "Iteration 5, loss = 0.13389809\n",
      "Iteration 6, loss = 0.12661342\n",
      "Iteration 7, loss = 0.11983992\n",
      "Iteration 8, loss = 0.11544369\n",
      "Iteration 9, loss = 0.10920595\n",
      "Iteration 10, loss = 0.10371550\n",
      "Iteration 11, loss = 0.10040570\n",
      "Iteration 12, loss = 0.09819381\n",
      "Iteration 13, loss = 0.09177985\n",
      "Iteration 14, loss = 0.09108431\n",
      "Iteration 15, loss = 0.08994595\n",
      "Iteration 16, loss = 0.08646625\n",
      "Iteration 17, loss = 0.08371531\n",
      "Iteration 18, loss = 0.08335145\n",
      "Iteration 19, loss = 0.07992350\n",
      "Iteration 20, loss = 0.07817756\n",
      "Iteration 21, loss = 0.07542085\n",
      "Iteration 22, loss = 0.07675099\n",
      "Iteration 23, loss = 0.07361698\n",
      "Iteration 24, loss = 0.07064926\n",
      "Iteration 25, loss = 0.06904264\n",
      "Iteration 26, loss = 0.07098637\n",
      "Iteration 27, loss = 0.06759811\n",
      "Iteration 28, loss = 0.06643727\n",
      "Iteration 29, loss = 0.06689193\n",
      "Iteration 30, loss = 0.06411668\n",
      "Iteration 31, loss = 0.06596780\n",
      "Iteration 32, loss = 0.06671428\n",
      "Iteration 33, loss = 0.06230638\n",
      "Iteration 34, loss = 0.06007441\n",
      "Iteration 35, loss = 0.05848118\n",
      "Iteration 36, loss = 0.05751554\n",
      "Iteration 37, loss = 0.05870701\n",
      "Iteration 38, loss = 0.05560119\n",
      "Iteration 39, loss = 0.05477204\n",
      "Iteration 40, loss = 0.05250223\n",
      "Iteration 41, loss = 0.05412800\n",
      "Iteration 42, loss = 0.05246743\n",
      "Iteration 43, loss = 0.05536652\n",
      "Iteration 44, loss = 0.05152239\n",
      "Iteration 45, loss = 0.05063044\n",
      "Iteration 46, loss = 0.05072287\n",
      "Iteration 47, loss = 0.04614943\n",
      "Iteration 48, loss = 0.04649136\n",
      "Iteration 49, loss = 0.04524033\n",
      "Iteration 50, loss = 0.04339075\n",
      "Iteration 51, loss = 0.04257743\n",
      "Iteration 52, loss = 0.04225936\n",
      "Iteration 53, loss = 0.04123092\n",
      "Iteration 54, loss = 0.04395682\n",
      "Iteration 55, loss = 0.04382523\n",
      "Iteration 56, loss = 0.04299309\n",
      "Iteration 57, loss = 0.04017097\n",
      "Iteration 58, loss = 0.03835694\n",
      "Iteration 59, loss = 0.03763559\n",
      "Iteration 60, loss = 0.03759274\n",
      "Iteration 61, loss = 0.03738657\n",
      "Iteration 62, loss = 0.03641000\n",
      "Iteration 63, loss = 0.03646345\n",
      "Iteration 64, loss = 0.03621462\n",
      "Iteration 65, loss = 0.03530850\n",
      "Iteration 66, loss = 0.03431610\n",
      "Iteration 67, loss = 0.03426124\n",
      "Iteration 68, loss = 0.03225844\n",
      "Iteration 69, loss = 0.03187674\n",
      "Iteration 70, loss = 0.03510808\n",
      "Iteration 71, loss = 0.03360406\n",
      "Iteration 72, loss = 0.03117044\n",
      "Iteration 73, loss = 0.02940756\n",
      "Iteration 74, loss = 0.02992048\n",
      "Iteration 75, loss = 0.02943912\n",
      "Iteration 76, loss = 0.03040959\n",
      "Iteration 77, loss = 0.02853320\n",
      "Iteration 78, loss = 0.03039065\n",
      "Iteration 79, loss = 0.02809986\n",
      "Iteration 80, loss = 0.02768380\n",
      "Iteration 81, loss = 0.02849192\n",
      "Iteration 82, loss = 0.02740734\n",
      "Iteration 83, loss = 0.02536246\n",
      "Iteration 84, loss = 0.02539078\n",
      "Iteration 85, loss = 0.02481775\n",
      "Iteration 86, loss = 0.02526365\n",
      "Iteration 87, loss = 0.02516758\n",
      "Iteration 88, loss = 0.02458409\n",
      "Iteration 89, loss = 0.02380854\n",
      "Iteration 90, loss = 0.02285479\n",
      "Iteration 91, loss = 0.02296944\n",
      "Iteration 92, loss = 0.02327232\n",
      "Iteration 93, loss = 0.02382206\n",
      "Iteration 94, loss = 0.02531925\n",
      "Iteration 95, loss = 0.02475021\n",
      "Iteration 96, loss = 0.02221212\n",
      "Iteration 97, loss = 0.02087456\n",
      "Iteration 98, loss = 0.02097525\n",
      "Iteration 99, loss = 0.01993490\n",
      "Iteration 100, loss = 0.02001687\n",
      "Iteration 101, loss = 0.01955389\n",
      "Iteration 102, loss = 0.01964200\n",
      "Iteration 103, loss = 0.01846711\n",
      "Iteration 104, loss = 0.01997741\n",
      "Iteration 105, loss = 0.02053682\n",
      "Iteration 106, loss = 0.01852361\n",
      "Iteration 107, loss = 0.01946694\n",
      "Iteration 108, loss = 0.01764099\n",
      "Iteration 109, loss = 0.01897154\n",
      "Iteration 110, loss = 0.01744867\n",
      "Iteration 111, loss = 0.01779878\n",
      "Iteration 112, loss = 0.01761902\n",
      "Iteration 113, loss = 0.01732067\n",
      "Iteration 114, loss = 0.01735269\n",
      "Iteration 115, loss = 0.01807027\n",
      "Iteration 116, loss = 0.01741273\n",
      "Iteration 117, loss = 0.01775489\n",
      "Iteration 118, loss = 0.01734646\n",
      "Iteration 119, loss = 0.01556580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 120, loss = 0.01693820\n",
      "Iteration 121, loss = 0.02328101\n",
      "Iteration 122, loss = 0.02111618\n",
      "Iteration 123, loss = 0.01685503\n",
      "Iteration 124, loss = 0.01531138\n",
      "Iteration 125, loss = 0.01458319\n",
      "Iteration 126, loss = 0.01666959\n",
      "Iteration 127, loss = 0.01702951\n",
      "Iteration 128, loss = 0.01472977\n",
      "Iteration 129, loss = 0.01472458\n",
      "Iteration 130, loss = 0.01350658\n",
      "Iteration 131, loss = 0.01328011\n",
      "Iteration 132, loss = 0.01323590\n",
      "Iteration 133, loss = 0.01259342\n",
      "Iteration 134, loss = 0.01226296\n",
      "Iteration 135, loss = 0.01459705\n",
      "Iteration 136, loss = 0.01361591\n",
      "Iteration 137, loss = 0.01257946\n",
      "Iteration 138, loss = 0.01227878\n",
      "Iteration 139, loss = 0.01207211\n",
      "Iteration 140, loss = 0.01218122\n",
      "Iteration 141, loss = 0.01344296\n",
      "Iteration 142, loss = 0.01190300\n",
      "Iteration 143, loss = 0.01150483\n",
      "Iteration 144, loss = 0.01149873\n",
      "Iteration 145, loss = 0.01183227\n",
      "Iteration 146, loss = 0.01259920\n",
      "Iteration 147, loss = 0.01248143\n",
      "Iteration 148, loss = 0.01210074\n",
      "Iteration 149, loss = 0.01150942\n",
      "Iteration 150, loss = 0.01451269\n",
      "Iteration 151, loss = 0.01460082\n",
      "Iteration 152, loss = 0.01598029\n",
      "Iteration 153, loss = 0.01294909\n",
      "Iteration 154, loss = 0.01223421\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 95.44049459041732\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.35471798\n",
      "Iteration 2, loss = 0.19183429\n",
      "Iteration 3, loss = 0.15508007\n",
      "Iteration 4, loss = 0.13887342\n",
      "Iteration 5, loss = 0.12686213\n",
      "Iteration 6, loss = 0.11984535\n",
      "Iteration 7, loss = 0.11243324\n",
      "Iteration 8, loss = 0.10829916\n",
      "Iteration 9, loss = 0.10318628\n",
      "Iteration 10, loss = 0.10144175\n",
      "Iteration 11, loss = 0.09800851\n",
      "Iteration 12, loss = 0.09517713\n",
      "Iteration 13, loss = 0.09276848\n",
      "Iteration 14, loss = 0.08998886\n",
      "Iteration 15, loss = 0.09260586\n",
      "Iteration 16, loss = 0.08693845\n",
      "Iteration 17, loss = 0.08591755\n",
      "Iteration 18, loss = 0.08380015\n",
      "Iteration 19, loss = 0.08145260\n",
      "Iteration 20, loss = 0.07924631\n",
      "Iteration 21, loss = 0.08086376\n",
      "Iteration 22, loss = 0.07619955\n",
      "Iteration 23, loss = 0.08069857\n",
      "Iteration 24, loss = 0.07488307\n",
      "Iteration 25, loss = 0.07190719\n",
      "Iteration 26, loss = 0.07076242\n",
      "Iteration 27, loss = 0.07918707\n",
      "Iteration 28, loss = 0.07211853\n",
      "Iteration 29, loss = 0.06744920\n",
      "Iteration 30, loss = 0.06500884\n",
      "Iteration 31, loss = 0.06349371\n",
      "Iteration 32, loss = 0.06465711\n",
      "Iteration 33, loss = 0.06224678\n",
      "Iteration 34, loss = 0.06298232\n",
      "Iteration 35, loss = 0.06209950\n",
      "Iteration 36, loss = 0.05967361\n",
      "Iteration 37, loss = 0.05888041\n",
      "Iteration 38, loss = 0.05679703\n",
      "Iteration 39, loss = 0.05719140\n",
      "Iteration 40, loss = 0.05546729\n",
      "Iteration 41, loss = 0.05598502\n",
      "Iteration 42, loss = 0.05511493\n",
      "Iteration 43, loss = 0.05302376\n",
      "Iteration 44, loss = 0.05383894\n",
      "Iteration 45, loss = 0.05199834\n",
      "Iteration 46, loss = 0.05331841\n",
      "Iteration 47, loss = 0.05040869\n",
      "Iteration 48, loss = 0.04832520\n",
      "Iteration 49, loss = 0.04839665\n",
      "Iteration 50, loss = 0.04825202\n",
      "Iteration 51, loss = 0.04862776\n",
      "Iteration 52, loss = 0.04539738\n",
      "Iteration 53, loss = 0.04514235\n",
      "Iteration 54, loss = 0.04581119\n",
      "Iteration 55, loss = 0.04425595\n",
      "Iteration 56, loss = 0.04585569\n",
      "Iteration 57, loss = 0.04426190\n",
      "Iteration 58, loss = 0.04468233\n",
      "Iteration 59, loss = 0.04127671\n",
      "Iteration 60, loss = 0.04044253\n",
      "Iteration 61, loss = 0.04059893\n",
      "Iteration 62, loss = 0.04102493\n",
      "Iteration 63, loss = 0.03835018\n",
      "Iteration 64, loss = 0.03873669\n",
      "Iteration 65, loss = 0.03858898\n",
      "Iteration 66, loss = 0.03833149\n",
      "Iteration 67, loss = 0.03659099\n",
      "Iteration 68, loss = 0.03640092\n",
      "Iteration 69, loss = 0.03500187\n",
      "Iteration 70, loss = 0.03586071\n",
      "Iteration 71, loss = 0.03800380\n",
      "Iteration 72, loss = 0.03793141\n",
      "Iteration 73, loss = 0.03550737\n",
      "Iteration 74, loss = 0.03512503\n",
      "Iteration 75, loss = 0.03296021\n",
      "Iteration 76, loss = 0.03360815\n",
      "Iteration 77, loss = 0.03209502\n",
      "Iteration 78, loss = 0.03096417\n",
      "Iteration 79, loss = 0.03135391\n",
      "Iteration 80, loss = 0.03122666\n",
      "Iteration 81, loss = 0.03627754\n",
      "Iteration 82, loss = 0.03515881\n",
      "Iteration 83, loss = 0.03186231\n",
      "Iteration 84, loss = 0.03020782\n",
      "Iteration 85, loss = 0.03228526\n",
      "Iteration 86, loss = 0.02889365\n",
      "Iteration 87, loss = 0.02768140\n",
      "Iteration 88, loss = 0.02864396\n",
      "Iteration 89, loss = 0.02697643\n",
      "Iteration 90, loss = 0.02694669\n",
      "Iteration 91, loss = 0.02723775\n",
      "Iteration 92, loss = 0.03047119\n",
      "Iteration 93, loss = 0.02622266\n",
      "Iteration 94, loss = 0.02689591\n",
      "Iteration 95, loss = 0.02646324\n",
      "Iteration 96, loss = 0.02710731\n",
      "Iteration 97, loss = 0.02472662\n",
      "Iteration 98, loss = 0.02479405\n",
      "Iteration 99, loss = 0.02311718\n",
      "Iteration 100, loss = 0.02345444\n",
      "Iteration 101, loss = 0.02432100\n",
      "Iteration 102, loss = 0.02348252\n",
      "Iteration 103, loss = 0.02616993\n",
      "Iteration 104, loss = 0.02466274\n",
      "Iteration 105, loss = 0.02458981\n",
      "Iteration 106, loss = 0.02198334\n",
      "Iteration 107, loss = 0.02113253\n",
      "Iteration 108, loss = 0.02019123\n",
      "Iteration 109, loss = 0.02014588\n",
      "Iteration 110, loss = 0.02279769\n",
      "Iteration 111, loss = 0.02832552\n",
      "Iteration 112, loss = 0.02052873\n",
      "Iteration 113, loss = 0.02282289\n",
      "Iteration 114, loss = 0.02089491\n",
      "Iteration 115, loss = 0.01843514\n",
      "Iteration 116, loss = 0.01997715\n",
      "Iteration 117, loss = 0.01839823\n",
      "Iteration 118, loss = 0.01845858\n",
      "Iteration 119, loss = 0.02089348\n",
      "Iteration 120, loss = 0.02246468\n",
      "Iteration 121, loss = 0.02376283\n",
      "Iteration 122, loss = 0.01883588\n",
      "Iteration 123, loss = 0.02003802\n",
      "Iteration 124, loss = 0.01946444\n",
      "Iteration 125, loss = 0.02204199\n",
      "Iteration 126, loss = 0.01854018\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 94.74497681607419\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.36452888\n",
      "Iteration 2, loss = 0.20131876\n",
      "Iteration 3, loss = 0.16249393\n",
      "Iteration 4, loss = 0.14036890\n",
      "Iteration 5, loss = 0.12963663\n",
      "Iteration 6, loss = 0.12431988\n",
      "Iteration 7, loss = 0.11513105\n",
      "Iteration 8, loss = 0.10897038\n",
      "Iteration 9, loss = 0.10650010\n",
      "Iteration 10, loss = 0.10315116\n",
      "Iteration 11, loss = 0.10096488\n",
      "Iteration 12, loss = 0.09781582\n",
      "Iteration 13, loss = 0.09469542\n",
      "Iteration 14, loss = 0.09001529\n",
      "Iteration 15, loss = 0.08840220\n",
      "Iteration 16, loss = 0.08576007\n",
      "Iteration 17, loss = 0.08902712\n",
      "Iteration 18, loss = 0.08413284\n",
      "Iteration 19, loss = 0.08223693\n",
      "Iteration 20, loss = 0.07702144\n",
      "Iteration 21, loss = 0.08025378\n",
      "Iteration 22, loss = 0.07537037\n",
      "Iteration 23, loss = 0.07540381\n",
      "Iteration 24, loss = 0.07469636\n",
      "Iteration 25, loss = 0.07128737\n",
      "Iteration 26, loss = 0.07086590\n",
      "Iteration 27, loss = 0.07159774\n",
      "Iteration 28, loss = 0.06906749\n",
      "Iteration 29, loss = 0.06688520\n",
      "Iteration 30, loss = 0.06639972\n",
      "Iteration 31, loss = 0.06510293\n",
      "Iteration 32, loss = 0.06438691\n",
      "Iteration 33, loss = 0.06268765\n",
      "Iteration 34, loss = 0.06264668\n",
      "Iteration 35, loss = 0.06012144\n",
      "Iteration 36, loss = 0.05849375\n",
      "Iteration 37, loss = 0.05812655\n",
      "Iteration 38, loss = 0.05982597\n",
      "Iteration 39, loss = 0.05929206\n",
      "Iteration 40, loss = 0.06095748\n",
      "Iteration 41, loss = 0.05415865\n",
      "Iteration 42, loss = 0.05364278\n",
      "Iteration 43, loss = 0.05523364\n",
      "Iteration 44, loss = 0.05288805\n",
      "Iteration 45, loss = 0.05117448\n",
      "Iteration 46, loss = 0.05577217\n",
      "Iteration 47, loss = 0.04877621\n",
      "Iteration 48, loss = 0.04821760\n",
      "Iteration 49, loss = 0.04682247\n",
      "Iteration 50, loss = 0.04721806\n",
      "Iteration 51, loss = 0.04651997\n",
      "Iteration 52, loss = 0.04680282\n",
      "Iteration 53, loss = 0.05049550\n",
      "Iteration 54, loss = 0.04751532\n",
      "Iteration 55, loss = 0.04300344\n",
      "Iteration 56, loss = 0.04240040\n",
      "Iteration 57, loss = 0.04226406\n",
      "Iteration 58, loss = 0.04318221\n",
      "Iteration 59, loss = 0.04267857\n",
      "Iteration 60, loss = 0.03956652\n",
      "Iteration 61, loss = 0.04050669\n",
      "Iteration 62, loss = 0.04041756\n",
      "Iteration 63, loss = 0.04225099\n",
      "Iteration 64, loss = 0.03921403\n",
      "Iteration 65, loss = 0.03657445\n",
      "Iteration 66, loss = 0.03648134\n",
      "Iteration 67, loss = 0.03487590\n",
      "Iteration 68, loss = 0.03600734\n",
      "Iteration 69, loss = 0.03354142\n",
      "Iteration 70, loss = 0.03528164\n",
      "Iteration 71, loss = 0.03595403\n",
      "Iteration 72, loss = 0.03424058\n",
      "Iteration 73, loss = 0.03162082\n",
      "Iteration 74, loss = 0.03191137\n",
      "Iteration 75, loss = 0.03292415\n",
      "Iteration 76, loss = 0.03154945\n",
      "Iteration 77, loss = 0.03313950\n",
      "Iteration 78, loss = 0.03048482\n",
      "Iteration 79, loss = 0.03006289\n",
      "Iteration 80, loss = 0.02886270\n",
      "Iteration 81, loss = 0.02916774\n",
      "Iteration 82, loss = 0.02771977\n",
      "Iteration 83, loss = 0.02889006\n",
      "Iteration 84, loss = 0.02930779\n",
      "Iteration 85, loss = 0.02767458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 86, loss = 0.02822873\n",
      "Iteration 87, loss = 0.03305200\n",
      "Iteration 88, loss = 0.02907720\n",
      "Iteration 89, loss = 0.02681612\n",
      "Iteration 90, loss = 0.02653276\n",
      "Iteration 91, loss = 0.02484566\n",
      "Iteration 92, loss = 0.02469232\n",
      "Iteration 93, loss = 0.03029721\n",
      "Iteration 94, loss = 0.02654626\n",
      "Iteration 95, loss = 0.02702421\n",
      "Iteration 96, loss = 0.02456772\n",
      "Iteration 97, loss = 0.02275822\n",
      "Iteration 98, loss = 0.02213074\n",
      "Iteration 99, loss = 0.02344573\n",
      "Iteration 100, loss = 0.02310169\n",
      "Iteration 101, loss = 0.02234413\n",
      "Iteration 102, loss = 0.02310854\n",
      "Iteration 103, loss = 0.02122653\n",
      "Iteration 104, loss = 0.02008821\n",
      "Iteration 105, loss = 0.02038757\n",
      "Iteration 106, loss = 0.02037250\n",
      "Iteration 107, loss = 0.02096869\n",
      "Iteration 108, loss = 0.02072672\n",
      "Iteration 109, loss = 0.02039611\n",
      "Iteration 110, loss = 0.02192305\n",
      "Iteration 111, loss = 0.02412938\n",
      "Iteration 112, loss = 0.02207645\n",
      "Iteration 113, loss = 0.02120090\n",
      "Iteration 114, loss = 0.02022364\n",
      "Iteration 115, loss = 0.02030466\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 94.5904173106646\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 95.44049459041732 %\n",
      "Fold 1: 95.20865533230294 %\n",
      "Fold 2: 95.44049459041732 %\n",
      "Fold 3: 94.74497681607419 %\n",
      "Fold 4: 94.5904173106646 %\n",
      "Average: 95.08500772797527 %\n",
      "Accuracy:  0.9140914709517923\n",
      "Precision:  0.9155446756425949\n",
      "Recall:  0.9144254278728606\n",
      "F1-Score:  0.9149847094801223\n",
      "AUC:  0.9140877139364304\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_mlp(X_Train,Y_Train.ravel())\n",
    "y_pred=clf.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test,y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test,y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test,y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test,y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoVUlEQVR4nO3deZgcZbn38e9vZjLZQ1bWJCTsILJGFkEEFAVEXPAVcRc4HlRU9Ojretx4z4J6XBA9HFRw16MiENwAUUCNQhLMxpqwBEICGcg6SWbt+/2jqkPPZGa6ZpKanp7+fa6rr66uruUumNTd9dRTz62IwMzMalddpQMwM7PKciIwM6txTgRmZjXOicDMrMY5EZiZ1biGSgfQX1OnTo1Zs2ZVOgwzs6qycOHCZyNiWk/fVV0imDVrFgsWLKh0GGZmVUXSyt6+c9OQmVmNcyIwM6txTgRmZjXOicDMrMY5EZiZ1bjcEoGkayWtlbSsl+8l6UpJKyQtkXRMXrGYmVnv8rwi+B5wZh/fnwUcmL7eDfx3jrGYmVkvcnuOICLukjSrj0VeA/wgknGw/y5poqS9ImJNXjGZVauIoLMQdBTS986gEMUXXacLQXSfV5wuJNM9fl9IpmOHbT6/XiEAkvUD0vdIYyzOi5K4k+8jkulk7WSZKH6gZJletklx+eK89HP3bdJlXtdtls7L8t97x3k9LJdpmYFtq6eF5syazCkH9fhM2E6p5ANl+wBPlnxelc7bIRFIejfJVQMzZ84clOCsthQKQUtHJ9vaOtna1sm29uenW9o7ae3opLWjQHtn0NZRoK2jk7bOQjpdoLVkuq2j0OW7ts4CHZ3FE3mBzkLQ3u3z9hN8+t7e2XV+Z8F1Q2qR1PXzJS/df9glAvUwr8e/9oi4BrgGYM6cOf4XYdu1dRTYsLWNTS3tbNzWweaWdja3dKSv9u3vm0o+b2tPT/bpCX9rWwct7YWdiqOxoY6R9XU0NpS80s8j6pPp+joxckQD9XWioU7Je33d89N1or6u6+cdvq9P3uuUvtcJSdQJ6pXMl6BOoq6O9PPz3xeni98rXWeH7+uS99LvS7cNyUlKKH1n+zx2mCdUsvzzy6XzitvrZZv0uJ8dt4nYvkxv29y+yR7OPup2Sup5mR7mdVuw52XKr1dJlUwEq4AZJZ+nA6srFIsNERHBui1tPL2phbWbWmna3Mq6rW2s27Lja/2WNja3dvS5vTrB+FEjmDC6gfEjRzBuVANTxjYyY1IDo0bUM6axntGN9YzuNj26Mf08ooFRI+oY2VCfnOy7neQbG5IT9VD6R23WX5VMBHOBSyX9DDge2Oj7A8Pf5pZ2nli3lSfXbeXJddtYvXEbaze18vSmFp7e2ELT5lbaOnf8dT6yoY4pYxuZNLaRyWMb2XfKGCaPbWTymGTehNEjGD+qgQmjGpgwagTjRyWfxzTW+yRtVkZuiUDST4FTgamSVgGfBUYARMTVwG+Bs4EVwFbgXXnFYoOrubWDR9Y2s3xtM480NZec+Leyfmt7l2XHNNaz54RR7DFhFMfNnsweE0axx4SRybzdRjFt3EimjGtkTGPVjY9oVjXy7DV0QZnvA3hfXvu3/LV1FHj4mc3ct3ojDz3dzIqmZlY8s5nVG1u2L9NQJ6ZPGs2MyWM4/IV7MXPyGGZOHsOMSWOYMXk0E8c0VvAIzAyqcBhqq4z2zgIPrNnEklUbuW/1RpY+tZGHnt5Me2dy737UiDoO2H0cx+83hQN2H7f9te/kMTTU+wF2s6HMicB6tLmlnX88sYEFj69j/uPrWfTkBra1dwIwccwIDt97Ny46eT8O32cCh++9GzMnj6Guzm3xZtXIicCA5Bf/P57YwF0PN/Hn5U0sfWojhUh63Ry29wTOf9EM5syaxFEzJrLPxNG+AWs2jDgR1LC1m1u47f5nuOOhJv72yHM0t3ZQXyeOmjGRS087gBfNnszRMycxbqT/TMyGM/8LrzGr1m/llvue4ffL1rBg5XoiYJ+Jo3n1kXvz0oOmcuL+U9lt9IhKh2lmg8iJoAas39LGzUtWc/29T7H4yQ0AHLLneD74sgM56/C9OGiPcW7qMathTgTDVEdngT891MT1C1dx+4PP0N4ZHLLneD525iGcefiezJ46ttIhmtkQ4UQwzDzX3MrP5j/Jj/6+kjUbW5gytpG3nTCL847dhxfsvVulwzOzIciJYJi4b/VGrv3L49y8ZDVtHQVOPmAqnzv3BZx+yO6McD9+M+uDE0GVW7hyPd/80wr++OBaxjTWc/6cGbzjxftywO7jKx2amVUJJ4Iqdc9j6/j67Q/z1xXPMWnMCP7ljIN4+4tnucePmfWbE0GVWf7MZq74/YP84YG1TBs/kk+dfShvPn4mY93X38wGKNezh6Qzga8D9cB3IuI/u30/CbgW2B9oAS6MiB6L3de6ps2tfOW2h/jf+U8ytrGBj77yYC48aTajG+srHZqZVbk8h6GuB74JnEFShGa+pLkRcX/JYp8EFkXE6yQdki7/srxiqkadheDHd6/kS7c8REt7J+948Szef/qBTB7rUTvNbNfI84rgOGBFRDwKkBageQ1QmggOA/4DICIelDRL0h4R8UyOcVWNpas28qkbl7Jk1UZOOmAKl7/mcPabNq7SYZnZMJNnIuipOP3x3ZZZDLwe+Iuk44B9SUpWdkkEtVa8vq2jwJW3L+dbd6xgyriRfP1NR3HukXv76V8zy0WeiSBLcfr/BL4uaRGwFPgHsEMR2loqXr/8mc1c9r+LuG/1Jt5w7HT+9ZzD3BPIzHKVZyIoW5w+IjaRlqhU8nP3sfRVcyKCH/19JZf/5gHGjWzg6rcey5mH71npsMysBmRKBJL2BQ6MiD9IGg00RMTmMqvNBw6UNBt4CngT8OZu250IbI2INuBi4K40OdSULa0dfOJXS5m7eDWnHTyNL77hSKaNH1npsMysRpRNBJL+iaR9fjJJN8/pwNWU6d0TER2SLgVuIek+em1E3CfpkvT7q4FDgR9I6iS5iXzRThxLVXqkqZlLfriQR5qa+egrD+Y9L93flb7MbFBluSJ4H0kPoLsBImK5pN2zbDwifgv8ttu8q0um/wYcmDnaYeavK57lkh8tpLG+jh9edDwnHTC10iGZWQ3KkghaI6Kt2GNFUgM73vS1fvrFgif5xK+Wst+0sVz7zhcxfdKYSodkZjUqSyK4U9IngdGSzgDeC9ycb1jDV0Tw1T8s58rbl/OSA6fyzbccw4RR7hVkZpWTZXzijwNNJN07/5mkqefTeQY1XEUEX/j1/Vx5+3LeOGc6177zRU4CZlZxWa4IRpPc6P02bB86YjSwNc/AhptCIfjUjcv46T1PcOFJs/nXcw71A2JmNiRkuSK4neTEXzQa+EM+4QxPhULwf69fwk/veYL3nba/k4CZDSlZrghGRURz8UNENEvync2MIoLLf3M/v1y4ig++7EA+dMZBlQ7JzKyLLFcEWyQdU/wg6VhgW34hDS/f+OMKrvvr41x40mwue3nN9pQ1syEsyxXBZcAvJBWHh9gLOD+3iIaRn9z9BF+57WHOO2Y6n36Vm4PMbGgqmwgiYn5aK+BgkoHkHoyI9twjq3LzVjzLv960jNMOnsYV573QTwub2ZCVddC5FwGz0uWPlkRE/CC3qKrcyue28N6f3Mt+U8dy5QVH01CfpQXOzKwysow19EOSMYYWAZ3p7ACcCHrQ3NrBxd9fAMB33/Eixvs5ATMb4rJcEcwBDosIDytRRkTw6RuW8khTMz+66HhmTnHnKjMb+rK0WSwDBjQwvqQzJT0kaYWkj/fw/W6Sbpa0WNJ9kt41kP0MFb9YuIobF63mspcfxIs9gJyZVYksVwRTgfsl3QO0FmdGxLl9rZSxeP37gPsj4tWSpgEPSfpxWp+gqqxYu5nP3nQfL95/Cu877YBKh2NmllmWRPC5AW47S/H6AMan1cnGAevooVTlUNfRWeBD/7uY0Y31fPX8o6h3DyEzqyJZuo/eOcBtZylefxUwl6SE5Xjg/IgodN/QUC9e/+0/P8bSpzbyzTcfwx4TRlU6HDOzfil7j0DSCZLmS2qW1CapU1KWcpJZite/kqQ30t7AUcBVkibssFLENRExJyLmTJs2LcOuB8+Ktc189Q8Pc9bhe/KqI/aqdDhmZv2W5WbxVcAFwHKSAecuTueVU7Z4PUnh+l9FYgVJ4fpDMmx7SCgUgo9dv4QxjfV84TWHVzocM7MByfSkU3qSro+Izoi4Djg1w2rbi9dLaiQpXj+32zJPkNY+lrQHydPLj2aMveJuXPQUC1eu55NnH+pi82ZWtbLcLN6ansgXSfoisAYYW26ljMXrLwe+J2kpSVPSxyLi2QEey6Bqbu3gP373IEfOmMgbjple6XDMzAYsSyJ4G8mJ/FLgQyTNPedl2XiG4vWrgVdkDXYo+cYfl9O0uZVvv32OxxEys6qWpdfQynRyG/D5fMOpDk+u28q1f3mMNxw7naNmTKx0OGZmO6XXRCDp5xHxxrTZZofhJSLiiFwjG8K+9ofl1El85BUHVzoUM7Od1tcVwQfT93MGI5BqsWJtMzf8YxUXnjSbPXfzMwNmVv16TQQRsSYdJuK7EfHyQYxpSPvqHx5m1Ih63nPq/pUOxcxsl+iz+2hEdJL0GtptkOIZ0h58ehO/WbKGC0+azZRx7i5qZsNDll5DLcBSSbcBW4ozI+IDuUU1RF1z56OMaazn4pfMrnQoZma7TJZE8Jv0VdNWb9jG3MWreduJ+zJxTGOlwzEz22WydB/9/mAEMtRd99fHCOCik301YGbDS5ZSlQcC/wEcBmzvJhMR++UY15CyqaWdn9z9BOccsRfTJ7nqmJkNL1nGGroO+G+SOgGnkdQq/mGeQQ01N9z7FFvaOrn45JrJfWZWQ7IkgtERcTugiFgZEZ8DTs83rKEjIvjJ3U9wxPTdeOF0d54ys+EnSyJokVQHLJd0qaTXAbtn2XiGmsUflbQofS1Lax1M7ucx5GrhyvU89Mxm3nzc0CuIY2a2K2RJBJcBY4APAMcCbwXeUW6lkprFZ5HcX7hA0mGly0TElyLiqIg4CvgEcGdErOvPAeTtJ3c/wbiRDbz6yL0rHYqZWS6ydB/tiIhmoJmkkExWWWoWl7oA+Gk/tp+7jVvb+fXSNbxxznTGjszyn8rMrPpkuSL4iqQHJV0u6QX92HZPNYv36WlBSWOAM4Hr+7H93P3+vjW0dRT4P8fOKL+wmVmVKpsIIuI0kopkTcA1kpZK+nSGbWepWVz0auCvvTULSXq3pAWSFjQ1NWXY9a5x06LVzJoyhiN8k9jMhrGspSqfjogrgUtIis1/JsNqWWoWF72JPpqFKlG8fu2mFv726HOce9Q+SC48Y2bDV9lEIOlQSZ+TtIykaP08kpN6OVlqFpMOaPdS4KZ+RZ6zm5esIQLO9U1iMxvmstwBvY7k1/or0tKSmWSsWQzwOuDWiNjSy6YqYu7i1bxg7wkcsPu4SodiZparLGMNnTDQjZerWZx+/h7wvYHuIw9Pb2xh8ZMb+OgrXYHMzIa/TPcIas3tDz4DwBmH7VHhSMzM8udE0IPbH1jLzMljONDNQmZWA5wIutna1sFfVjzLyw7d3b2FzKwm9HqPQNLN9N7vn4g4N5eIKuwvy5+lraPAGYe6WcjMakNfN4u/nL6/HtgT+FH6+QLg8Rxjqqg/PbSW8SMbeNHsITX2nZlZbnpNBBFxJ4CkyyPilJKvbpZ0V+6RVci8R57j+P2mMKLerWZmVhuynO2mSdpekUXSbGBwHu8dZKvWb2Xlc1t58f5TKh2KmdmgyfJA2YeAOyQ9mn6eBfxzbhFV0LxHngPgpAOmVjgSM7PBk+WBst+ndYsPSWc9GBGt+YZVGfNWPMvUcY0ctIe7jZpZ7cgy1tAY4KPApRGxGJgp6ZzcIxtkEcG8R57jxP2nutuomdWUrMXr24AT08+rgP+XW0QVsmr9NtZubuV49xYysxqTJRHsHxFfBNoBImIbPdcaqGr3PrEegGNmTqpwJGZmgytLImiTNJr04TJJ+wOZ7hGUK16fLnNqWrz+Pkl3Zo58F/vHExsY01jv+wNmVnOy9Br6LPB7YIakHwMnAe8st1JJ8fozSJqT5kuaGxH3lywzEfgWcGZEPCFp934fwS7yjyc3cMT03Wjw8wNmVmOy9Bq6TdK9wAkkTUIfjIhnM2w7S/H6NwO/iogn0n2t7Wf8u0RLeyf3r97IxS/Zr/zCZmbDTNafv6OA9cAm4DBJp5RZHrIVrz8ImCTpDkkLJb29pw3lXbP4vtWbaO8Mjp4xcZdv28xsqCt7RSDpCuB84D6gkM4OoNwwE1mK1zcAxwIvA0YDf5P094h4uMtKEdcA1wDMmTOn14HwBmrxkxsAOMqJwMxqUJZ7BK8FDh7AQ2RZitevAp5Ny1RuSccwOhJ4mEF0/5pNTB03kt0njBrM3ZqZDQlZmoYeBUYMYNtZitffBLxEUkP64NrxwAMD2NdOeWDNJg7da/xg79bMbEjIckWwFVgk6XZKuo1GxAf6WilL8fqIeEDS74ElJM1O34mIZQM8lgFp7yyw/Jlm3nXSrMHcrZnZkJElEcxlx1/ymWQsXv8l4EsD2f6u8GjTFto6Cxy614RKhWBmVlFZuo9+fzACqZQH1mwC4BA3DZlZjeqrVOXPI+KNkpbSQ8nKiDgi18gGyQNPb6Kxvo79p/mJYjOrTX1dEXwwfR92I42WWv5MM/tNG+uKZGZWs/oqVbkmfV85eOEMvkebmnnB3rtVOgwzs4rJUo/gBEnzJTVLapPUKWnTYASXt7aOAk+u38bsqWMrHYqZWcVkaQ+5CrgAWE7y9O/FwDfyDGqwPLFuK52FYL9pTgRmVruydB8lIlZIqo+ITuA6SfNyjmtQPPbsFgBfEZhZTcv0QFn6ZPAiSV8E1gDD4sz5aFMzAPtNdY8hM6tdWZqG3kbyZPClwBaS8YPOyzOowfJo0xamjG1ktzEDGUHDzGx4yPJAWbHX0Dbg8/mGM7gee26Lm4XMrOb19UBZjw+SFQ2HB8qeWr+N41ys3sxqXF9XBMP6QbKOzgJPb2phn4mjKx2KmVlF9XqPICJWFl8ko44eCRwBtGZ9yKxc8fq0cP3GtHj9IkmfGeiB9NfTm1roLAT7THIiMLPaluWBsouBe4DXA28A/i7pwgzrFYvXnwUcBlwg6bAeFv1zRByVvr7Qr+h3wlPrtwH4isDMal6W7qMfBY6OiOcAJE0B5gHXllkvS/H6ilm9MU0EviIwsxqXpfvoKmBzyefNdC1K35ssxesBTpS0WNLvJL2gpw3lUby+eEWw925OBGZW27JcETwF3C3pJpJeRK8B7pH0YYCI+Eov62UpXn8vsG9ENEs6G7gROHCHlXIoXv/Uhm1MGdvI6Mb6XbE5M7OqleWK4BGSE3TxBHwTydPF49NXb8oWr4+ITRHRnE7/FhghaWqmyHfSUxta3CxkZka2K4IrIqKldIakqRHxbJn1thevJ7mqeBPw5m7b2RN4JiJC0nEkiem5zNHvhLWbWpgxecxg7MrMbEjLckVwj6QTih8knUdys7hPEdFBMizFLcADwM+LxeuLBexJeiEtk7QYuBJ4U0Tskqafcpo2tzJt/MjB2JWZ2ZCW5YrgLcC1ku4A9gamAKdn2Xi54vURcRXJMNeDqr2zwLqtbUwb50RgZpZlrKGlkv4N+CFJj6FTImJV7pHlaN2WNiJg9wlOBGZmZROBpO8C+5M8VXwQcLOkqyLim3kHl5e1m1oBfEVgZka2ewTLgNMi4rGIuAU4ATgm37Dy1dSc3Pv2PQIzswyJICK+CsyU9PJ0VhtwWZ5B5a1pc3pF4ERgZpZprKF/An4J/E86azrJcwVVq5gIprppyMwsU9PQ+4CTgE0AEbEc2D3PoPLWtLmVCaMaGDXCTxWbmWVJBK0R0Vb8IKmBPgrWVIOm5lamulnIzAzIlgjulPRJYLSkM4BfADfnG1a+1m1pY+pYJwIzM8iWCD4ONAFLgX8meUDs03kGlbcNW9tdsN7MLJXlgbIC8O30NSys39rGEdN3q3QYZmZDQpYrgmFnw9Z2Jo1prHQYZmZDQs0lgm1tnbR2FNw0ZGaWypwIJI3t78bLFa8vWe5FkjolvaG/++iv9VuTDlC+IjAzS2R5oOzFku4nGUoaSUdK+laG9TIVr0+Xu4JkuOrcbdjaDsDE0b4iMDODbFcEXwVeSVowJiIWA6dkWG978fr0OYRi8fru3g9cD6zNFPFO2pBeEUz0FYGZGZCxaSgiuher78ywWtni9ZL2AV4HXE0fdmXx+g3bkiuCSWN9RWBmBtkSwZOSXgyEpEZJHyFtJiojS/H6rwEfi4g+E0tEXBMRcyJizrRp0zLsunfFewQTR/uKwMwMslUouwT4Osmv+VXArSTjD5VTtng9MAf4mSSAqcDZkjoi4sYM2x+Q7fcI3GvIzAzIlggUEW8ZwLbLFq+PiNnbdyJ9D/h1nkkAYOO2dkaNqPOAc2ZmqSxNQ/Mk3SrpIkkTs244Y/H6Qbe5pYPxo3w1YGZWlGWIiQMlHUfyi/5TaVfSn0XEjzKs22fx+m7z35kp4p3U3NrBuJFZLoTMzGpD1l5D90TEh0m6hK4Dvp9rVDna0trB2JFuFjIzK8ryQNkESe+Q9DtgHrCGJCFUpeYWXxGYmZXKckZcTFKa8gsR8bd8w8lfc2sHe08cVekwzMyGjCyJYL+IqOqKZKV8j8DMrKtez4iSvhYRlwFzJe2QCCLi3DwDy0tyj8CJwMysqK8z4g/T9y8PRiCDZbOvCMzMuuj1jBgRC9PJoyLi66XfSfogcGeegeWhraNAW0fBicDMrESW7qPv6GHeO3dxHINiS2sHgJuGzMxK9HWP4AKSISFmS5pb8tV40iGpq01zmgjGjXIiMDMr6uuMWHxmYCrwXyXzNwNL8gwqL1va0kTgKwIzs+36ukewElgJnDh44eRrS2sy2vXoRj9ZbGZWlOXJ4hMkzZfULKktrS28aTCC29Va29NE4JFHzcy2y3Kz+CrgAmA5MBq4GPhGlo2XK14v6TWSlkhalFYgO7k/wfdXS0eSCDwEtZnZ8zI1lkfECkn1aSWx6yTNK7dOSfH6M0iK1MyXNDci7i9Z7HZgbkSEpCOAnwOH9PsoMmppLwAwakSmsfbMzGpClkSwVVIjsEjSF0luII/NsN724vUAkorF67cngohoLll+LDuWstyltrWlVwQNviIwMyvK8tP4bUA9SZGZLSTlJ8/LsF7Z4vUAkl4n6UHgN8CFPW1oVxWvd9OQmdmOshSmWZlObgM+349tZyleT0TcANwg6RTgcuDlPSxzDXANwJw5cwZ81eCmITOzHfX1QNlS+miqiYgjymw7S/H60u3dJWl/SVMj4tky2x6QlnZfEZiZddfXFcE5O7ntssXrJR0APJLeLD4GaCTHp5Zb2zuRYGSDrwjMzIrKPVA2YBHRIalYvL4euLZYvD79/mqSew1vl9RO0vR0fp61D1o6CoxsqEPqqdXKzKw2lb1HIGkzzzcRNQIjgC0RMaHcuuWK10fEFcAV/Ql4Z7S0d7pZyMysmyw3i8eXfpb0Wqq0ZnFLe6e7jpqZddPvxvKIuBE4fdeHkr9t7QX3GDIz6yZL09DrSz7WAXPI+cGvvLhpyMxsR1meLH51yXQH8DjJE8JVp7WjwEgnAjOzLrLcI3jXYAQyGNo7CjTWu8eQmVmpLE1Ds4H3A7NKl4+Ic/MLKx/tnQUa/QyBmVkXWZqGbgS+C9wMFHKNJmfthWBMvROBmVmpLImgJSKuzD2SQeCmITOzHWVJBF+X9FngVqC1ODMi7s0tqpx0FAo01PmKwMysVJZE8EKSoahP5/mmoaAKnyVo7wxG+B6BmVkXWRLB64D9IqIt72Dy1t5ZYESdm4bMzEpl+Xm8GJg4kI1nqFn8lrRm8RJJ8yQdOZD9ZNXeWWCEbxabmXWR5YpgD+BBSfPpeo+gz+6jGWsWPwa8NCLWSzqLpPjM8f08hsw6OoMG3yw2M+siSyL47AC3naVm8byS5f9OUrwmN22+IjAz20GWJ4vvHOC2e6pZ3Nev/YuA3w1wX5l0dAYjfEVgZtZFnvUIMtUsTvdxGkkiOLmX798NvBtg5syZ5ULule8RmJntKM96BJlqFks6AvgOcFZE9FimclcUr48IOgpBgxOBmVkXedYj2F6zWFIjSc3iuaULSJoJ/Ap4W0Q83N9Y+qO9M8kffrLYzKyr3OoRZKxZ/BlgCvCttI5wR0TM6fdRZNBRSJ6F8xWBmVlXudYjyFCz+GLg4izb2lntHUnu8j0CM7OuaqYeQXt6ReBeQ2ZmXZX9eSzp+5ImlnyeJOnaXKPKQUd6j6DeQ0yYmXWRpZ3kiIjYUPwQEeuBo3OLKCeFSBOBnAjMzEplSQR1kiYVP0iaTLZ7C0NKMRHU+YrAzKyLLCf0/wLmSfolSW+hNwL/lmtUOUhvEVDnKwIzsy6y3Cz+gaQFJM8OCHh9t4HjqsL2piF3GjIz6yJTE0964q+6k3+pzmLTkK8IzMy6qJnfx+FEYGbWo5pJBJ2+R2Bm1qOaSQTbew05D5iZdVF7icCZwMysi9pJBG4aMjPrUa6JIEPx+kMk/U1Sq6SP5BmLu4+amfUstyeEMxavXwd8AHhtXnEUFbuPylcEZmZd5Pn7eHvx+ohoA4rF67eLiLURMR9ozzGO4r4AjzVkZtZdnomgp+L1+wxkQ5LeLWmBpAVNTU0DCsbdR83MepZnIshcvL6ciLgmIuZExJxp06YNKJjnew0NaHUzs2Erz9NipuL1g6XgJ4vNzHqUZyIoW7x+MLn7qJlZz3LrNZSleL2kPYEFwASgIOky4LCI2LSr43H3UTOznuVaYCZD8fqnSZqMcufuo2ZmPauZ38fuPmpm1rOaSQTuPmpm1rOaSQTuPmpm1rOaOS26MI2ZWc9qJhG4acjMrGc1kwj23G0kr3rhXkwYnWtHKTOzqlMzZ8Vj953MsftOrnQYZmZDTs1cEZiZWc+cCMzMapwTgZlZjXMiMDOrcU4EZmY1zonAzKzGORGYmdU4JwIzsxqn4hg81UJSE7BygKtPBZ7dheEMpmqOHao7fsdeGY5919o3Inos+l51iWBnSFoQEXMqHcdAVHPsUN3xO/bKcOyDx01DZmY1zonAzKzG1VoiuKbSAeyEao4dqjt+x14Zjn2Q1NQ9AjMz21GtXRGYmVk3TgRmZjWuZhKBpDMlPSRphaSPVzoeAEnXSloraVnJvMmSbpO0PH2fVPLdJ9L4H5L0ypL5x0pamn53pZR/PU5JMyT9SdIDku6T9MFqiV/SKEn3SFqcxv75aok93We9pH9I+nU1xZ3u9/F0v4skLaim+CVNlPRLSQ+mf/cnVkvsZUXEsH8B9cAjwH5AI7AYOGwIxHUKcAywrGTeF4GPp9MfB65Ipw9L4x4JzE6Ppz797h7gREDA74CzBiH2vYBj0unxwMNpjEM+/nQ/49LpEcDdwAnVEHu6zw8DPwF+XU1/M+l+HwemdptXFfED3wcuTqcbgYnVEnvZY6t0AIP0x3cicEvJ508An6h0XGkss+iaCB4C9kqn9wIe6ilm4Jb0uPYCHiyZfwHwPxU4jpuAM6otfmAMcC9wfDXEDkwHbgdO5/lEMOTjLtnX4+yYCIZ8/MAE4DHSDjbVFHuWV600De0DPFnyeVU6byjaIyLWAKTvu6fzezuGfdLp7vMHjaRZwNEkv6yrIv60eWURsBa4LSKqJfavAf8XKJTMq4a4iwK4VdJCSe9O51VD/PsBTcB1abPcdySNrZLYy6qVRNBTG1y19Zvt7RgqemySxgHXA5dFxKa+Fu1hXsXij4jOiDiK5Bf2cZIO72PxIRG7pHOAtRGxMOsqPcyr9N/MSRFxDHAW8D5Jp/Sx7FCKv4GkGfe/I+JoYAtJU1BvhlLsZdVKIlgFzCj5PB1YXaFYynlG0l4A6fvadH5vx7Aqne4+P3eSRpAkgR9HxK/S2VUTP0BEbADuAM5k6Md+EnCupMeBnwGnS/pRFcS9XUSsTt/XAjcAx1Ed8a8CVqVXjgC/JEkM1RB7WbWSCOYDB0qaLakReBMwt8Ix9WYu8I50+h0kbe/F+W+SNFLSbOBA4J70cnSzpBPS3gdvL1knN+m+vgs8EBFfqab4JU2TNDGdHg28HHhwqMceEZ+IiOkRMYvkb/iPEfHWoR53kaSxksYXp4FXAMuqIf6IeBp4UtLB6ayXAfdXQ+yZVPomxWC9gLNJerY8Anyq0vGkMf0UWAO0k/xSuAiYQnIzcHn6Prlk+U+l8T9ESU8DYA7JP6hHgKvodkMrp9hPJrmkXQIsSl9nV0P8wBHAP9LYlwGfSecP+dhL9nsqz98sroq4SdrZF6ev+4r/Dqso/qOABenfzY3ApGqJvdzLQ0yYmdW4WmkaMjOzXjgRmJnVOCcCM7Ma50RgZlbjnAjMzGqcE4FVPUl3SMq9ULikD6SjTv44731VUjrK5nsrHYcNHicCq2mSGvqx+HuBsyPiLXnFM0RMJDlWqxFOBDYoJM1Kf01/W0kNgFvTp3q7/KKXNDUdQgFJ75R0o6SbJT0m6VJJH04H/fq7pMklu3irpHmSlkk6Ll1/rJKaD/PTdV5Tst1fSLoZuLWHWD+cbmeZpMvSeVeTPBA1V9KHui1fL+nL6RjzSyS9P53/snS/S9M4RqbzH5f075L+JmmBpGMk3SLpEUmXpMucKukuSTdIul/S1ZLq0u8uSLe5TNIVJXE0S/o3JXUW/i5pj3T+NEnXp/8d5ks6KZ3/uTSuOyQ9KukD6ab+E9hfSc2AL0naK41lUbrPlwz078CGqEo/0eZXbbxIhtvuAI5KP/8ceGs6fQcwJ52eCjyeTr8TWEFS72AasBG4JP3uqyQD3RXX/3Y6fQrpsN7Av5fsYyLJk+Vj0+2uouQp0JI4jwWWpsuNI3kC9uj0u8fpNoRyOv89JGMuNaSfJwOjSEafPCid94OSeB8H3lNyHEtKjnFtOv9UoIUk+dQDtwFvAPYGnkiXbQD+CLw2XSeAV6fTXwQ+nU7/BDg5nZ5JMiwIwOeAeSRj5k8FniOpzzCLrkOj/wvPPwVcD4yv9N+TX7v21Z/LYrOd9VhELEqnF5KccMr5U0RsJhmfZSNwczp/KclQEUU/BYiIuyRNSMcSegXJIG0fSZcZRXIihGTo6XU97O9k4IaI2AIg6VfAS0iGpOjNy4GrI6IjjWGdpCPT4304Xeb7wPtIhpGG58e6WkpSJKd4jC3FcZBIxqZ5NI3jp2ls7cAdEdGUzv8xSfK7EWgDfp2uu5CkPkQxvsP0fCGsCcUxf4DfREQr0CppLbBHD8c3H7hWySCDN5b8P7RhwonABlNryXQnMDqd7uD5ZspRfaxTKPlcoOvfb/exUopD/p4XEQ+VfiHpeJJhhHsykLKB6mH/5bZTehzdj7F4XL0dU2/aI6K4TmfJduqAEyNiW5cAk8TQ/f/JDueENLmeArwK+KGkL0XED/qIw6qM7xHYUPA4SZMMJM0fA3E+gKSTgY0RsZGkKtT701EekXR0hu3cBbxW0hglI2S+DvhzmXVuBS4p3nhO7108CMySdEC6zNuAO/t5TMcpGTG3juT4/kJS/Oel6b2UepIKV+W2eytwafGDpKPKLL+ZpKmquPy+JE1W3yYZcfaYfh6HDXG+IrCh4MvAzyW9jaTNeyDWS5pHUlLwwnTe5SRNMUvSZPA4cE5fG4mIeyV9j6SuLMB3IqKvZiGA7wAHpftpJ7lfcZWkdwG/SBPEfODqfh7T30hu3L6QJEHdEBEFSZ8A/kRydfDbiCg3jPEHgG9KWkLyb/4u4JLeFo6I5yT9VdIykpq6y4CPpsfWTDJ0sg0jHn3UbAiSdCrwkYjoM3GZ7QpuGjIzq3G+IjAzq3G+IjAzq3FOBGZmNc6JwMysxjkRmJnVOCcCM7Ma9/8BksV048sCtmUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kpca = KernelPCA(kernel = 'rbf')\n",
    "kpca_transform = kpca.fit_transform(X_Train_FeatureMap)\n",
    "explained_variance = np.var(kpca_transform, axis=0)\n",
    "explained_variance_ratio = explained_variance / np.sum(explained_variance)\n",
    "plt.yticks([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.plot(np.cumsum(explained_variance_ratio))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6470, 5000)\n"
     ]
    }
   ],
   "source": [
    "kpca = KernelPCA(kernel = 'rbf',n_components=5000)\n",
    "X_Train_Transformed_FeatureMap = kpca.fit_transform(X_Train_FeatureMap)\n",
    "print(X_Train_Transformed_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1618, 18432) (1618, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_Test_Transformed_FeatureMap = kpca.transform(X_Test_FeatureMap)\n",
    "\n",
    "print(X_Test_FeatureMap.shape,X_Test_Transformed_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5; 1/2] START C=10, gamma=10, kernel=rbf..................................\n",
      "[CV 1/5; 1/2] END ...C=10, gamma=10, kernel=rbf;, score=0.904 total time= 1.2min\n",
      "[CV 2/5; 1/2] START C=10, gamma=10, kernel=rbf..................................\n",
      "[CV 2/5; 1/2] END ...C=10, gamma=10, kernel=rbf;, score=0.913 total time= 1.5min\n",
      "[CV 3/5; 1/2] START C=10, gamma=10, kernel=rbf..................................\n",
      "[CV 3/5; 1/2] END ...C=10, gamma=10, kernel=rbf;, score=0.906 total time= 1.2min\n",
      "[CV 4/5; 1/2] START C=10, gamma=10, kernel=rbf..................................\n",
      "[CV 4/5; 1/2] END ...C=10, gamma=10, kernel=rbf;, score=0.911 total time= 1.4min\n",
      "[CV 5/5; 1/2] START C=10, gamma=10, kernel=rbf..................................\n",
      "[CV 5/5; 1/2] END ...C=10, gamma=10, kernel=rbf;, score=0.914 total time= 1.4min\n",
      "[CV 1/5; 2/2] START C=10, gamma=100, kernel=rbf.................................\n",
      "[CV 1/5; 2/2] END ..C=10, gamma=100, kernel=rbf;, score=0.903 total time= 2.6min\n",
      "[CV 2/5; 2/2] START C=10, gamma=100, kernel=rbf.................................\n",
      "[CV 2/5; 2/2] END ..C=10, gamma=100, kernel=rbf;, score=0.917 total time= 2.5min\n",
      "[CV 3/5; 2/2] START C=10, gamma=100, kernel=rbf.................................\n",
      "[CV 3/5; 2/2] END ..C=10, gamma=100, kernel=rbf;, score=0.912 total time= 2.6min\n",
      "[CV 4/5; 2/2] START C=10, gamma=100, kernel=rbf.................................\n",
      "[CV 4/5; 2/2] END ..C=10, gamma=100, kernel=rbf;, score=0.909 total time= 2.8min\n",
      "[CV 5/5; 2/2] START C=10, gamma=100, kernel=rbf.................................\n",
      "[CV 5/5; 2/2] END ..C=10, gamma=100, kernel=rbf;, score=0.919 total time= 2.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [10], 'gamma': [10, 100], 'kernel': ['rbf']},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% notify -m \"GridCV\"\n",
    "tuned_parameters = {'kernel': ['rbf'], 'gamma': [10,100],\n",
    "                     'C': [10],\n",
    "}\n",
    "clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring= 'accuracy',verbose=10\n",
    "    )\n",
    "clf.fit(X_Train_Transformed_FeatureMap, Y_Train_FeatureMap.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 47.68160741885626\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 49.84544049459041\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 50.23183925811438\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 48.76352395672334\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 48.29984544049459\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 47.68160741885626 %\n",
      "Fold 1: 49.84544049459041 %\n",
      "Fold 2: 50.23183925811438 %\n",
      "Fold 3: 48.76352395672334 %\n",
      "Fold 4: 48.29984544049459 %\n",
      "Average: 48.964451313755795 %\n",
      "Accuracy:  0.5055624227441285\n",
      "Precision:  0.5055624227441285\n",
      "Recall:  1.0\n",
      "F1-Score:  0.671592775041051\n",
      "AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_svm(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "y_pred=clf.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 77.58887171561051\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 76.50695517774344\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 76.42967542503864\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 78.20710973724884\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 78.516228748068\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 77.58887171561051 %\n",
      "Fold 1: 76.50695517774344 %\n",
      "Fold 2: 76.42967542503864 %\n",
      "Fold 3: 78.20710973724884 %\n",
      "Fold 4: 78.516228748068 %\n",
      "Average: 77.44976816074188 %\n",
      "Accuracy:  0.565512978986403\n",
      "Precision:  0.5897035881435257\n",
      "Recall:  0.4621026894865526\n",
      "F1-Score:  0.5181631254283756\n",
      "AUC:  0.5666763447432763\n"
     ]
    }
   ],
   "source": [
    "dtree=k_fold_cv_dtree(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "y_pred=dtree.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "[17:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 88.79443585780525\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "[17:15:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 88.79443585780525\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "[17:18:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 88.87171561051005\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "[17:21:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 88.94899536321483\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "[17:24:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 89.41267387944359\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 88.79443585780525 %\n",
      "Fold 1: 88.79443585780525 %\n",
      "Fold 2: 88.87171561051005 %\n",
      "Fold 3: 88.94899536321483 %\n",
      "Fold 4: 89.41267387944359 %\n",
      "Average: 88.96445131375579 %\n",
      "Accuracy:  0.8776266996291718\n",
      "Precision:  0.8579676674364896\n",
      "Recall:  0.9083129584352079\n",
      "F1-Score:  0.8824228028503563\n",
      "AUC:  0.8772814792176038\n"
     ]
    }
   ],
   "source": [
    "xg=k_fold_cv_xgb(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "y_pred=xg.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69496691\n",
      "Iteration 2, loss = 0.68602978\n",
      "Iteration 3, loss = 0.67716084\n",
      "Iteration 4, loss = 0.66475774\n",
      "Iteration 5, loss = 0.64840574\n",
      "Iteration 6, loss = 0.62808971\n",
      "Iteration 7, loss = 0.60389605\n",
      "Iteration 8, loss = 0.57705726\n",
      "Iteration 9, loss = 0.54799314\n",
      "Iteration 10, loss = 0.51792518\n",
      "Iteration 11, loss = 0.48727857\n",
      "Iteration 12, loss = 0.45707695\n",
      "Iteration 13, loss = 0.42853071\n",
      "Iteration 14, loss = 0.40154187\n",
      "Iteration 15, loss = 0.37638929\n",
      "Iteration 16, loss = 0.35343965\n",
      "Iteration 17, loss = 0.33240787\n",
      "Iteration 18, loss = 0.31387806\n",
      "Iteration 19, loss = 0.29616926\n",
      "Iteration 20, loss = 0.28072252\n",
      "Iteration 21, loss = 0.26651704\n",
      "Iteration 22, loss = 0.25371662\n",
      "Iteration 23, loss = 0.24221590\n",
      "Iteration 24, loss = 0.23133449\n",
      "Iteration 25, loss = 0.22148709\n",
      "Iteration 26, loss = 0.21261788\n",
      "Iteration 27, loss = 0.20434503\n",
      "Iteration 28, loss = 0.19664487\n",
      "Iteration 29, loss = 0.18957304\n",
      "Iteration 30, loss = 0.18396195\n",
      "Iteration 31, loss = 0.17738687\n",
      "Iteration 32, loss = 0.17134785\n",
      "Iteration 33, loss = 0.16639111\n",
      "Iteration 34, loss = 0.16143647\n",
      "Iteration 35, loss = 0.15690977\n",
      "Iteration 36, loss = 0.15193507\n",
      "Iteration 37, loss = 0.14785164\n",
      "Iteration 38, loss = 0.14362666\n",
      "Iteration 39, loss = 0.14009721\n",
      "Iteration 40, loss = 0.13619999\n",
      "Iteration 41, loss = 0.13306057\n",
      "Iteration 42, loss = 0.12969173\n",
      "Iteration 43, loss = 0.12645147\n",
      "Iteration 44, loss = 0.12354282\n",
      "Iteration 45, loss = 0.12047233\n",
      "Iteration 46, loss = 0.11793990\n",
      "Iteration 47, loss = 0.11520790\n",
      "Iteration 48, loss = 0.11272383\n",
      "Iteration 49, loss = 0.11012588\n",
      "Iteration 50, loss = 0.10811547\n",
      "Iteration 51, loss = 0.10550442\n",
      "Iteration 52, loss = 0.10343186\n",
      "Iteration 53, loss = 0.10168248\n",
      "Iteration 54, loss = 0.09978778\n",
      "Iteration 55, loss = 0.09750758\n",
      "Iteration 56, loss = 0.09559386\n",
      "Iteration 57, loss = 0.09361867\n",
      "Iteration 58, loss = 0.09205690\n",
      "Iteration 59, loss = 0.09018068\n",
      "Iteration 60, loss = 0.08855973\n",
      "Iteration 61, loss = 0.08695381\n",
      "Iteration 62, loss = 0.08543929\n",
      "Iteration 63, loss = 0.08404013\n",
      "Iteration 64, loss = 0.08258806\n",
      "Iteration 65, loss = 0.08098633\n",
      "Iteration 66, loss = 0.07978699\n",
      "Iteration 67, loss = 0.07822560\n",
      "Iteration 68, loss = 0.07727074\n",
      "Iteration 69, loss = 0.07577386\n",
      "Iteration 70, loss = 0.07499211\n",
      "Iteration 71, loss = 0.07344427\n",
      "Iteration 72, loss = 0.07232112\n",
      "Iteration 73, loss = 0.07115925\n",
      "Iteration 74, loss = 0.07017817\n",
      "Iteration 75, loss = 0.06899794\n",
      "Iteration 76, loss = 0.06810758\n",
      "Iteration 77, loss = 0.06721021\n",
      "Iteration 78, loss = 0.06630196\n",
      "Iteration 79, loss = 0.06525593\n",
      "Iteration 80, loss = 0.06436416\n",
      "Iteration 81, loss = 0.06331372\n",
      "Iteration 82, loss = 0.06262807\n",
      "Iteration 83, loss = 0.06184823\n",
      "Iteration 84, loss = 0.06083920\n",
      "Iteration 85, loss = 0.06010879\n",
      "Iteration 86, loss = 0.05935855\n",
      "Iteration 87, loss = 0.05866705\n",
      "Iteration 88, loss = 0.05781572\n",
      "Iteration 89, loss = 0.05710074\n",
      "Iteration 90, loss = 0.05657704\n",
      "Iteration 91, loss = 0.05600981\n",
      "Iteration 92, loss = 0.05503289\n",
      "Iteration 93, loss = 0.05441127\n",
      "Iteration 94, loss = 0.05383787\n",
      "Iteration 95, loss = 0.05320792\n",
      "Iteration 96, loss = 0.05252961\n",
      "Iteration 97, loss = 0.05187281\n",
      "Iteration 98, loss = 0.05157960\n",
      "Iteration 99, loss = 0.05110870\n",
      "Iteration 100, loss = 0.05021478\n",
      "Iteration 101, loss = 0.04972676\n",
      "Iteration 102, loss = 0.04921741\n",
      "Iteration 103, loss = 0.04853472\n",
      "Iteration 104, loss = 0.04861278\n",
      "Iteration 105, loss = 0.04769228\n",
      "Iteration 106, loss = 0.04708052\n",
      "Iteration 107, loss = 0.04666183\n",
      "Iteration 108, loss = 0.04612850\n",
      "Iteration 109, loss = 0.04567917\n",
      "Iteration 110, loss = 0.04531434\n",
      "Iteration 111, loss = 0.04475582\n",
      "Iteration 112, loss = 0.04437762\n",
      "Iteration 113, loss = 0.04399242\n",
      "Iteration 114, loss = 0.04362755\n",
      "Iteration 115, loss = 0.04314919\n",
      "Iteration 116, loss = 0.04275406\n",
      "Iteration 117, loss = 0.04256650\n",
      "Iteration 118, loss = 0.04207851\n",
      "Iteration 119, loss = 0.04158656\n",
      "Iteration 120, loss = 0.04108632\n",
      "Iteration 121, loss = 0.04081159\n",
      "Iteration 122, loss = 0.04049867\n",
      "Iteration 123, loss = 0.04021161\n",
      "Iteration 124, loss = 0.03974556\n",
      "Iteration 125, loss = 0.03943481\n",
      "Iteration 126, loss = 0.03916209\n",
      "Iteration 127, loss = 0.03880297\n",
      "Iteration 128, loss = 0.03846090\n",
      "Iteration 129, loss = 0.03805851\n",
      "Iteration 130, loss = 0.03778058\n",
      "Iteration 131, loss = 0.03755565\n",
      "Iteration 132, loss = 0.03721112\n",
      "Iteration 133, loss = 0.03686309\n",
      "Iteration 134, loss = 0.03664091\n",
      "Iteration 135, loss = 0.03637835\n",
      "Iteration 136, loss = 0.03607424\n",
      "Iteration 137, loss = 0.03587549\n",
      "Iteration 138, loss = 0.03544797\n",
      "Iteration 139, loss = 0.03532364\n",
      "Iteration 140, loss = 0.03489102\n",
      "Iteration 141, loss = 0.03466808\n",
      "Iteration 142, loss = 0.03442885\n",
      "Iteration 143, loss = 0.03423387\n",
      "Iteration 144, loss = 0.03398075\n",
      "Iteration 145, loss = 0.03365374\n",
      "Iteration 146, loss = 0.03349727\n",
      "Iteration 147, loss = 0.03325597\n",
      "Iteration 148, loss = 0.03297979\n",
      "Iteration 149, loss = 0.03284752\n",
      "Iteration 150, loss = 0.03258935\n",
      "Iteration 151, loss = 0.03233742\n",
      "Iteration 152, loss = 0.03211088\n",
      "Iteration 153, loss = 0.03210803\n",
      "Iteration 154, loss = 0.03162507\n",
      "Iteration 155, loss = 0.03167608\n",
      "Iteration 156, loss = 0.03125548\n",
      "Iteration 157, loss = 0.03102265\n",
      "Iteration 158, loss = 0.03081380\n",
      "Iteration 159, loss = 0.03060982\n",
      "Iteration 160, loss = 0.03056789\n",
      "Iteration 161, loss = 0.03031496\n",
      "Iteration 162, loss = 0.03004301\n",
      "Iteration 163, loss = 0.02991392\n",
      "Iteration 164, loss = 0.02975305\n",
      "Iteration 165, loss = 0.02981278\n",
      "Iteration 166, loss = 0.02948767\n",
      "Iteration 167, loss = 0.02934616\n",
      "Iteration 168, loss = 0.02895069\n",
      "Iteration 169, loss = 0.02887389\n",
      "Iteration 170, loss = 0.02861483\n",
      "Iteration 171, loss = 0.02841625\n",
      "Iteration 172, loss = 0.02833038\n",
      "Iteration 173, loss = 0.02817122\n",
      "Iteration 174, loss = 0.02795101\n",
      "Iteration 175, loss = 0.02779466\n",
      "Iteration 176, loss = 0.02776629\n",
      "Iteration 177, loss = 0.02750334\n",
      "Iteration 178, loss = 0.02731899\n",
      "Iteration 179, loss = 0.02718670\n",
      "Iteration 180, loss = 0.02703698\n",
      "Iteration 181, loss = 0.02685608\n",
      "Iteration 182, loss = 0.02671052\n",
      "Iteration 183, loss = 0.02657119\n",
      "Iteration 184, loss = 0.02648148\n",
      "Iteration 185, loss = 0.02636471\n",
      "Iteration 186, loss = 0.02624691\n",
      "Iteration 187, loss = 0.02612239\n",
      "Iteration 188, loss = 0.02589625\n",
      "Iteration 189, loss = 0.02573725\n",
      "Iteration 190, loss = 0.02561214\n",
      "Iteration 191, loss = 0.02553539\n",
      "Iteration 192, loss = 0.02537626\n",
      "Iteration 193, loss = 0.02524129\n",
      "Iteration 194, loss = 0.02504867\n",
      "Iteration 195, loss = 0.02505978\n",
      "Iteration 196, loss = 0.02487447\n",
      "Iteration 197, loss = 0.02476258\n",
      "Iteration 198, loss = 0.02457550\n",
      "Iteration 199, loss = 0.02437401\n",
      "Iteration 200, loss = 0.02446284\n",
      "Iteration 201, loss = 0.02419992\n",
      "Iteration 202, loss = 0.02412003\n",
      "Iteration 203, loss = 0.02405520\n",
      "Iteration 204, loss = 0.02416658\n",
      "Iteration 205, loss = 0.02369229\n",
      "Iteration 206, loss = 0.02366281\n",
      "Iteration 207, loss = 0.02350787\n",
      "Iteration 208, loss = 0.02334198\n",
      "Iteration 209, loss = 0.02321354\n",
      "Iteration 210, loss = 0.02312265\n",
      "Iteration 211, loss = 0.02301353\n",
      "Iteration 212, loss = 0.02303891\n",
      "Iteration 213, loss = 0.02275509\n",
      "Iteration 214, loss = 0.02297333\n",
      "Iteration 215, loss = 0.02261388\n",
      "Iteration 216, loss = 0.02254960\n",
      "Iteration 217, loss = 0.02237918\n",
      "Iteration 218, loss = 0.02235082\n",
      "Iteration 219, loss = 0.02213812\n",
      "Iteration 220, loss = 0.02207281\n",
      "Iteration 221, loss = 0.02193776\n",
      "Iteration 222, loss = 0.02211526\n",
      "Iteration 223, loss = 0.02176789\n",
      "Iteration 224, loss = 0.02184545\n",
      "Iteration 225, loss = 0.02158838\n",
      "Iteration 226, loss = 0.02144296\n",
      "Iteration 227, loss = 0.02137724\n",
      "Iteration 228, loss = 0.02123799\n",
      "Iteration 229, loss = 0.02111518\n",
      "Iteration 230, loss = 0.02106453\n",
      "Iteration 231, loss = 0.02112363\n",
      "Iteration 232, loss = 0.02084085\n",
      "Iteration 233, loss = 0.02077330\n",
      "Iteration 234, loss = 0.02074141\n",
      "Iteration 235, loss = 0.02055867\n",
      "Iteration 236, loss = 0.02053155\n",
      "Iteration 237, loss = 0.02043764\n",
      "Iteration 238, loss = 0.02028239\n",
      "Iteration 239, loss = 0.02025261\n",
      "Iteration 240, loss = 0.02013451\n",
      "Iteration 241, loss = 0.01997297\n",
      "Iteration 242, loss = 0.02014538\n",
      "Iteration 243, loss = 0.01987899\n",
      "Iteration 244, loss = 0.01982516\n",
      "Iteration 245, loss = 0.01968209\n",
      "Iteration 246, loss = 0.01964324\n",
      "Iteration 247, loss = 0.01952339\n",
      "Iteration 248, loss = 0.01946843\n",
      "Iteration 249, loss = 0.01939802\n",
      "Iteration 250, loss = 0.01925340\n",
      "Iteration 251, loss = 0.01931782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 252, loss = 0.01918670\n",
      "Iteration 253, loss = 0.01915714\n",
      "Iteration 254, loss = 0.01896634\n",
      "Iteration 255, loss = 0.01885578\n",
      "Iteration 256, loss = 0.01876318\n",
      "Iteration 257, loss = 0.01869563\n",
      "Iteration 258, loss = 0.01868129\n",
      "Iteration 259, loss = 0.01860498\n",
      "Iteration 260, loss = 0.01863018\n",
      "Iteration 261, loss = 0.01844488\n",
      "Iteration 262, loss = 0.01841199\n",
      "Iteration 263, loss = 0.01827058\n",
      "Iteration 264, loss = 0.01823431\n",
      "Iteration 265, loss = 0.01817303\n",
      "Iteration 266, loss = 0.01801687\n",
      "Iteration 267, loss = 0.01797532\n",
      "Iteration 268, loss = 0.01783167\n",
      "Iteration 269, loss = 0.01781199\n",
      "Iteration 270, loss = 0.01778526\n",
      "Iteration 271, loss = 0.01773800\n",
      "Iteration 272, loss = 0.01764651\n",
      "Iteration 273, loss = 0.01755173\n",
      "Iteration 274, loss = 0.01741415\n",
      "Iteration 275, loss = 0.01733452\n",
      "Iteration 276, loss = 0.01725941\n",
      "Iteration 277, loss = 0.01722469\n",
      "Iteration 278, loss = 0.01713883\n",
      "Iteration 279, loss = 0.01709782\n",
      "Iteration 280, loss = 0.01705626\n",
      "Iteration 281, loss = 0.01704459\n",
      "Iteration 282, loss = 0.01687909\n",
      "Iteration 283, loss = 0.01679824\n",
      "Iteration 284, loss = 0.01693565\n",
      "Iteration 285, loss = 0.01671687\n",
      "Iteration 286, loss = 0.01659007\n",
      "Iteration 287, loss = 0.01653211\n",
      "Iteration 288, loss = 0.01644831\n",
      "Iteration 289, loss = 0.01642569\n",
      "Iteration 290, loss = 0.01632499\n",
      "Iteration 291, loss = 0.01635473\n",
      "Iteration 292, loss = 0.01622822\n",
      "Iteration 293, loss = 0.01613851\n",
      "Iteration 294, loss = 0.01611619\n",
      "Iteration 295, loss = 0.01608380\n",
      "Iteration 296, loss = 0.01600110\n",
      "Iteration 297, loss = 0.01589178\n",
      "Iteration 298, loss = 0.01585770\n",
      "Iteration 299, loss = 0.01578547\n",
      "Iteration 300, loss = 0.01578089\n",
      "Iteration 301, loss = 0.01576498\n",
      "Iteration 302, loss = 0.01561835\n",
      "Iteration 303, loss = 0.01553471\n",
      "Iteration 304, loss = 0.01558210\n",
      "Iteration 305, loss = 0.01543293\n",
      "Iteration 306, loss = 0.01544110\n",
      "Iteration 307, loss = 0.01537708\n",
      "Iteration 308, loss = 0.01527595\n",
      "Iteration 309, loss = 0.01518958\n",
      "Iteration 310, loss = 0.01512318\n",
      "Iteration 311, loss = 0.01512819\n",
      "Iteration 312, loss = 0.01500808\n",
      "Iteration 313, loss = 0.01500211\n",
      "Iteration 314, loss = 0.01497244\n",
      "Iteration 315, loss = 0.01504098\n",
      "Iteration 316, loss = 0.01484440\n",
      "Iteration 317, loss = 0.01480043\n",
      "Iteration 318, loss = 0.01470532\n",
      "Iteration 319, loss = 0.01467530\n",
      "Iteration 320, loss = 0.01459611\n",
      "Iteration 321, loss = 0.01462497\n",
      "Iteration 322, loss = 0.01446855\n",
      "Iteration 323, loss = 0.01442741\n",
      "Iteration 324, loss = 0.01440973\n",
      "Iteration 325, loss = 0.01431846\n",
      "Iteration 326, loss = 0.01430044\n",
      "Iteration 327, loss = 0.01430397\n",
      "Iteration 328, loss = 0.01416552\n",
      "Iteration 329, loss = 0.01411841\n",
      "Iteration 330, loss = 0.01405023\n",
      "Iteration 331, loss = 0.01404379\n",
      "Iteration 332, loss = 0.01396130\n",
      "Iteration 333, loss = 0.01406151\n",
      "Iteration 334, loss = 0.01398822\n",
      "Iteration 335, loss = 0.01382276\n",
      "Iteration 336, loss = 0.01377131\n",
      "Iteration 337, loss = 0.01373327\n",
      "Iteration 338, loss = 0.01370108\n",
      "Iteration 339, loss = 0.01362909\n",
      "Iteration 340, loss = 0.01356354\n",
      "Iteration 341, loss = 0.01353182\n",
      "Iteration 342, loss = 0.01348488\n",
      "Iteration 343, loss = 0.01344624\n",
      "Iteration 344, loss = 0.01337134\n",
      "Iteration 345, loss = 0.01333867\n",
      "Iteration 346, loss = 0.01337298\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 88.4080370942813\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69424706\n",
      "Iteration 2, loss = 0.68564031\n",
      "Iteration 3, loss = 0.67665758\n",
      "Iteration 4, loss = 0.66394839\n",
      "Iteration 5, loss = 0.64719004\n",
      "Iteration 6, loss = 0.62583094\n",
      "Iteration 7, loss = 0.60064195\n",
      "Iteration 8, loss = 0.57290483\n",
      "Iteration 9, loss = 0.54288969\n",
      "Iteration 10, loss = 0.51244200\n",
      "Iteration 11, loss = 0.48191260\n",
      "Iteration 12, loss = 0.45256948\n",
      "Iteration 13, loss = 0.42468169\n",
      "Iteration 14, loss = 0.39789026\n",
      "Iteration 15, loss = 0.37329278\n",
      "Iteration 16, loss = 0.35106080\n",
      "Iteration 17, loss = 0.33049674\n",
      "Iteration 18, loss = 0.31196715\n",
      "Iteration 19, loss = 0.29505184\n",
      "Iteration 20, loss = 0.27983139\n",
      "Iteration 21, loss = 0.26599028\n",
      "Iteration 22, loss = 0.25327731\n",
      "Iteration 23, loss = 0.24174888\n",
      "Iteration 24, loss = 0.23136795\n",
      "Iteration 25, loss = 0.22182147\n",
      "Iteration 26, loss = 0.21297799\n",
      "Iteration 27, loss = 0.20472422\n",
      "Iteration 28, loss = 0.19735930\n",
      "Iteration 29, loss = 0.19025025\n",
      "Iteration 30, loss = 0.18351848\n",
      "Iteration 31, loss = 0.17760280\n",
      "Iteration 32, loss = 0.17228409\n",
      "Iteration 33, loss = 0.16644103\n",
      "Iteration 34, loss = 0.16155576\n",
      "Iteration 35, loss = 0.15681170\n",
      "Iteration 36, loss = 0.15239475\n",
      "Iteration 37, loss = 0.14844058\n",
      "Iteration 38, loss = 0.14427725\n",
      "Iteration 39, loss = 0.14057648\n",
      "Iteration 40, loss = 0.13693137\n",
      "Iteration 41, loss = 0.13322468\n",
      "Iteration 42, loss = 0.13043884\n",
      "Iteration 43, loss = 0.12702257\n",
      "Iteration 44, loss = 0.12383194\n",
      "Iteration 45, loss = 0.12096856\n",
      "Iteration 46, loss = 0.11822134\n",
      "Iteration 47, loss = 0.11566538\n",
      "Iteration 48, loss = 0.11324446\n",
      "Iteration 49, loss = 0.11100146\n",
      "Iteration 50, loss = 0.10830831\n",
      "Iteration 51, loss = 0.10592771\n",
      "Iteration 52, loss = 0.10395098\n",
      "Iteration 53, loss = 0.10170309\n",
      "Iteration 54, loss = 0.09951008\n",
      "Iteration 55, loss = 0.09772425\n",
      "Iteration 56, loss = 0.09595122\n",
      "Iteration 57, loss = 0.09389277\n",
      "Iteration 58, loss = 0.09258733\n",
      "Iteration 59, loss = 0.09053175\n",
      "Iteration 60, loss = 0.08914256\n",
      "Iteration 61, loss = 0.08711341\n",
      "Iteration 62, loss = 0.08568729\n",
      "Iteration 63, loss = 0.08396804\n",
      "Iteration 64, loss = 0.08281529\n",
      "Iteration 65, loss = 0.08127213\n",
      "Iteration 66, loss = 0.07986593\n",
      "Iteration 67, loss = 0.07858857\n",
      "Iteration 68, loss = 0.07733767\n",
      "Iteration 69, loss = 0.07645651\n",
      "Iteration 70, loss = 0.07509555\n",
      "Iteration 71, loss = 0.07407201\n",
      "Iteration 72, loss = 0.07263463\n",
      "Iteration 73, loss = 0.07133679\n",
      "Iteration 74, loss = 0.07040089\n",
      "Iteration 75, loss = 0.06913501\n",
      "Iteration 76, loss = 0.06829720\n",
      "Iteration 77, loss = 0.06717419\n",
      "Iteration 78, loss = 0.06634072\n",
      "Iteration 79, loss = 0.06542334\n",
      "Iteration 80, loss = 0.06451994\n",
      "Iteration 81, loss = 0.06360025\n",
      "Iteration 82, loss = 0.06280461\n",
      "Iteration 83, loss = 0.06197282\n",
      "Iteration 84, loss = 0.06097563\n",
      "Iteration 85, loss = 0.06059680\n",
      "Iteration 86, loss = 0.05936972\n",
      "Iteration 87, loss = 0.05884841\n",
      "Iteration 88, loss = 0.05812073\n",
      "Iteration 89, loss = 0.05723194\n",
      "Iteration 90, loss = 0.05653442\n",
      "Iteration 91, loss = 0.05588021\n",
      "Iteration 92, loss = 0.05528321\n",
      "Iteration 93, loss = 0.05459038\n",
      "Iteration 94, loss = 0.05394969\n",
      "Iteration 95, loss = 0.05328303\n",
      "Iteration 96, loss = 0.05301817\n",
      "Iteration 97, loss = 0.05216652\n",
      "Iteration 98, loss = 0.05149880\n",
      "Iteration 99, loss = 0.05098280\n",
      "Iteration 100, loss = 0.05050558\n",
      "Iteration 101, loss = 0.04978192\n",
      "Iteration 102, loss = 0.04927249\n",
      "Iteration 103, loss = 0.04889321\n",
      "Iteration 104, loss = 0.04831980\n",
      "Iteration 105, loss = 0.04788628\n",
      "Iteration 106, loss = 0.04728483\n",
      "Iteration 107, loss = 0.04698729\n",
      "Iteration 108, loss = 0.04631278\n",
      "Iteration 109, loss = 0.04591657\n",
      "Iteration 110, loss = 0.04560161\n",
      "Iteration 111, loss = 0.04532892\n",
      "Iteration 112, loss = 0.04460723\n",
      "Iteration 113, loss = 0.04423213\n",
      "Iteration 114, loss = 0.04378335\n",
      "Iteration 115, loss = 0.04339918\n",
      "Iteration 116, loss = 0.04303113\n",
      "Iteration 117, loss = 0.04270968\n",
      "Iteration 118, loss = 0.04215199\n",
      "Iteration 119, loss = 0.04183786\n",
      "Iteration 120, loss = 0.04133653\n",
      "Iteration 121, loss = 0.04123770\n",
      "Iteration 122, loss = 0.04076638\n",
      "Iteration 123, loss = 0.04028193\n",
      "Iteration 124, loss = 0.03990945\n",
      "Iteration 125, loss = 0.03976350\n",
      "Iteration 126, loss = 0.03926660\n",
      "Iteration 127, loss = 0.03897242\n",
      "Iteration 128, loss = 0.03864158\n",
      "Iteration 129, loss = 0.03832702\n",
      "Iteration 130, loss = 0.03798054\n",
      "Iteration 131, loss = 0.03764114\n",
      "Iteration 132, loss = 0.03742004\n",
      "Iteration 133, loss = 0.03705386\n",
      "Iteration 134, loss = 0.03675953\n",
      "Iteration 135, loss = 0.03651630\n",
      "Iteration 136, loss = 0.03626808\n",
      "Iteration 137, loss = 0.03588486\n",
      "Iteration 138, loss = 0.03571773\n",
      "Iteration 139, loss = 0.03557895\n",
      "Iteration 140, loss = 0.03508856\n",
      "Iteration 141, loss = 0.03488444\n",
      "Iteration 142, loss = 0.03474981\n",
      "Iteration 143, loss = 0.03449222\n",
      "Iteration 144, loss = 0.03414647\n",
      "Iteration 145, loss = 0.03396745\n",
      "Iteration 146, loss = 0.03377752\n",
      "Iteration 147, loss = 0.03346233\n",
      "Iteration 148, loss = 0.03311413\n",
      "Iteration 149, loss = 0.03290661\n",
      "Iteration 150, loss = 0.03274061\n",
      "Iteration 151, loss = 0.03253631\n",
      "Iteration 152, loss = 0.03236200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 153, loss = 0.03238269\n",
      "Iteration 154, loss = 0.03198002\n",
      "Iteration 155, loss = 0.03170943\n",
      "Iteration 156, loss = 0.03141435\n",
      "Iteration 157, loss = 0.03131333\n",
      "Iteration 158, loss = 0.03102996\n",
      "Iteration 159, loss = 0.03100964\n",
      "Iteration 160, loss = 0.03062282\n",
      "Iteration 161, loss = 0.03047854\n",
      "Iteration 162, loss = 0.03041732\n",
      "Iteration 163, loss = 0.03015073\n",
      "Iteration 164, loss = 0.02992047\n",
      "Iteration 165, loss = 0.02969125\n",
      "Iteration 166, loss = 0.02947147\n",
      "Iteration 167, loss = 0.02928698\n",
      "Iteration 168, loss = 0.02917269\n",
      "Iteration 169, loss = 0.02898835\n",
      "Iteration 170, loss = 0.02878641\n",
      "Iteration 171, loss = 0.02860880\n",
      "Iteration 172, loss = 0.02850788\n",
      "Iteration 173, loss = 0.02823488\n",
      "Iteration 174, loss = 0.02827265\n",
      "Iteration 175, loss = 0.02804561\n",
      "Iteration 176, loss = 0.02779774\n",
      "Iteration 177, loss = 0.02771159\n",
      "Iteration 178, loss = 0.02753285\n",
      "Iteration 179, loss = 0.02733363\n",
      "Iteration 180, loss = 0.02713400\n",
      "Iteration 181, loss = 0.02700716\n",
      "Iteration 182, loss = 0.02693785\n",
      "Iteration 183, loss = 0.02677533\n",
      "Iteration 184, loss = 0.02659605\n",
      "Iteration 185, loss = 0.02646301\n",
      "Iteration 186, loss = 0.02628354\n",
      "Iteration 187, loss = 0.02617864\n",
      "Iteration 188, loss = 0.02602959\n",
      "Iteration 189, loss = 0.02601963\n",
      "Iteration 190, loss = 0.02572809\n",
      "Iteration 191, loss = 0.02556218\n",
      "Iteration 192, loss = 0.02543519\n",
      "Iteration 193, loss = 0.02534530\n",
      "Iteration 194, loss = 0.02518166\n",
      "Iteration 195, loss = 0.02508562\n",
      "Iteration 196, loss = 0.02496968\n",
      "Iteration 197, loss = 0.02481359\n",
      "Iteration 198, loss = 0.02468649\n",
      "Iteration 199, loss = 0.02461094\n",
      "Iteration 200, loss = 0.02437485\n",
      "Iteration 201, loss = 0.02440576\n",
      "Iteration 202, loss = 0.02419943\n",
      "Iteration 203, loss = 0.02410555\n",
      "Iteration 204, loss = 0.02395747\n",
      "Iteration 205, loss = 0.02384270\n",
      "Iteration 206, loss = 0.02366012\n",
      "Iteration 207, loss = 0.02361628\n",
      "Iteration 208, loss = 0.02357437\n",
      "Iteration 209, loss = 0.02344422\n",
      "Iteration 210, loss = 0.02324992\n",
      "Iteration 211, loss = 0.02315870\n",
      "Iteration 212, loss = 0.02298295\n",
      "Iteration 213, loss = 0.02290463\n",
      "Iteration 214, loss = 0.02274948\n",
      "Iteration 215, loss = 0.02269253\n",
      "Iteration 216, loss = 0.02252886\n",
      "Iteration 217, loss = 0.02254258\n",
      "Iteration 218, loss = 0.02249702\n",
      "Iteration 219, loss = 0.02223730\n",
      "Iteration 220, loss = 0.02213795\n",
      "Iteration 221, loss = 0.02205757\n",
      "Iteration 222, loss = 0.02193534\n",
      "Iteration 223, loss = 0.02182462\n",
      "Iteration 224, loss = 0.02181196\n",
      "Iteration 225, loss = 0.02168954\n",
      "Iteration 226, loss = 0.02155723\n",
      "Iteration 227, loss = 0.02147208\n",
      "Iteration 228, loss = 0.02136207\n",
      "Iteration 229, loss = 0.02125748\n",
      "Iteration 230, loss = 0.02114040\n",
      "Iteration 231, loss = 0.02115557\n",
      "Iteration 232, loss = 0.02137227\n",
      "Iteration 233, loss = 0.02080886\n",
      "Iteration 234, loss = 0.02075941\n",
      "Iteration 235, loss = 0.02074876\n",
      "Iteration 236, loss = 0.02064752\n",
      "Iteration 237, loss = 0.02051231\n",
      "Iteration 238, loss = 0.02035701\n",
      "Iteration 239, loss = 0.02036481\n",
      "Iteration 240, loss = 0.02019597\n",
      "Iteration 241, loss = 0.02016580\n",
      "Iteration 242, loss = 0.02006654\n",
      "Iteration 243, loss = 0.02018315\n",
      "Iteration 244, loss = 0.01990537\n",
      "Iteration 245, loss = 0.01972572\n",
      "Iteration 246, loss = 0.01968895\n",
      "Iteration 247, loss = 0.01959968\n",
      "Iteration 248, loss = 0.01949712\n",
      "Iteration 249, loss = 0.01943701\n",
      "Iteration 250, loss = 0.01944228\n",
      "Iteration 251, loss = 0.01924641\n",
      "Iteration 252, loss = 0.01921643\n",
      "Iteration 253, loss = 0.01905413\n",
      "Iteration 254, loss = 0.01901930\n",
      "Iteration 255, loss = 0.01893142\n",
      "Iteration 256, loss = 0.01888478\n",
      "Iteration 257, loss = 0.01879031\n",
      "Iteration 258, loss = 0.01867567\n",
      "Iteration 259, loss = 0.01865030\n",
      "Iteration 260, loss = 0.01853872\n",
      "Iteration 261, loss = 0.01845824\n",
      "Iteration 262, loss = 0.01835319\n",
      "Iteration 263, loss = 0.01839082\n",
      "Iteration 264, loss = 0.01823683\n",
      "Iteration 265, loss = 0.01827176\n",
      "Iteration 266, loss = 0.01809448\n",
      "Iteration 267, loss = 0.01799577\n",
      "Iteration 268, loss = 0.01792562\n",
      "Iteration 269, loss = 0.01785896\n",
      "Iteration 270, loss = 0.01776872\n",
      "Iteration 271, loss = 0.01770055\n",
      "Iteration 272, loss = 0.01763896\n",
      "Iteration 273, loss = 0.01758223\n",
      "Iteration 274, loss = 0.01753856\n",
      "Iteration 275, loss = 0.01741461\n",
      "Iteration 276, loss = 0.01734997\n",
      "Iteration 277, loss = 0.01742607\n",
      "Iteration 278, loss = 0.01717933\n",
      "Iteration 279, loss = 0.01712895\n",
      "Iteration 280, loss = 0.01720576\n",
      "Iteration 281, loss = 0.01701325\n",
      "Iteration 282, loss = 0.01706843\n",
      "Iteration 283, loss = 0.01687685\n",
      "Iteration 284, loss = 0.01683685\n",
      "Iteration 285, loss = 0.01676012\n",
      "Iteration 286, loss = 0.01662617\n",
      "Iteration 287, loss = 0.01661803\n",
      "Iteration 288, loss = 0.01653571\n",
      "Iteration 289, loss = 0.01654278\n",
      "Iteration 290, loss = 0.01643444\n",
      "Iteration 291, loss = 0.01637462\n",
      "Iteration 292, loss = 0.01638959\n",
      "Iteration 293, loss = 0.01620966\n",
      "Iteration 294, loss = 0.01613568\n",
      "Iteration 295, loss = 0.01605221\n",
      "Iteration 296, loss = 0.01603120\n",
      "Iteration 297, loss = 0.01602279\n",
      "Iteration 298, loss = 0.01588798\n",
      "Iteration 299, loss = 0.01584268\n",
      "Iteration 300, loss = 0.01577028\n",
      "Iteration 301, loss = 0.01569233\n",
      "Iteration 302, loss = 0.01563733\n",
      "Iteration 303, loss = 0.01557763\n",
      "Iteration 304, loss = 0.01562961\n",
      "Iteration 305, loss = 0.01550313\n",
      "Iteration 306, loss = 0.01552423\n",
      "Iteration 307, loss = 0.01541044\n",
      "Iteration 308, loss = 0.01539925\n",
      "Iteration 309, loss = 0.01524221\n",
      "Iteration 310, loss = 0.01516987\n",
      "Iteration 311, loss = 0.01518545\n",
      "Iteration 312, loss = 0.01506511\n",
      "Iteration 313, loss = 0.01508920\n",
      "Iteration 314, loss = 0.01496922\n",
      "Iteration 315, loss = 0.01494158\n",
      "Iteration 316, loss = 0.01483315\n",
      "Iteration 317, loss = 0.01482335\n",
      "Iteration 318, loss = 0.01473621\n",
      "Iteration 319, loss = 0.01471142\n",
      "Iteration 320, loss = 0.01462852\n",
      "Iteration 321, loss = 0.01459182\n",
      "Iteration 322, loss = 0.01455761\n",
      "Iteration 323, loss = 0.01445818\n",
      "Iteration 324, loss = 0.01445799\n",
      "Iteration 325, loss = 0.01438597\n",
      "Iteration 326, loss = 0.01432197\n",
      "Iteration 327, loss = 0.01426268\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 88.02163833075734\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69356040\n",
      "Iteration 2, loss = 0.68553605\n",
      "Iteration 3, loss = 0.67645267\n",
      "Iteration 4, loss = 0.66319924\n",
      "Iteration 5, loss = 0.64562960\n",
      "Iteration 6, loss = 0.62397983\n",
      "Iteration 7, loss = 0.59865700\n",
      "Iteration 8, loss = 0.57086843\n",
      "Iteration 9, loss = 0.54069483\n",
      "Iteration 10, loss = 0.51028934\n",
      "Iteration 11, loss = 0.47972217\n",
      "Iteration 12, loss = 0.45018195\n",
      "Iteration 13, loss = 0.42203756\n",
      "Iteration 14, loss = 0.39576436\n",
      "Iteration 15, loss = 0.37121128\n",
      "Iteration 16, loss = 0.34936257\n",
      "Iteration 17, loss = 0.32845951\n",
      "Iteration 18, loss = 0.30981269\n",
      "Iteration 19, loss = 0.29289175\n",
      "Iteration 20, loss = 0.27784017\n",
      "Iteration 21, loss = 0.26362656\n",
      "Iteration 22, loss = 0.25106303\n",
      "Iteration 23, loss = 0.23931040\n",
      "Iteration 24, loss = 0.22882920\n",
      "Iteration 25, loss = 0.21899485\n",
      "Iteration 26, loss = 0.21038438\n",
      "Iteration 27, loss = 0.20239259\n",
      "Iteration 28, loss = 0.19487958\n",
      "Iteration 29, loss = 0.18769958\n",
      "Iteration 30, loss = 0.18107745\n",
      "Iteration 31, loss = 0.17497297\n",
      "Iteration 32, loss = 0.16912551\n",
      "Iteration 33, loss = 0.16404250\n",
      "Iteration 34, loss = 0.15896651\n",
      "Iteration 35, loss = 0.15421611\n",
      "Iteration 36, loss = 0.15004811\n",
      "Iteration 37, loss = 0.14562950\n",
      "Iteration 38, loss = 0.14194807\n",
      "Iteration 39, loss = 0.13790815\n",
      "Iteration 40, loss = 0.13426874\n",
      "Iteration 41, loss = 0.13121124\n",
      "Iteration 42, loss = 0.12750459\n",
      "Iteration 43, loss = 0.12443473\n",
      "Iteration 44, loss = 0.12157209\n",
      "Iteration 45, loss = 0.11874510\n",
      "Iteration 46, loss = 0.11589657\n",
      "Iteration 47, loss = 0.11330302\n",
      "Iteration 48, loss = 0.11080990\n",
      "Iteration 49, loss = 0.10835086\n",
      "Iteration 50, loss = 0.10615957\n",
      "Iteration 51, loss = 0.10427684\n",
      "Iteration 52, loss = 0.10167905\n",
      "Iteration 53, loss = 0.09958241\n",
      "Iteration 54, loss = 0.09758504\n",
      "Iteration 55, loss = 0.09591716\n",
      "Iteration 56, loss = 0.09386533\n",
      "Iteration 57, loss = 0.09204769\n",
      "Iteration 58, loss = 0.09031550\n",
      "Iteration 59, loss = 0.08853289\n",
      "Iteration 60, loss = 0.08705429\n",
      "Iteration 61, loss = 0.08524508\n",
      "Iteration 62, loss = 0.08399380\n",
      "Iteration 63, loss = 0.08246717\n",
      "Iteration 64, loss = 0.08086997\n",
      "Iteration 65, loss = 0.07959984\n",
      "Iteration 66, loss = 0.07823014\n",
      "Iteration 67, loss = 0.07683966\n",
      "Iteration 68, loss = 0.07585982\n",
      "Iteration 69, loss = 0.07442159\n",
      "Iteration 70, loss = 0.07327017\n",
      "Iteration 71, loss = 0.07222125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 72, loss = 0.07086603\n",
      "Iteration 73, loss = 0.06992739\n",
      "Iteration 74, loss = 0.06872325\n",
      "Iteration 75, loss = 0.06773592\n",
      "Iteration 76, loss = 0.06674558\n",
      "Iteration 77, loss = 0.06603873\n",
      "Iteration 78, loss = 0.06500719\n",
      "Iteration 79, loss = 0.06425046\n",
      "Iteration 80, loss = 0.06291996\n",
      "Iteration 81, loss = 0.06211330\n",
      "Iteration 82, loss = 0.06134113\n",
      "Iteration 83, loss = 0.06063454\n",
      "Iteration 84, loss = 0.05972397\n",
      "Iteration 85, loss = 0.05909357\n",
      "Iteration 86, loss = 0.05827899\n",
      "Iteration 87, loss = 0.05743162\n",
      "Iteration 88, loss = 0.05663397\n",
      "Iteration 89, loss = 0.05627286\n",
      "Iteration 90, loss = 0.05525024\n",
      "Iteration 91, loss = 0.05465262\n",
      "Iteration 92, loss = 0.05400940\n",
      "Iteration 93, loss = 0.05334050\n",
      "Iteration 94, loss = 0.05261399\n",
      "Iteration 95, loss = 0.05203164\n",
      "Iteration 96, loss = 0.05142033\n",
      "Iteration 97, loss = 0.05085688\n",
      "Iteration 98, loss = 0.05039455\n",
      "Iteration 99, loss = 0.04983473\n",
      "Iteration 100, loss = 0.04916602\n",
      "Iteration 101, loss = 0.04891365\n",
      "Iteration 102, loss = 0.04819790\n",
      "Iteration 103, loss = 0.04784026\n",
      "Iteration 104, loss = 0.04750860\n",
      "Iteration 105, loss = 0.04683151\n",
      "Iteration 106, loss = 0.04627565\n",
      "Iteration 107, loss = 0.04576311\n",
      "Iteration 108, loss = 0.04538959\n",
      "Iteration 109, loss = 0.04494021\n",
      "Iteration 110, loss = 0.04449026\n",
      "Iteration 111, loss = 0.04404429\n",
      "Iteration 112, loss = 0.04352752\n",
      "Iteration 113, loss = 0.04308551\n",
      "Iteration 114, loss = 0.04275573\n",
      "Iteration 115, loss = 0.04225872\n",
      "Iteration 116, loss = 0.04186208\n",
      "Iteration 117, loss = 0.04157654\n",
      "Iteration 118, loss = 0.04108594\n",
      "Iteration 119, loss = 0.04087024\n",
      "Iteration 120, loss = 0.04039494\n",
      "Iteration 121, loss = 0.04009825\n",
      "Iteration 122, loss = 0.03981935\n",
      "Iteration 123, loss = 0.03945478\n",
      "Iteration 124, loss = 0.03895331\n",
      "Iteration 125, loss = 0.03864593\n",
      "Iteration 126, loss = 0.03845294\n",
      "Iteration 127, loss = 0.03806368\n",
      "Iteration 128, loss = 0.03769106\n",
      "Iteration 129, loss = 0.03736991\n",
      "Iteration 130, loss = 0.03713067\n",
      "Iteration 131, loss = 0.03673025\n",
      "Iteration 132, loss = 0.03643249\n",
      "Iteration 133, loss = 0.03612913\n",
      "Iteration 134, loss = 0.03598873\n",
      "Iteration 135, loss = 0.03569903\n",
      "Iteration 136, loss = 0.03532222\n",
      "Iteration 137, loss = 0.03499530\n",
      "Iteration 138, loss = 0.03475864\n",
      "Iteration 139, loss = 0.03454693\n",
      "Iteration 140, loss = 0.03437271\n",
      "Iteration 141, loss = 0.03421529\n",
      "Iteration 142, loss = 0.03386160\n",
      "Iteration 143, loss = 0.03348935\n",
      "Iteration 144, loss = 0.03343077\n",
      "Iteration 145, loss = 0.03302117\n",
      "Iteration 146, loss = 0.03297947\n",
      "Iteration 147, loss = 0.03251519\n",
      "Iteration 148, loss = 0.03238548\n",
      "Iteration 149, loss = 0.03213425\n",
      "Iteration 150, loss = 0.03192164\n",
      "Iteration 151, loss = 0.03172090\n",
      "Iteration 152, loss = 0.03152459\n",
      "Iteration 153, loss = 0.03132534\n",
      "Iteration 154, loss = 0.03103854\n",
      "Iteration 155, loss = 0.03084355\n",
      "Iteration 156, loss = 0.03062205\n",
      "Iteration 157, loss = 0.03047653\n",
      "Iteration 158, loss = 0.03016050\n",
      "Iteration 159, loss = 0.03010828\n",
      "Iteration 160, loss = 0.02988388\n",
      "Iteration 161, loss = 0.02965890\n",
      "Iteration 162, loss = 0.02950494\n",
      "Iteration 163, loss = 0.02938086\n",
      "Iteration 164, loss = 0.02920368\n",
      "Iteration 165, loss = 0.02888426\n",
      "Iteration 166, loss = 0.02892317\n",
      "Iteration 167, loss = 0.02881550\n",
      "Iteration 168, loss = 0.02841110\n",
      "Iteration 169, loss = 0.02818080\n",
      "Iteration 170, loss = 0.02806311\n",
      "Iteration 171, loss = 0.02802165\n",
      "Iteration 172, loss = 0.02771758\n",
      "Iteration 173, loss = 0.02755635\n",
      "Iteration 174, loss = 0.02756023\n",
      "Iteration 175, loss = 0.02719637\n",
      "Iteration 176, loss = 0.02709812\n",
      "Iteration 177, loss = 0.02699525\n",
      "Iteration 178, loss = 0.02676333\n",
      "Iteration 179, loss = 0.02679967\n",
      "Iteration 180, loss = 0.02648483\n",
      "Iteration 181, loss = 0.02631020\n",
      "Iteration 182, loss = 0.02623898\n",
      "Iteration 183, loss = 0.02606285\n",
      "Iteration 184, loss = 0.02592633\n",
      "Iteration 185, loss = 0.02572350\n",
      "Iteration 186, loss = 0.02566368\n",
      "Iteration 187, loss = 0.02547484\n",
      "Iteration 188, loss = 0.02558692\n",
      "Iteration 189, loss = 0.02521672\n",
      "Iteration 190, loss = 0.02500281\n",
      "Iteration 191, loss = 0.02500291\n",
      "Iteration 192, loss = 0.02481637\n",
      "Iteration 193, loss = 0.02469863\n",
      "Iteration 194, loss = 0.02459506\n",
      "Iteration 195, loss = 0.02449440\n",
      "Iteration 196, loss = 0.02428165\n",
      "Iteration 197, loss = 0.02415795\n",
      "Iteration 198, loss = 0.02405763\n",
      "Iteration 199, loss = 0.02390579\n",
      "Iteration 200, loss = 0.02381413\n",
      "Iteration 201, loss = 0.02376605\n",
      "Iteration 202, loss = 0.02348400\n",
      "Iteration 203, loss = 0.02345781\n",
      "Iteration 204, loss = 0.02335864\n",
      "Iteration 205, loss = 0.02323838\n",
      "Iteration 206, loss = 0.02303634\n",
      "Iteration 207, loss = 0.02297935\n",
      "Iteration 208, loss = 0.02288310\n",
      "Iteration 209, loss = 0.02278399\n",
      "Iteration 210, loss = 0.02264179\n",
      "Iteration 211, loss = 0.02249891\n",
      "Iteration 212, loss = 0.02235539\n",
      "Iteration 213, loss = 0.02243170\n",
      "Iteration 214, loss = 0.02224697\n",
      "Iteration 215, loss = 0.02228793\n",
      "Iteration 216, loss = 0.02208392\n",
      "Iteration 217, loss = 0.02187866\n",
      "Iteration 218, loss = 0.02184565\n",
      "Iteration 219, loss = 0.02178564\n",
      "Iteration 220, loss = 0.02162690\n",
      "Iteration 221, loss = 0.02174492\n",
      "Iteration 222, loss = 0.02145715\n",
      "Iteration 223, loss = 0.02124156\n",
      "Iteration 224, loss = 0.02119220\n",
      "Iteration 225, loss = 0.02109480\n",
      "Iteration 226, loss = 0.02093322\n",
      "Iteration 227, loss = 0.02091657\n",
      "Iteration 228, loss = 0.02075168\n",
      "Iteration 229, loss = 0.02084521\n",
      "Iteration 230, loss = 0.02063096\n",
      "Iteration 231, loss = 0.02052360\n",
      "Iteration 232, loss = 0.02038515\n",
      "Iteration 233, loss = 0.02035221\n",
      "Iteration 234, loss = 0.02025554\n",
      "Iteration 235, loss = 0.02017816\n",
      "Iteration 236, loss = 0.02007139\n",
      "Iteration 237, loss = 0.01994595\n",
      "Iteration 238, loss = 0.01981578\n",
      "Iteration 239, loss = 0.01979582\n",
      "Iteration 240, loss = 0.01965936\n",
      "Iteration 241, loss = 0.01975668\n",
      "Iteration 242, loss = 0.01960642\n",
      "Iteration 243, loss = 0.01955469\n",
      "Iteration 244, loss = 0.01932960\n",
      "Iteration 245, loss = 0.01927314\n",
      "Iteration 246, loss = 0.01916344\n",
      "Iteration 247, loss = 0.01904683\n",
      "Iteration 248, loss = 0.01899961\n",
      "Iteration 249, loss = 0.01894016\n",
      "Iteration 250, loss = 0.01883606\n",
      "Iteration 251, loss = 0.01882514\n",
      "Iteration 252, loss = 0.01866319\n",
      "Iteration 253, loss = 0.01860503\n",
      "Iteration 254, loss = 0.01855374\n",
      "Iteration 255, loss = 0.01842663\n",
      "Iteration 256, loss = 0.01833781\n",
      "Iteration 257, loss = 0.01829507\n",
      "Iteration 258, loss = 0.01819570\n",
      "Iteration 259, loss = 0.01813088\n",
      "Iteration 260, loss = 0.01802387\n",
      "Iteration 261, loss = 0.01804131\n",
      "Iteration 262, loss = 0.01786206\n",
      "Iteration 263, loss = 0.01787171\n",
      "Iteration 264, loss = 0.01773807\n",
      "Iteration 265, loss = 0.01762054\n",
      "Iteration 266, loss = 0.01765426\n",
      "Iteration 267, loss = 0.01750079\n",
      "Iteration 268, loss = 0.01746903\n",
      "Iteration 269, loss = 0.01737140\n",
      "Iteration 270, loss = 0.01729678\n",
      "Iteration 271, loss = 0.01726285\n",
      "Iteration 272, loss = 0.01719068\n",
      "Iteration 273, loss = 0.01708631\n",
      "Iteration 274, loss = 0.01703781\n",
      "Iteration 275, loss = 0.01695745\n",
      "Iteration 276, loss = 0.01689066\n",
      "Iteration 277, loss = 0.01682715\n",
      "Iteration 278, loss = 0.01673928\n",
      "Iteration 279, loss = 0.01669292\n",
      "Iteration 280, loss = 0.01666524\n",
      "Iteration 281, loss = 0.01654034\n",
      "Iteration 282, loss = 0.01645595\n",
      "Iteration 283, loss = 0.01640214\n",
      "Iteration 284, loss = 0.01632347\n",
      "Iteration 285, loss = 0.01627775\n",
      "Iteration 286, loss = 0.01629988\n",
      "Iteration 287, loss = 0.01616641\n",
      "Iteration 288, loss = 0.01609072\n",
      "Iteration 289, loss = 0.01601866\n",
      "Iteration 290, loss = 0.01594137\n",
      "Iteration 291, loss = 0.01586874\n",
      "Iteration 292, loss = 0.01594778\n",
      "Iteration 293, loss = 0.01591716\n",
      "Iteration 294, loss = 0.01579026\n",
      "Iteration 295, loss = 0.01572905\n",
      "Iteration 296, loss = 0.01562056\n",
      "Iteration 297, loss = 0.01550362\n",
      "Iteration 298, loss = 0.01545656\n",
      "Iteration 299, loss = 0.01538974\n",
      "Iteration 300, loss = 0.01531756\n",
      "Iteration 301, loss = 0.01541110\n",
      "Iteration 302, loss = 0.01520980\n",
      "Iteration 303, loss = 0.01527195\n",
      "Iteration 304, loss = 0.01510043\n",
      "Iteration 305, loss = 0.01508063\n",
      "Iteration 306, loss = 0.01502415\n",
      "Iteration 307, loss = 0.01494075\n",
      "Iteration 308, loss = 0.01486564\n",
      "Iteration 309, loss = 0.01481812\n",
      "Iteration 310, loss = 0.01492836\n",
      "Iteration 311, loss = 0.01466513\n",
      "Iteration 312, loss = 0.01468122\n",
      "Iteration 313, loss = 0.01463227\n",
      "Iteration 314, loss = 0.01456531\n",
      "Iteration 315, loss = 0.01453138\n",
      "Iteration 316, loss = 0.01448495\n",
      "Iteration 317, loss = 0.01437886\n",
      "Iteration 318, loss = 0.01438214\n",
      "Iteration 319, loss = 0.01433201\n",
      "Iteration 320, loss = 0.01422044\n",
      "Iteration 321, loss = 0.01417551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 322, loss = 0.01414818\n",
      "Iteration 323, loss = 0.01410859\n",
      "Iteration 324, loss = 0.01404339\n",
      "Iteration 325, loss = 0.01397991\n",
      "Iteration 326, loss = 0.01412820\n",
      "Iteration 327, loss = 0.01403822\n",
      "Iteration 328, loss = 0.01384265\n",
      "Iteration 329, loss = 0.01378380\n",
      "Iteration 330, loss = 0.01372669\n",
      "Iteration 331, loss = 0.01364607\n",
      "Iteration 332, loss = 0.01363555\n",
      "Iteration 333, loss = 0.01365006\n",
      "Iteration 334, loss = 0.01350477\n",
      "Iteration 335, loss = 0.01351448\n",
      "Iteration 336, loss = 0.01344409\n",
      "Iteration 337, loss = 0.01341223\n",
      "Iteration 338, loss = 0.01333541\n",
      "Iteration 339, loss = 0.01334121\n",
      "Iteration 340, loss = 0.01326665\n",
      "Iteration 341, loss = 0.01322336\n",
      "Iteration 342, loss = 0.01313701\n",
      "Iteration 343, loss = 0.01313196\n",
      "Iteration 344, loss = 0.01307009\n",
      "Iteration 345, loss = 0.01307590\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 87.24884080370943\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69470357\n",
      "Iteration 2, loss = 0.68573709\n",
      "Iteration 3, loss = 0.67681579\n",
      "Iteration 4, loss = 0.66397653\n",
      "Iteration 5, loss = 0.64678951\n",
      "Iteration 6, loss = 0.62562652\n",
      "Iteration 7, loss = 0.60111376\n",
      "Iteration 8, loss = 0.57281924\n",
      "Iteration 9, loss = 0.54300490\n",
      "Iteration 10, loss = 0.51235272\n",
      "Iteration 11, loss = 0.48187138\n",
      "Iteration 12, loss = 0.45219131\n",
      "Iteration 13, loss = 0.42391703\n",
      "Iteration 14, loss = 0.39713932\n",
      "Iteration 15, loss = 0.37264437\n",
      "Iteration 16, loss = 0.35012535\n",
      "Iteration 17, loss = 0.32936597\n",
      "Iteration 18, loss = 0.31036000\n",
      "Iteration 19, loss = 0.29350632\n",
      "Iteration 20, loss = 0.27785871\n",
      "Iteration 21, loss = 0.26351489\n",
      "Iteration 22, loss = 0.25068496\n",
      "Iteration 23, loss = 0.23919190\n",
      "Iteration 24, loss = 0.22847268\n",
      "Iteration 25, loss = 0.21850291\n",
      "Iteration 26, loss = 0.20947845\n",
      "Iteration 27, loss = 0.20106064\n",
      "Iteration 28, loss = 0.19357695\n",
      "Iteration 29, loss = 0.18654958\n",
      "Iteration 30, loss = 0.17996407\n",
      "Iteration 31, loss = 0.17345683\n",
      "Iteration 32, loss = 0.16763698\n",
      "Iteration 33, loss = 0.16236564\n",
      "Iteration 34, loss = 0.15728193\n",
      "Iteration 35, loss = 0.15239826\n",
      "Iteration 36, loss = 0.14787430\n",
      "Iteration 37, loss = 0.14374788\n",
      "Iteration 38, loss = 0.13944849\n",
      "Iteration 39, loss = 0.13562916\n",
      "Iteration 40, loss = 0.13190709\n",
      "Iteration 41, loss = 0.12872366\n",
      "Iteration 42, loss = 0.12529192\n",
      "Iteration 43, loss = 0.12211130\n",
      "Iteration 44, loss = 0.11904737\n",
      "Iteration 45, loss = 0.11598841\n",
      "Iteration 46, loss = 0.11366451\n",
      "Iteration 47, loss = 0.11067288\n",
      "Iteration 48, loss = 0.10817382\n",
      "Iteration 49, loss = 0.10582623\n",
      "Iteration 50, loss = 0.10344863\n",
      "Iteration 51, loss = 0.10119427\n",
      "Iteration 52, loss = 0.09887802\n",
      "Iteration 53, loss = 0.09723644\n",
      "Iteration 54, loss = 0.09488408\n",
      "Iteration 55, loss = 0.09293145\n",
      "Iteration 56, loss = 0.09178816\n",
      "Iteration 57, loss = 0.08925002\n",
      "Iteration 58, loss = 0.08750168\n",
      "Iteration 59, loss = 0.08612418\n",
      "Iteration 60, loss = 0.08430358\n",
      "Iteration 61, loss = 0.08282129\n",
      "Iteration 62, loss = 0.08121589\n",
      "Iteration 63, loss = 0.07965869\n",
      "Iteration 64, loss = 0.07827820\n",
      "Iteration 65, loss = 0.07694074\n",
      "Iteration 66, loss = 0.07566995\n",
      "Iteration 67, loss = 0.07435620\n",
      "Iteration 68, loss = 0.07335137\n",
      "Iteration 69, loss = 0.07179344\n",
      "Iteration 70, loss = 0.07094489\n",
      "Iteration 71, loss = 0.07001276\n",
      "Iteration 72, loss = 0.06858234\n",
      "Iteration 73, loss = 0.06745038\n",
      "Iteration 74, loss = 0.06637820\n",
      "Iteration 75, loss = 0.06536636\n",
      "Iteration 76, loss = 0.06443730\n",
      "Iteration 77, loss = 0.06366478\n",
      "Iteration 78, loss = 0.06259400\n",
      "Iteration 79, loss = 0.06165392\n",
      "Iteration 80, loss = 0.06076413\n",
      "Iteration 81, loss = 0.05995457\n",
      "Iteration 82, loss = 0.05917166\n",
      "Iteration 83, loss = 0.05848047\n",
      "Iteration 84, loss = 0.05774775\n",
      "Iteration 85, loss = 0.05680583\n",
      "Iteration 86, loss = 0.05603047\n",
      "Iteration 87, loss = 0.05550702\n",
      "Iteration 88, loss = 0.05503957\n",
      "Iteration 89, loss = 0.05405400\n",
      "Iteration 90, loss = 0.05335015\n",
      "Iteration 91, loss = 0.05288731\n",
      "Iteration 92, loss = 0.05202820\n",
      "Iteration 93, loss = 0.05180774\n",
      "Iteration 94, loss = 0.05085693\n",
      "Iteration 95, loss = 0.05037171\n",
      "Iteration 96, loss = 0.04987146\n",
      "Iteration 97, loss = 0.04912434\n",
      "Iteration 98, loss = 0.04868446\n",
      "Iteration 99, loss = 0.04804336\n",
      "Iteration 100, loss = 0.04759835\n",
      "Iteration 101, loss = 0.04703195\n",
      "Iteration 102, loss = 0.04673312\n",
      "Iteration 103, loss = 0.04613724\n",
      "Iteration 104, loss = 0.04556614\n",
      "Iteration 105, loss = 0.04513916\n",
      "Iteration 106, loss = 0.04506359\n",
      "Iteration 107, loss = 0.04426151\n",
      "Iteration 108, loss = 0.04394699\n",
      "Iteration 109, loss = 0.04335786\n",
      "Iteration 110, loss = 0.04302338\n",
      "Iteration 111, loss = 0.04251019\n",
      "Iteration 112, loss = 0.04210467\n",
      "Iteration 113, loss = 0.04178403\n",
      "Iteration 114, loss = 0.04133473\n",
      "Iteration 115, loss = 0.04107000\n",
      "Iteration 116, loss = 0.04059271\n",
      "Iteration 117, loss = 0.04023317\n",
      "Iteration 118, loss = 0.03998610\n",
      "Iteration 119, loss = 0.03963856\n",
      "Iteration 120, loss = 0.03928697\n",
      "Iteration 121, loss = 0.03884952\n",
      "Iteration 122, loss = 0.03870881\n",
      "Iteration 123, loss = 0.03823511\n",
      "Iteration 124, loss = 0.03794403\n",
      "Iteration 125, loss = 0.03760134\n",
      "Iteration 126, loss = 0.03726931\n",
      "Iteration 127, loss = 0.03711783\n",
      "Iteration 128, loss = 0.03671973\n",
      "Iteration 129, loss = 0.03643990\n",
      "Iteration 130, loss = 0.03609443\n",
      "Iteration 131, loss = 0.03593900\n",
      "Iteration 132, loss = 0.03549158\n",
      "Iteration 133, loss = 0.03529889\n",
      "Iteration 134, loss = 0.03495100\n",
      "Iteration 135, loss = 0.03470020\n",
      "Iteration 136, loss = 0.03447115\n",
      "Iteration 137, loss = 0.03416984\n",
      "Iteration 138, loss = 0.03389957\n",
      "Iteration 139, loss = 0.03376312\n",
      "Iteration 140, loss = 0.03349150\n",
      "Iteration 141, loss = 0.03324751\n",
      "Iteration 142, loss = 0.03290150\n",
      "Iteration 143, loss = 0.03273662\n",
      "Iteration 144, loss = 0.03248958\n",
      "Iteration 145, loss = 0.03249537\n",
      "Iteration 146, loss = 0.03229999\n",
      "Iteration 147, loss = 0.03195264\n",
      "Iteration 148, loss = 0.03171131\n",
      "Iteration 149, loss = 0.03148579\n",
      "Iteration 150, loss = 0.03124323\n",
      "Iteration 151, loss = 0.03096077\n",
      "Iteration 152, loss = 0.03071769\n",
      "Iteration 153, loss = 0.03048570\n",
      "Iteration 154, loss = 0.03045774\n",
      "Iteration 155, loss = 0.03040167\n",
      "Iteration 156, loss = 0.03000941\n",
      "Iteration 157, loss = 0.02981157\n",
      "Iteration 158, loss = 0.02946671\n",
      "Iteration 159, loss = 0.02957898\n",
      "Iteration 160, loss = 0.02925853\n",
      "Iteration 161, loss = 0.02902166\n",
      "Iteration 162, loss = 0.02900064\n",
      "Iteration 163, loss = 0.02895432\n",
      "Iteration 164, loss = 0.02870551\n",
      "Iteration 165, loss = 0.02851382\n",
      "Iteration 166, loss = 0.02822680\n",
      "Iteration 167, loss = 0.02811073\n",
      "Iteration 168, loss = 0.02782239\n",
      "Iteration 169, loss = 0.02779372\n",
      "Iteration 170, loss = 0.02764668\n",
      "Iteration 171, loss = 0.02735119\n",
      "Iteration 172, loss = 0.02730639\n",
      "Iteration 173, loss = 0.02700570\n",
      "Iteration 174, loss = 0.02683061\n",
      "Iteration 175, loss = 0.02674656\n",
      "Iteration 176, loss = 0.02659923\n",
      "Iteration 177, loss = 0.02645342\n",
      "Iteration 178, loss = 0.02627124\n",
      "Iteration 179, loss = 0.02612651\n",
      "Iteration 180, loss = 0.02605447\n",
      "Iteration 181, loss = 0.02583435\n",
      "Iteration 182, loss = 0.02569705\n",
      "Iteration 183, loss = 0.02556276\n",
      "Iteration 184, loss = 0.02548287\n",
      "Iteration 185, loss = 0.02534553\n",
      "Iteration 186, loss = 0.02512548\n",
      "Iteration 187, loss = 0.02508528\n",
      "Iteration 188, loss = 0.02522190\n",
      "Iteration 189, loss = 0.02479835\n",
      "Iteration 190, loss = 0.02460631\n",
      "Iteration 191, loss = 0.02455622\n",
      "Iteration 192, loss = 0.02441549\n",
      "Iteration 193, loss = 0.02427402\n",
      "Iteration 194, loss = 0.02408606\n",
      "Iteration 195, loss = 0.02404047\n",
      "Iteration 196, loss = 0.02387277\n",
      "Iteration 197, loss = 0.02406265\n",
      "Iteration 198, loss = 0.02389196\n",
      "Iteration 199, loss = 0.02352451\n",
      "Iteration 200, loss = 0.02338150\n",
      "Iteration 201, loss = 0.02328168\n",
      "Iteration 202, loss = 0.02320838\n",
      "Iteration 203, loss = 0.02301555\n",
      "Iteration 204, loss = 0.02296026\n",
      "Iteration 205, loss = 0.02279712\n",
      "Iteration 206, loss = 0.02279974\n",
      "Iteration 207, loss = 0.02260583\n",
      "Iteration 208, loss = 0.02251051\n",
      "Iteration 209, loss = 0.02235079\n",
      "Iteration 210, loss = 0.02227089\n",
      "Iteration 211, loss = 0.02218647\n",
      "Iteration 212, loss = 0.02206807\n",
      "Iteration 213, loss = 0.02204353\n",
      "Iteration 214, loss = 0.02193485\n",
      "Iteration 215, loss = 0.02180322\n",
      "Iteration 216, loss = 0.02170321\n",
      "Iteration 217, loss = 0.02162331\n",
      "Iteration 218, loss = 0.02159767\n",
      "Iteration 219, loss = 0.02142810\n",
      "Iteration 220, loss = 0.02133295\n",
      "Iteration 221, loss = 0.02117884\n",
      "Iteration 222, loss = 0.02105524\n",
      "Iteration 223, loss = 0.02110541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 224, loss = 0.02095865\n",
      "Iteration 225, loss = 0.02080805\n",
      "Iteration 226, loss = 0.02082169\n",
      "Iteration 227, loss = 0.02069594\n",
      "Iteration 228, loss = 0.02052741\n",
      "Iteration 229, loss = 0.02046847\n",
      "Iteration 230, loss = 0.02033612\n",
      "Iteration 231, loss = 0.02026623\n",
      "Iteration 232, loss = 0.02016254\n",
      "Iteration 233, loss = 0.02007956\n",
      "Iteration 234, loss = 0.02001989\n",
      "Iteration 235, loss = 0.01993401\n",
      "Iteration 236, loss = 0.01981493\n",
      "Iteration 237, loss = 0.01977930\n",
      "Iteration 238, loss = 0.01969601\n",
      "Iteration 239, loss = 0.01954385\n",
      "Iteration 240, loss = 0.01950437\n",
      "Iteration 241, loss = 0.01969420\n",
      "Iteration 242, loss = 0.01949508\n",
      "Iteration 243, loss = 0.01937883\n",
      "Iteration 244, loss = 0.01919508\n",
      "Iteration 245, loss = 0.01921369\n",
      "Iteration 246, loss = 0.01901015\n",
      "Iteration 247, loss = 0.01898396\n",
      "Iteration 248, loss = 0.01891066\n",
      "Iteration 249, loss = 0.01882012\n",
      "Iteration 250, loss = 0.01876445\n",
      "Iteration 251, loss = 0.01856641\n",
      "Iteration 252, loss = 0.01855665\n",
      "Iteration 253, loss = 0.01841109\n",
      "Iteration 254, loss = 0.01845243\n",
      "Iteration 255, loss = 0.01833101\n",
      "Iteration 256, loss = 0.01822750\n",
      "Iteration 257, loss = 0.01817904\n",
      "Iteration 258, loss = 0.01808073\n",
      "Iteration 259, loss = 0.01801982\n",
      "Iteration 260, loss = 0.01801815\n",
      "Iteration 261, loss = 0.01788131\n",
      "Iteration 262, loss = 0.01782226\n",
      "Iteration 263, loss = 0.01777034\n",
      "Iteration 264, loss = 0.01766164\n",
      "Iteration 265, loss = 0.01764652\n",
      "Iteration 266, loss = 0.01758865\n",
      "Iteration 267, loss = 0.01747505\n",
      "Iteration 268, loss = 0.01750900\n",
      "Iteration 269, loss = 0.01733914\n",
      "Iteration 270, loss = 0.01763793\n",
      "Iteration 271, loss = 0.01732790\n",
      "Iteration 272, loss = 0.01719354\n",
      "Iteration 273, loss = 0.01703454\n",
      "Iteration 274, loss = 0.01698495\n",
      "Iteration 275, loss = 0.01692986\n",
      "Iteration 276, loss = 0.01688006\n",
      "Iteration 277, loss = 0.01686183\n",
      "Iteration 278, loss = 0.01670661\n",
      "Iteration 279, loss = 0.01666408\n",
      "Iteration 280, loss = 0.01664307\n",
      "Iteration 281, loss = 0.01656888\n",
      "Iteration 282, loss = 0.01648375\n",
      "Iteration 283, loss = 0.01639314\n",
      "Iteration 284, loss = 0.01636219\n",
      "Iteration 285, loss = 0.01627353\n",
      "Iteration 286, loss = 0.01623578\n",
      "Iteration 287, loss = 0.01613990\n",
      "Iteration 288, loss = 0.01615407\n",
      "Iteration 289, loss = 0.01608502\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 87.4806800618238\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69451633\n",
      "Iteration 2, loss = 0.68560226\n",
      "Iteration 3, loss = 0.67611322\n",
      "Iteration 4, loss = 0.66306234\n",
      "Iteration 5, loss = 0.64578509\n",
      "Iteration 6, loss = 0.62478285\n",
      "Iteration 7, loss = 0.60010584\n",
      "Iteration 8, loss = 0.57314304\n",
      "Iteration 9, loss = 0.54353416\n",
      "Iteration 10, loss = 0.51340410\n",
      "Iteration 11, loss = 0.48315183\n",
      "Iteration 12, loss = 0.45419234\n",
      "Iteration 13, loss = 0.42584702\n",
      "Iteration 14, loss = 0.39893587\n",
      "Iteration 15, loss = 0.37424166\n",
      "Iteration 16, loss = 0.35195883\n",
      "Iteration 17, loss = 0.33084784\n",
      "Iteration 18, loss = 0.31193425\n",
      "Iteration 19, loss = 0.29512003\n",
      "Iteration 20, loss = 0.27927148\n",
      "Iteration 21, loss = 0.26489938\n",
      "Iteration 22, loss = 0.25201337\n",
      "Iteration 23, loss = 0.24046450\n",
      "Iteration 24, loss = 0.22961693\n",
      "Iteration 25, loss = 0.21962327\n",
      "Iteration 26, loss = 0.21067729\n",
      "Iteration 27, loss = 0.20218395\n",
      "Iteration 28, loss = 0.19461628\n",
      "Iteration 29, loss = 0.18740180\n",
      "Iteration 30, loss = 0.18075769\n",
      "Iteration 31, loss = 0.17469188\n",
      "Iteration 32, loss = 0.16932866\n",
      "Iteration 33, loss = 0.16381677\n",
      "Iteration 34, loss = 0.15851096\n",
      "Iteration 35, loss = 0.15389087\n",
      "Iteration 36, loss = 0.14930516\n",
      "Iteration 37, loss = 0.14503031\n",
      "Iteration 38, loss = 0.14078668\n",
      "Iteration 39, loss = 0.13715522\n",
      "Iteration 40, loss = 0.13437176\n",
      "Iteration 41, loss = 0.13029351\n",
      "Iteration 42, loss = 0.12671901\n",
      "Iteration 43, loss = 0.12393582\n",
      "Iteration 44, loss = 0.12048321\n",
      "Iteration 45, loss = 0.11759894\n",
      "Iteration 46, loss = 0.11502109\n",
      "Iteration 47, loss = 0.11235547\n",
      "Iteration 48, loss = 0.10998588\n",
      "Iteration 49, loss = 0.10727472\n",
      "Iteration 50, loss = 0.10492268\n",
      "Iteration 51, loss = 0.10270567\n",
      "Iteration 52, loss = 0.10049734\n",
      "Iteration 53, loss = 0.09852416\n",
      "Iteration 54, loss = 0.09667994\n",
      "Iteration 55, loss = 0.09462811\n",
      "Iteration 56, loss = 0.09274641\n",
      "Iteration 57, loss = 0.09091566\n",
      "Iteration 58, loss = 0.08925531\n",
      "Iteration 59, loss = 0.08751674\n",
      "Iteration 60, loss = 0.08572673\n",
      "Iteration 61, loss = 0.08428250\n",
      "Iteration 62, loss = 0.08280810\n",
      "Iteration 63, loss = 0.08139748\n",
      "Iteration 64, loss = 0.08029827\n",
      "Iteration 65, loss = 0.07850056\n",
      "Iteration 66, loss = 0.07723673\n",
      "Iteration 67, loss = 0.07569054\n",
      "Iteration 68, loss = 0.07463843\n",
      "Iteration 69, loss = 0.07323451\n",
      "Iteration 70, loss = 0.07209504\n",
      "Iteration 71, loss = 0.07093781\n",
      "Iteration 72, loss = 0.06969145\n",
      "Iteration 73, loss = 0.06874593\n",
      "Iteration 74, loss = 0.06768698\n",
      "Iteration 75, loss = 0.06654387\n",
      "Iteration 76, loss = 0.06565707\n",
      "Iteration 77, loss = 0.06475149\n",
      "Iteration 78, loss = 0.06391668\n",
      "Iteration 79, loss = 0.06322823\n",
      "Iteration 80, loss = 0.06183419\n",
      "Iteration 81, loss = 0.06120127\n",
      "Iteration 82, loss = 0.06027104\n",
      "Iteration 83, loss = 0.05940002\n",
      "Iteration 84, loss = 0.05858627\n",
      "Iteration 85, loss = 0.05790654\n",
      "Iteration 86, loss = 0.05720280\n",
      "Iteration 87, loss = 0.05627169\n",
      "Iteration 88, loss = 0.05566170\n",
      "Iteration 89, loss = 0.05509829\n",
      "Iteration 90, loss = 0.05428826\n",
      "Iteration 91, loss = 0.05362999\n",
      "Iteration 92, loss = 0.05285034\n",
      "Iteration 93, loss = 0.05232098\n",
      "Iteration 94, loss = 0.05158000\n",
      "Iteration 95, loss = 0.05120404\n",
      "Iteration 96, loss = 0.05037232\n",
      "Iteration 97, loss = 0.04992960\n",
      "Iteration 98, loss = 0.04925240\n",
      "Iteration 99, loss = 0.04874742\n",
      "Iteration 100, loss = 0.04828157\n",
      "Iteration 101, loss = 0.04791031\n",
      "Iteration 102, loss = 0.04718019\n",
      "Iteration 103, loss = 0.04668763\n",
      "Iteration 104, loss = 0.04624417\n",
      "Iteration 105, loss = 0.04562688\n",
      "Iteration 106, loss = 0.04535569\n",
      "Iteration 107, loss = 0.04475584\n",
      "Iteration 108, loss = 0.04428428\n",
      "Iteration 109, loss = 0.04379396\n",
      "Iteration 110, loss = 0.04339161\n",
      "Iteration 111, loss = 0.04290095\n",
      "Iteration 112, loss = 0.04255832\n",
      "Iteration 113, loss = 0.04214185\n",
      "Iteration 114, loss = 0.04190179\n",
      "Iteration 115, loss = 0.04129363\n",
      "Iteration 116, loss = 0.04097810\n",
      "Iteration 117, loss = 0.04075911\n",
      "Iteration 118, loss = 0.04028843\n",
      "Iteration 119, loss = 0.04001689\n",
      "Iteration 120, loss = 0.03945106\n",
      "Iteration 121, loss = 0.03934549\n",
      "Iteration 122, loss = 0.03870105\n",
      "Iteration 123, loss = 0.03842614\n",
      "Iteration 124, loss = 0.03804663\n",
      "Iteration 125, loss = 0.03775358\n",
      "Iteration 126, loss = 0.03741515\n",
      "Iteration 127, loss = 0.03721569\n",
      "Iteration 128, loss = 0.03681249\n",
      "Iteration 129, loss = 0.03649874\n",
      "Iteration 130, loss = 0.03621705\n",
      "Iteration 131, loss = 0.03594304\n",
      "Iteration 132, loss = 0.03558929\n",
      "Iteration 133, loss = 0.03528276\n",
      "Iteration 134, loss = 0.03510931\n",
      "Iteration 135, loss = 0.03472513\n",
      "Iteration 136, loss = 0.03444695\n",
      "Iteration 137, loss = 0.03419054\n",
      "Iteration 138, loss = 0.03397677\n",
      "Iteration 139, loss = 0.03367476\n",
      "Iteration 140, loss = 0.03341535\n",
      "Iteration 141, loss = 0.03321651\n",
      "Iteration 142, loss = 0.03298075\n",
      "Iteration 143, loss = 0.03271282\n",
      "Iteration 144, loss = 0.03245937\n",
      "Iteration 145, loss = 0.03227405\n",
      "Iteration 146, loss = 0.03197775\n",
      "Iteration 147, loss = 0.03172754\n",
      "Iteration 148, loss = 0.03150220\n",
      "Iteration 149, loss = 0.03129297\n",
      "Iteration 150, loss = 0.03114211\n",
      "Iteration 151, loss = 0.03086913\n",
      "Iteration 152, loss = 0.03067224\n",
      "Iteration 153, loss = 0.03044660\n",
      "Iteration 154, loss = 0.03049145\n",
      "Iteration 155, loss = 0.03017591\n",
      "Iteration 156, loss = 0.02989387\n",
      "Iteration 157, loss = 0.02977448\n",
      "Iteration 158, loss = 0.02954785\n",
      "Iteration 159, loss = 0.02934127\n",
      "Iteration 160, loss = 0.02947874\n",
      "Iteration 161, loss = 0.02926114\n",
      "Iteration 162, loss = 0.02884976\n",
      "Iteration 163, loss = 0.02864397\n",
      "Iteration 164, loss = 0.02838327\n",
      "Iteration 165, loss = 0.02830418\n",
      "Iteration 166, loss = 0.02813666\n",
      "Iteration 167, loss = 0.02792161\n",
      "Iteration 168, loss = 0.02772640\n",
      "Iteration 169, loss = 0.02773062\n",
      "Iteration 170, loss = 0.02753729\n",
      "Iteration 171, loss = 0.02724707\n",
      "Iteration 172, loss = 0.02721739\n",
      "Iteration 173, loss = 0.02697870\n",
      "Iteration 174, loss = 0.02673005\n",
      "Iteration 175, loss = 0.02691858\n",
      "Iteration 176, loss = 0.02659586\n",
      "Iteration 177, loss = 0.02638058\n",
      "Iteration 178, loss = 0.02623663\n",
      "Iteration 179, loss = 0.02610230\n",
      "Iteration 180, loss = 0.02594057\n",
      "Iteration 181, loss = 0.02595806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 182, loss = 0.02576360\n",
      "Iteration 183, loss = 0.02555292\n",
      "Iteration 184, loss = 0.02534721\n",
      "Iteration 185, loss = 0.02533031\n",
      "Iteration 186, loss = 0.02506326\n",
      "Iteration 187, loss = 0.02499971\n",
      "Iteration 188, loss = 0.02487833\n",
      "Iteration 189, loss = 0.02473813\n",
      "Iteration 190, loss = 0.02494206\n",
      "Iteration 191, loss = 0.02460337\n",
      "Iteration 192, loss = 0.02435058\n",
      "Iteration 193, loss = 0.02420975\n",
      "Iteration 194, loss = 0.02411635\n",
      "Iteration 195, loss = 0.02397669\n",
      "Iteration 196, loss = 0.02380620\n",
      "Iteration 197, loss = 0.02373515\n",
      "Iteration 198, loss = 0.02376252\n",
      "Iteration 199, loss = 0.02372071\n",
      "Iteration 200, loss = 0.02341572\n",
      "Iteration 201, loss = 0.02325714\n",
      "Iteration 202, loss = 0.02315352\n",
      "Iteration 203, loss = 0.02312526\n",
      "Iteration 204, loss = 0.02297449\n",
      "Iteration 205, loss = 0.02284958\n",
      "Iteration 206, loss = 0.02268991\n",
      "Iteration 207, loss = 0.02262180\n",
      "Iteration 208, loss = 0.02249471\n",
      "Iteration 209, loss = 0.02250662\n",
      "Iteration 210, loss = 0.02231958\n",
      "Iteration 211, loss = 0.02218618\n",
      "Iteration 212, loss = 0.02207911\n",
      "Iteration 213, loss = 0.02196547\n",
      "Iteration 214, loss = 0.02192046\n",
      "Iteration 215, loss = 0.02182634\n",
      "Iteration 216, loss = 0.02172543\n",
      "Iteration 217, loss = 0.02162023\n",
      "Iteration 218, loss = 0.02147175\n",
      "Iteration 219, loss = 0.02149477\n",
      "Iteration 220, loss = 0.02131855\n",
      "Iteration 221, loss = 0.02131833\n",
      "Iteration 222, loss = 0.02103468\n",
      "Iteration 223, loss = 0.02112995\n",
      "Iteration 224, loss = 0.02087576\n",
      "Iteration 225, loss = 0.02094911\n",
      "Iteration 226, loss = 0.02080667\n",
      "Iteration 227, loss = 0.02060809\n",
      "Iteration 228, loss = 0.02053067\n",
      "Iteration 229, loss = 0.02051372\n",
      "Iteration 230, loss = 0.02028509\n",
      "Iteration 231, loss = 0.02029973\n",
      "Iteration 232, loss = 0.02014427\n",
      "Iteration 233, loss = 0.02005590\n",
      "Iteration 234, loss = 0.02003197\n",
      "Iteration 235, loss = 0.01996273\n",
      "Iteration 236, loss = 0.01982986\n",
      "Iteration 237, loss = 0.01970367\n",
      "Iteration 238, loss = 0.01960703\n",
      "Iteration 239, loss = 0.01956304\n",
      "Iteration 240, loss = 0.01954472\n",
      "Iteration 241, loss = 0.01933937\n",
      "Iteration 242, loss = 0.01940603\n",
      "Iteration 243, loss = 0.01918504\n",
      "Iteration 244, loss = 0.01911737\n",
      "Iteration 245, loss = 0.01902425\n",
      "Iteration 246, loss = 0.01897175\n",
      "Iteration 247, loss = 0.01895892\n",
      "Iteration 248, loss = 0.01883538\n",
      "Iteration 249, loss = 0.01874154\n",
      "Iteration 250, loss = 0.01870336\n",
      "Iteration 251, loss = 0.01861488\n",
      "Iteration 252, loss = 0.01848713\n",
      "Iteration 253, loss = 0.01844145\n",
      "Iteration 254, loss = 0.01832948\n",
      "Iteration 255, loss = 0.01834906\n",
      "Iteration 256, loss = 0.01823961\n",
      "Iteration 257, loss = 0.01815982\n",
      "Iteration 258, loss = 0.01804176\n",
      "Iteration 259, loss = 0.01794463\n",
      "Iteration 260, loss = 0.01795249\n",
      "Iteration 261, loss = 0.01780213\n",
      "Iteration 262, loss = 0.01771877\n",
      "Iteration 263, loss = 0.01770264\n",
      "Iteration 264, loss = 0.01762084\n",
      "Iteration 265, loss = 0.01753911\n",
      "Iteration 266, loss = 0.01744666\n",
      "Iteration 267, loss = 0.01736672\n",
      "Iteration 268, loss = 0.01730059\n",
      "Iteration 269, loss = 0.01736852\n",
      "Iteration 270, loss = 0.01722597\n",
      "Iteration 271, loss = 0.01715048\n",
      "Iteration 272, loss = 0.01708177\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 87.4806800618238\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 88.4080370942813 %\n",
      "Fold 1: 88.02163833075734 %\n",
      "Fold 2: 87.24884080370943 %\n",
      "Fold 3: 87.4806800618238 %\n",
      "Fold 4: 87.4806800618238 %\n",
      "Average: 87.72797527047913 %\n",
      "Accuracy:  0.8609394313967862\n",
      "Precision:  0.8559423769507803\n",
      "Recall:  0.871638141809291\n",
      "F1-Score:  0.8637189582071472\n",
      "AUC:  0.8608190709046454\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_mlp(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "y_pred=clf.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 81.76197836166924\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 81.68469860896445\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 80.75734157650696\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 82.61205564142195\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 80.370942812983\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 81.76197836166924 %\n",
      "Fold 1: 81.68469860896445 %\n",
      "Fold 2: 80.75734157650696 %\n",
      "Fold 3: 82.61205564142195 %\n",
      "Fold 4: 80.370942812983 %\n",
      "Average: 81.43740340030912 %\n",
      "Accuracy:  0.6687268232385661\n",
      "Precision:  0.7067448680351907\n",
      "Recall:  0.589242053789731\n",
      "F1-Score:  0.6426666666666666\n",
      "AUC:  0.6696210268948656\n"
     ]
    }
   ],
   "source": [
    "random_forest=k_fold_cv_rforest(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "y_pred=random_forest.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

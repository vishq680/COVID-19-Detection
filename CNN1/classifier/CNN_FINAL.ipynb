{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8a127c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c46fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa49613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febb1f4",
   "metadata": {},
   "source": [
    "#Data \n",
    "0->Covid\n",
    "1->No Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bdb2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Covid','No Covid']\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0452b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape all images to 64x64 and apply tensor transformation\n",
    "dataset = torchvision.datasets.ImageFolder(root=\"./data\",transform=transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Resize([227,227])\n",
    "                                                            # transforms.Grayscale(num_output_channels=1)\n",
    "                                                            ]))\n",
    "# testset = torchvision.datasets.ImageFolder(root=\"./xray\",train=False,transform=transforms.Compose([transforms.Resize([300,305]),transforms.ToTensor()]))\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977e9729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n",
      "1617.5 404.5\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "trainset,testset=torch.utils.data.random_split(dataset,[round(0.8*len(dataset)),round(0.2*len(dataset))],generator=torch.Generator().manual_seed(42))\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=4,shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=4,shuffle=False)\n",
    "print(len(trainset)/batch_size,len(testset)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa978d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 227, 227]) tensor([1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter=iter(trainloader)\n",
    "images,labels=dataiter.next()\n",
    "print(images.shape,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17ca4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img):\n",
    "    npimg=img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515436a",
   "metadata": {},
   "source": [
    "# Preparing The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd925ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader,model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total,correct=0,0\n",
    "        for data in dataloader:\n",
    "            inputs,labels=data\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            outputs=model(inputs)\n",
    "    #         print(outputs)\n",
    "    #         print(outputs,labels)\n",
    "            m = nn.Sigmoid()\n",
    "            outputs=m(outputs)\n",
    "            pred=outputs>=0.5\n",
    "            pred=pred.flatten()\n",
    "            total+=labels.size(0)\n",
    "            # labels=torch.add(labels,-1)\n",
    "            # print(pred,labels)\n",
    "    #         print(list(map(lambda a: classes[a],pred)),list(map(lambda a: classes[a],labels)))\n",
    "            correct+=(pred==labels).sum().item()\n",
    "    print(correct,total)\n",
    "    model.train()\n",
    "    return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bf8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.representation_network=nn.Sequential(\n",
    "            nn.Conv2d(3,32,3), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2,stride=3),\n",
    "            nn.Conv2d(32,32,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=3),\n",
    "        )\n",
    "        self.classification_network=nn.Sequential(\n",
    "            nn.Linear(18432,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,1),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "#         print(x.shape)\n",
    "        x=self.representation_network(x)\n",
    "#         print(x.shape)\n",
    "        # flattening of the vector=> same dimension of first index(batch size) , everythign else is flattened(-1)\n",
    "        x=x.view(x.size(0),-1)\n",
    "#         print(x.shape)\n",
    "        x=self.classification_network(x)\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f693392",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "# net=torch.load(\"./coronaCNN.pt\")\n",
    "# net.load_state_dict(torch.load(\"./coronaCNN_State.pt\"))\n",
    "opt=optim.Adam(params=net.parameters())\n",
    "net=net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dfdd4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(net(images.to(device)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39c92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,dataloader,epochs=15):\n",
    "    loss_fn=nn.BCEWithLogitsLoss().to(device)\n",
    "    opt=optim.Adam(params=net.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for i,data in enumerate(dataloader,0):\n",
    "            inputs,labels=data\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            opt.zero_grad()\n",
    "            outputs=net(inputs)\n",
    "            labels=labels.unsqueeze(-1)\n",
    "            labels = labels.type_as(outputs)\n",
    "    #         print(outputs)\n",
    "            loss=loss_fn(outputs,labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            torch.cuda.empty_cache()\n",
    "            del inputs,labels,outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7554c98",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a83ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ef3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "    '''\n",
    "    net.load_state_dict(torch.load(\"CNN-1_originalstate.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830d3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(model,dataset,loss_function,k_folds=5,epochs=10):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "              dataset, \n",
    "              batch_size=batch_size, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "              dataset,\n",
    "              batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        network = model\n",
    "        network.apply(reset_weights)\n",
    "        optimizer = optim.Adam(network.parameters())\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, epochs):\n",
    "\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Perform forward pass\n",
    "                outputs = network(inputs)\n",
    "                targets = targets.unsqueeze(-1)\n",
    "                targets = targets.type_as(outputs)\n",
    "                # Compute loss\n",
    "                loss = loss_function(outputs, targets)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                if i % 500 == 499:\n",
    "                    print('Loss after mini-batch %5d: %.3f' %\n",
    "                      (i + 1, current_loss / 500))\n",
    "                    current_loss = 0.0\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving the trained model.')\n",
    "        save_path = f'./CNN-fold-{fold}.pth'\n",
    "        torch.save(network, save_path)\n",
    "\n",
    "        # Evaluation for this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "                inputs,targets=inputs.to(device),targets.to(device)\n",
    "                # Generate outputs\n",
    "                outputs = network(inputs)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs=m(outputs)\n",
    "                pred=outputs>=0.5\n",
    "                pred=pred.flatten()\n",
    "                # Set total and correct\n",
    "                total += targets.size(0)\n",
    "                correct += (pred == targets).sum().item()\n",
    "\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54913759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=18432, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.547\n",
      "Loss after mini-batch  1000: 0.390\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.289\n",
      "Loss after mini-batch  1000: 0.308\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.212\n",
      "Loss after mini-batch  1000: 0.215\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.162\n",
      "Loss after mini-batch  1000: 0.158\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.159\n",
      "Loss after mini-batch  1000: 0.116\n",
      "Starting epoch 6\n",
      "Loss after mini-batch   500: 0.114\n",
      "Loss after mini-batch  1000: 0.103\n",
      "Starting epoch 7\n",
      "Loss after mini-batch   500: 0.087\n",
      "Loss after mini-batch  1000: 0.094\n",
      "Starting epoch 8\n",
      "Loss after mini-batch   500: 0.057\n",
      "Loss after mini-batch  1000: 0.091\n",
      "Starting epoch 9\n",
      "Loss after mini-batch   500: 0.054\n",
      "Loss after mini-batch  1000: 0.050\n",
      "Starting epoch 10\n",
      "Loss after mini-batch   500: 0.056\n",
      "Loss after mini-batch  1000: 0.057\n",
      "Starting epoch 11\n",
      "Loss after mini-batch   500: 0.035\n",
      "Loss after mini-batch  1000: 0.042\n",
      "Starting epoch 12\n",
      "Loss after mini-batch   500: 0.049\n",
      "Loss after mini-batch  1000: 0.086\n",
      "Starting epoch 13\n",
      "Loss after mini-batch   500: 0.035\n",
      "Loss after mini-batch  1000: 0.041\n",
      "Starting epoch 14\n",
      "Loss after mini-batch   500: 0.019\n",
      "Loss after mini-batch  1000: 0.043\n",
      "Starting epoch 15\n",
      "Loss after mini-batch   500: 0.021\n",
      "Loss after mini-batch  1000: 0.054\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 0: 91 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=18432, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.545\n",
      "Loss after mini-batch  1000: 0.428\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.320\n",
      "Loss after mini-batch  1000: 0.282\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.237\n",
      "Loss after mini-batch  1000: 0.242\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.189\n",
      "Loss after mini-batch  1000: 0.184\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.160\n",
      "Loss after mini-batch  1000: 0.164\n",
      "Starting epoch 6\n",
      "Loss after mini-batch   500: 0.193\n",
      "Loss after mini-batch  1000: 0.170\n",
      "Starting epoch 7\n",
      "Loss after mini-batch   500: 0.151\n",
      "Loss after mini-batch  1000: 0.131\n",
      "Starting epoch 8\n",
      "Loss after mini-batch   500: 0.096\n",
      "Loss after mini-batch  1000: 0.123\n",
      "Starting epoch 9\n",
      "Loss after mini-batch   500: 0.088\n",
      "Loss after mini-batch  1000: 0.092\n",
      "Starting epoch 10\n",
      "Loss after mini-batch   500: 0.069\n",
      "Loss after mini-batch  1000: 0.080\n",
      "Starting epoch 11\n",
      "Loss after mini-batch   500: 0.067\n",
      "Loss after mini-batch  1000: 0.071\n",
      "Starting epoch 12\n",
      "Loss after mini-batch   500: 0.068\n",
      "Loss after mini-batch  1000: 0.069\n",
      "Starting epoch 13\n",
      "Loss after mini-batch   500: 0.042\n",
      "Loss after mini-batch  1000: 0.041\n",
      "Starting epoch 14\n",
      "Loss after mini-batch   500: 0.087\n",
      "Loss after mini-batch  1000: 0.057\n",
      "Starting epoch 15\n",
      "Loss after mini-batch   500: 0.054\n",
      "Loss after mini-batch  1000: 0.037\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 1: 93 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=18432, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.538\n",
      "Loss after mini-batch  1000: 0.455\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.339\n",
      "Loss after mini-batch  1000: 0.297\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.251\n",
      "Loss after mini-batch  1000: 0.241\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.184\n",
      "Loss after mini-batch  1000: 0.189\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.148\n",
      "Loss after mini-batch  1000: 0.147\n",
      "Starting epoch 6\n",
      "Loss after mini-batch   500: 0.124\n",
      "Loss after mini-batch  1000: 0.136\n",
      "Starting epoch 7\n",
      "Loss after mini-batch   500: 0.100\n",
      "Loss after mini-batch  1000: 0.095\n",
      "Starting epoch 8\n",
      "Loss after mini-batch   500: 0.081\n",
      "Loss after mini-batch  1000: 0.089\n",
      "Starting epoch 9\n",
      "Loss after mini-batch   500: 0.088\n",
      "Loss after mini-batch  1000: 0.088\n",
      "Starting epoch 10\n",
      "Loss after mini-batch   500: 0.054\n",
      "Loss after mini-batch  1000: 0.085\n",
      "Starting epoch 11\n",
      "Loss after mini-batch   500: 0.061\n",
      "Loss after mini-batch  1000: 0.049\n",
      "Starting epoch 12\n",
      "Loss after mini-batch   500: 0.050\n",
      "Loss after mini-batch  1000: 0.048\n",
      "Starting epoch 13\n",
      "Loss after mini-batch   500: 0.048\n",
      "Loss after mini-batch  1000: 0.041\n",
      "Starting epoch 14\n",
      "Loss after mini-batch   500: 0.053\n",
      "Loss after mini-batch  1000: 0.065\n",
      "Starting epoch 15\n",
      "Loss after mini-batch   500: 0.029\n",
      "Loss after mini-batch  1000: 0.087\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 2: 91 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=18432, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.493\n",
      "Loss after mini-batch  1000: 0.395\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.304\n",
      "Loss after mini-batch  1000: 0.306\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.215\n",
      "Loss after mini-batch  1000: 0.221\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.188\n",
      "Loss after mini-batch  1000: 0.181\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.161\n",
      "Loss after mini-batch  1000: 0.134\n",
      "Starting epoch 6\n",
      "Loss after mini-batch   500: 0.119\n",
      "Loss after mini-batch  1000: 0.108\n",
      "Starting epoch 7\n",
      "Loss after mini-batch   500: 0.095\n",
      "Loss after mini-batch  1000: 0.086\n",
      "Starting epoch 8\n",
      "Loss after mini-batch   500: 0.084\n",
      "Loss after mini-batch  1000: 0.086\n",
      "Starting epoch 9\n",
      "Loss after mini-batch   500: 0.078\n",
      "Loss after mini-batch  1000: 0.076\n",
      "Starting epoch 10\n",
      "Loss after mini-batch   500: 0.050\n",
      "Loss after mini-batch  1000: 0.063\n",
      "Starting epoch 11\n",
      "Loss after mini-batch   500: 0.040\n",
      "Loss after mini-batch  1000: 0.066\n",
      "Starting epoch 12\n",
      "Loss after mini-batch   500: 0.053\n",
      "Loss after mini-batch  1000: 0.049\n",
      "Starting epoch 13\n",
      "Loss after mini-batch   500: 0.037\n",
      "Loss after mini-batch  1000: 0.049\n",
      "Starting epoch 14\n",
      "Loss after mini-batch   500: 0.040\n",
      "Loss after mini-batch  1000: 0.045\n",
      "Starting epoch 15\n",
      "Loss after mini-batch   500: 0.031\n",
      "Loss after mini-batch  1000: 0.064\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 3: 91 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=18432, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch  1000: 0.358\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.270\n",
      "Loss after mini-batch  1000: 0.262\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.212\n",
      "Loss after mini-batch  1000: 0.195\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.184\n",
      "Loss after mini-batch  1000: 0.167\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.112\n",
      "Loss after mini-batch  1000: 0.143\n",
      "Starting epoch 6\n",
      "Loss after mini-batch   500: 0.100\n",
      "Loss after mini-batch  1000: 0.106\n",
      "Starting epoch 7\n",
      "Loss after mini-batch   500: 0.080\n",
      "Loss after mini-batch  1000: 0.101\n",
      "Starting epoch 8\n",
      "Loss after mini-batch   500: 0.054\n",
      "Loss after mini-batch  1000: 0.055\n",
      "Starting epoch 9\n",
      "Loss after mini-batch   500: 0.054\n",
      "Loss after mini-batch  1000: 0.083\n",
      "Starting epoch 10\n",
      "Loss after mini-batch   500: 0.078\n",
      "Loss after mini-batch  1000: 0.088\n",
      "Starting epoch 11\n",
      "Loss after mini-batch   500: 0.031\n",
      "Loss after mini-batch  1000: 0.038\n",
      "Starting epoch 12\n",
      "Loss after mini-batch   500: 0.022\n",
      "Loss after mini-batch  1000: 0.041\n",
      "Starting epoch 13\n",
      "Loss after mini-batch   500: 0.054\n",
      "Loss after mini-batch  1000: 0.034\n",
      "Starting epoch 14\n",
      "Loss after mini-batch   500: 0.018\n",
      "Loss after mini-batch  1000: 0.024\n",
      "Starting epoch 15\n",
      "Loss after mini-batch   500: 0.060\n",
      "Loss after mini-batch  1000: 0.037\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 4: 92 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 91.80834621329211 %\n",
      "Fold 1: 93.89489953632149 %\n",
      "Fold 2: 91.80834621329211 %\n",
      "Fold 3: 91.73106646058733 %\n",
      "Fold 4: 92.34930448222566 %\n",
      "Average: 92.31839258114374 %\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"861e7ab6-f904-4e72-92c8-e995be9005de\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"861e7ab6-f904-4e72-92c8-e995be9005de\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "net=CNN().to(device)\n",
    "loss_fn=nn.BCEWithLogitsLoss().to(device)\n",
    "data_set=trainset\n",
    "torch.save(net.state_dict(),\"CNN-1_originalstate.pt\")\n",
    "k_fold_cv(net,data_set,loss_fn,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f9d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_weights(net)\n",
    "train(net,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d578133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481 1618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.5327564894932"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(testloader,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2314173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,\"./CNN-1_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ab416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30896040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(dataloader,model):\n",
    "    y_true,y_pred=torch.tensor([]),torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total,correct=0,0\n",
    "        for data in dataloader:\n",
    "            inputs,labels=data\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            outputs=model(inputs)\n",
    "    #         print(outputs)\n",
    "    #         print(outputs,labels)\n",
    "            m = nn.Sigmoid()\n",
    "            outputs=m(outputs)\n",
    "            pred=outputs>=0.5\n",
    "            pred=pred.flatten()\n",
    "            y_true=torch.cat((y_true,copy.deepcopy(labels.cpu())),0)\n",
    "            y_pred=torch.cat((y_pred,copy.deepcopy(pred.cpu())),0)\n",
    "#             print(y_pred,y_true,y_pred==y_true,pred==labels)\n",
    "            total+=labels.size(0)\n",
    "            # labels=torch.add(labels,-1)\n",
    "            # print(pred,labels)\n",
    "    #         print(list(map(lambda a: classes[a],pred)),list(map(lambda a: classes[a],labels)))\n",
    "            correct+=(pred==labels).sum().item()\n",
    "#             print((pred==labels).sum())\n",
    "    print(\"Accuracy: \",accuracy_score(y_true,y_pred))\n",
    "    print(\"Precision: \",precision_score(y_true,y_pred))\n",
    "    print(\"Recall: \",recall_score(y_true,y_pred))\n",
    "    print(\"F1-Score: \",f1_score(y_true,y_pred))\n",
    "    print(\"AUC: \",roc_auc_score(y_true,y_pred))\n",
    "    print(correct,total)\n",
    "#     print(y_true,y_pred)\n",
    "    y_pred=y_pred.flatten()\n",
    "    y_true=y_true.flatten()\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    model.train()\n",
    "    return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a9c85ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.915327564894932\n",
      "Precision:  0.8927335640138409\n",
      "Recall:  0.9462102689486552\n",
      "F1-Score:  0.9186943620178042\n",
      "AUC:  0.9149801344743277\n",
      "1481 1618\n",
      "91.5327564894932\n"
     ]
    }
   ],
   "source": [
    "print(report(testloader,net))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

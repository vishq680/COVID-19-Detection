{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9c627b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e41fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1dbcc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc96b1",
   "metadata": {},
   "source": [
    "#Data \n",
    "0->Covid\n",
    "1->No Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5b16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Covid','No Covid']\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb6a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape all images to 64x64 and apply tensor transformation\n",
    "dataset = torchvision.datasets.ImageFolder(root=\"./Full\",transform=transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Resize([227,227])\n",
    "                                                            # transforms.Grayscale(num_output_channels=1)\n",
    "                                                            ]))\n",
    "# testset = torchvision.datasets.ImageFolder(root=\"./xray\",train=False,transform=transforms.Compose([transforms.Resize([300,305]),transforms.ToTensor()]))\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27eb8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "trainset,testset,valset=torch.utils.data.random_split(dataset,[round(0.8*len(dataset)),round(0.1*len(dataset)),round(0.1*len(dataset))],generator=torch.Generator().manual_seed(42))\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False)\n",
    "valloader=torch.utils.data.DataLoader(valset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393c1f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n",
      "1617.5 404.5\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "trainset,testset=torch.utils.data.random_split(dataset,[round(0.8*len(dataset)),round(0.2*len(dataset))],generator=torch.Generator().manual_seed(42))\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=4,shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=4,shuffle=False)\n",
    "print(len(trainset)/batch_size,len(testset)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7516f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 227, 227]) tensor([0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter=iter(trainloader)\n",
    "images,labels=dataiter.next()\n",
    "print(images.shape,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be806b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img):\n",
    "    npimg=img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385cf7c8",
   "metadata": {},
   "source": [
    "# Preparing The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949e767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader,model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total,correct=0,0\n",
    "        for data in dataloader:\n",
    "            inputs,labels=data\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            outputs=model(inputs)\n",
    "    #         print(outputs)\n",
    "    #         print(outputs,labels)\n",
    "            m = nn.Sigmoid()\n",
    "            outputs=m(outputs)\n",
    "            pred=outputs>=0.5\n",
    "            pred=pred.flatten()\n",
    "            total+=labels.size(0)\n",
    "            # labels=torch.add(labels,-1)\n",
    "            # print(pred,labels)\n",
    "    #         print(list(map(lambda a: classes[a],pred)),list(map(lambda a: classes[a],labels)))\n",
    "            correct+=(pred==labels).sum().item()\n",
    "    print(correct,total)\n",
    "    model.train()\n",
    "    return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7420edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.representation_network=nn.Sequential(\n",
    "            nn.Conv2d(3,32,3), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2,stride=3),\n",
    "            nn.Conv2d(32,32,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=3),\n",
    "            nn.Conv2d(32,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=3),\n",
    "        )\n",
    "        self.classification_network=nn.Sequential(\n",
    "            nn.Linear(3136,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "#         print(x.shape)\n",
    "        x=self.representation_network(x)\n",
    "#        print(x.shape)\n",
    "        # flattening of the vector=> same dimension of first index(batch size) , everythign else is flattened(-1)\n",
    "        x=x.view(x.size(0),-1)\n",
    "#        print(x.shape)\n",
    "        x=self.classification_network(x)\n",
    "#        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21340456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,dataloader,epochs=15):\n",
    "    loss_fn=nn.BCEWithLogitsLoss().to(device)\n",
    "    opt=optim.Adam(params=net.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for i,data in enumerate(dataloader,0):\n",
    "            inputs,labels=data\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            opt.zero_grad()\n",
    "            outputs=net(inputs)\n",
    "            labels=labels.unsqueeze(-1)\n",
    "            labels = labels.type_as(outputs)\n",
    "    #         print(outputs)\n",
    "            loss=loss_fn(outputs,labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            torch.cuda.empty_cache()\n",
    "            del inputs,labels,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b273cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "# net=torch.load(\"./coronaCNN.pt\")\n",
    "# net.load_state_dict(torch.load(\"./coronaCNN_State.pt\"))\n",
    "opt=optim.Adam(params=net.parameters())\n",
    "net=net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05f4f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(net(images.to(device)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36424c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 1618\n",
      "49.44375772558715\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"59f92de5-db49-4443-840c-696c6335472c\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"59f92de5-db49-4443-840c-696c6335472c\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"completed\"\n",
    "print(evaluation(testloader,net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107958c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),\"./coronaCNN_State.pt\")\n",
    "torch.save(net,\"./coronaCNN.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc332d",
   "metadata": {},
   "source": [
    "Test Accuracy and K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b48e3f",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a22a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78f27b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "    '''\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1025f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(model,dataset,loss_function,k_folds=5,epochs=10):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "              dataset, \n",
    "              batch_size=batch_size, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "              dataset,\n",
    "              batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        network = model\n",
    "        network.apply(reset_weights)\n",
    "        optimizer = optim.Adam(network.parameters())\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, epochs):\n",
    "\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Perform forward pass\n",
    "                outputs = network(inputs)\n",
    "                targets = targets.unsqueeze(-1)\n",
    "                targets = targets.type_as(outputs)\n",
    "                # Compute loss\n",
    "                loss = loss_function(outputs, targets)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                if i % 500 == 499:\n",
    "                    print('Loss after mini-batch %5d: %.3f' %\n",
    "                      (i + 1, current_loss / 500))\n",
    "                    current_loss = 0.0\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving the trained model.')\n",
    "        save_path = f'./py1/CNN-fold-{fold}.pth'\n",
    "        torch.save(network, save_path)\n",
    "\n",
    "        # Evaluation for this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "                inputs,targets=inputs.to(device),targets.to(device)\n",
    "                # Generate outputs\n",
    "                outputs = network(inputs)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs=m(outputs)\n",
    "                pred=outputs>=0.5\n",
    "                pred=pred.flatten()\n",
    "                # Set total and correct\n",
    "                total += targets.size(0)\n",
    "                correct += (pred == targets).sum().item()\n",
    "\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf5bfb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=3136, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.567\n",
      "Loss after mini-batch  1000: 0.408\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.302\n",
      "Loss after mini-batch  1000: 0.301\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.237\n",
      "Loss after mini-batch  1000: 0.238\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.186\n",
      "Loss after mini-batch  1000: 0.200\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.151\n",
      "Loss after mini-batch  1000: 0.164\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 0: 88 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=3136, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.590\n",
      "Loss after mini-batch  1000: 0.444\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.341\n",
      "Loss after mini-batch  1000: 0.318\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.267\n",
      "Loss after mini-batch  1000: 0.259\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.190\n",
      "Loss after mini-batch  1000: 0.219\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.164\n",
      "Loss after mini-batch  1000: 0.179\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 1: 90 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=3136, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.561\n",
      "Loss after mini-batch  1000: 0.388\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.302\n",
      "Loss after mini-batch  1000: 0.287\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.224\n",
      "Loss after mini-batch  1000: 0.240\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.209\n",
      "Loss after mini-batch  1000: 0.199\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.165\n",
      "Loss after mini-batch  1000: 0.182\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 2: 92 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=3136, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.579\n",
      "Loss after mini-batch  1000: 0.464\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.324\n",
      "Loss after mini-batch  1000: 0.326\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.261\n",
      "Loss after mini-batch  1000: 0.241\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.201\n",
      "Loss after mini-batch  1000: 0.200\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.152\n",
      "Loss after mini-batch  1000: 0.180\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 3: 92 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=3136, out_features=512, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=512, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 0.576\n",
      "Loss after mini-batch  1000: 0.443\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.365\n",
      "Loss after mini-batch  1000: 0.339\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.239\n",
      "Loss after mini-batch  1000: 0.260\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 0.207\n",
      "Loss after mini-batch  1000: 0.203\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 0.175\n",
      "Loss after mini-batch  1000: 0.159\n",
      "Training process has finished. Saving the trained model.\n",
      "Accuracy for fold 4: 90 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 88.63987635239567 %\n",
      "Fold 1: 90.1854714064915 %\n",
      "Fold 2: 92.58114374034004 %\n",
      "Fold 3: 92.65842349304482 %\n",
      "Fold 4: 90.95826893353942 %\n",
      "Average: 91.0046367851623 %\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"ef0957e8-6cf8-404c-80f3-2edd4c3e7502\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"ef0957e8-6cf8-404c-80f3-2edd4c3e7502\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "net=CNN().to(device)\n",
    "loss_fn=nn.BCEWithLogitsLoss().to(device)\n",
    "data_set=trainset\n",
    "k_fold_cv(net,data_set,loss_fn,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_weights(net)\n",
    "train(net,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c8146fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,\"./CNN6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d1eca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(dataloader,model):\n",
    "    y_true,y_pred=torch.tensor([]),torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total,correct=0,0\n",
    "        for data in dataloader:\n",
    "            inputs,labels=data\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            outputs=model(inputs)\n",
    "    #         print(outputs)\n",
    "    #         print(outputs,labels)\n",
    "            m = nn.Sigmoid()\n",
    "            outputs=m(outputs)\n",
    "            pred=outputs>=0.5\n",
    "            pred=pred.flatten()\n",
    "            y_true=torch.cat((y_true,copy.deepcopy(labels.cpu())),0)\n",
    "            y_pred=torch.cat((y_pred,copy.deepcopy(pred.cpu())),0)\n",
    "#             print(y_pred,y_true,y_pred==y_true,pred==labels)\n",
    "            total+=labels.size(0)\n",
    "            # labels=torch.add(labels,-1)\n",
    "            # print(pred,labels)\n",
    "    #         print(list(map(lambda a: classes[a],pred)),list(map(lambda a: classes[a],labels)))\n",
    "            correct+=(pred==labels).sum().item()\n",
    "#             print((pred==labels).sum())\n",
    "    print(\"Accuracy: \",accuracy_score(y_true,y_pred))\n",
    "    print(\"Precision: \",precision_score(y_true,y_pred))\n",
    "    print(\"Recall: \",recall_score(y_true,y_pred))\n",
    "    print(\"F1-Score: \",f1_score(y_true,y_pred))\n",
    "    print(\"AUC: \",roc_auc_score(y_true,y_pred))\n",
    "    print(correct,total)\n",
    "#     print(y_true,y_pred)\n",
    "    y_pred=y_pred.flatten()\n",
    "    y_true=y_true.flatten()\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    model.train()\n",
    "    return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfc41ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1bf59df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9184177997527813\n",
      "Precision:  0.9073634204275535\n",
      "Recall:  0.9339853300733496\n",
      "F1-Score:  0.9204819277108433\n",
      "AUC:  0.9182426650366747\n",
      "1486 1618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.84177997527811"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(testloader,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ddca45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

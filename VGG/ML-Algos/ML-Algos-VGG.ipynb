{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5380e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import copy\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f3cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ed854",
   "metadata": {},
   "source": [
    "# General ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d955724",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Covid','No Covid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f31ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61fefbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root=\"./data\",transform=transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Resize([227,227]),\n",
    "#                                                             transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                                                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ff911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "trainset,testset=torch.utils.data.random_split(dataset,[round(0.8*len(dataset)),round(0.2*len(dataset))],generator=torch.Generator().manual_seed(42))\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ec9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img,normal=False):\n",
    "    npimg=img.numpy()\n",
    "    if normal:\n",
    "#     img*mean(0.5) + SD(0.5) => unnormalizing the image\n",
    "        npimg=img.numpy()/2+0.5\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d55f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"508be681-4442-434c-88d3-f9380a3fb2c6\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"508be681-4442-434c-88d3-f9380a3fb2c6\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"completed\"\n",
    "dataiter=iter(trainloader)\n",
    "images,labels=dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c488a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, ['No Covid', 'No Covid', 'No Covid', 'No Covid'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_img(torchvision.utils.make_grid(images)),list(map(lambda a: classes[a],labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e95ea",
   "metadata": {},
   "source": [
    "## Extracting the Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(pl.LightningModule):\n",
    "    def get_first_FC_Layer(self,x):\n",
    "        x=self.feature_extractor(x).flatten(1)\n",
    "        x=self.classifier[0](x)\n",
    "        return x;\n",
    "    def get_Representation_Net(self,x):\n",
    "        x=self.feature_extractor(x).flatten(1)\n",
    "        return  x;\n",
    "#     def train_dataloader(self):\n",
    "#         return torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
    "#     def test_dataloader(self):\n",
    "#         return torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False)\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = optim.Adam(params=self.parameters(),lr=(self.lr or self.learning_rate))\n",
    "#         return optimizer\n",
    "    def __init__(self,learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        # init a pretrained vggnet\n",
    "        backbone = models.vgg16_bn(pretrained=True)\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        fc=[]\n",
    "        fc.extend([nn.Linear(in_features=25088,out_features=512),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(),\n",
    "           nn.Linear(in_features=512,out_features=128),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(),\n",
    "           nn.Linear(in_features=128,out_features=1)\n",
    "          ])\n",
    "        self.classifier=nn.Sequential(*fc)\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad=False\n",
    "#     def forward(self, x):\n",
    "#         with torch.no_grad():\n",
    "#             representations = self.feature_extractor(x).flatten(1)\n",
    "#         x=self.classifier(representations)\n",
    "#         return x;\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         inputs, labels = batch\n",
    "#         pred = self.forward(inputs)\n",
    "#         labels = labels.unsqueeze(-1)\n",
    "# #         self.log('train_acc_step', torchmetrics.functional.accuracy(pred, labels,average='micro', mdmc_average='global', num_classes=num_classes, multiclass=False),on_step=True)\n",
    "# #         self.log('conf matrix',torchmetrics.functional.confusion_matrix(pred,labels,num_classes=num_classes, normalize=None, threshold=0.5, multilabel=False),on_step=True,)\n",
    "#         labels = labels.type_as(pred)\n",
    "# #         print(labels)\n",
    "#         loss = nn.BCEWithLogitsLoss()(pred,labels)\n",
    "#         self.log('train_loss', loss, on_epoch=True, prog_bar=True, logger=False)\n",
    "        \n",
    "#         return loss     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed675e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg=VGG()\n",
    "# Loading weights\n",
    "vgg.load_state_dict(torch.load(\"VGG-final.pth\").state_dict())\n",
    "# print(vgg.get_first_FC_Layer(images).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b926c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "print(vgg.get_first_FC_Layer(images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe627d0e",
   "metadata": {},
   "source": [
    "### Getting The Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4333e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 512)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "Done with the batch: 405\n",
      "Done with the batch: 406\n",
      "Done with the batch: 407\n",
      "Done with the batch: 408\n",
      "Done with the batch: 409\n",
      "Done with the batch: 410\n",
      "Done with the batch: 411\n",
      "Done with the batch: 412\n",
      "Done with the batch: 413\n",
      "Done with the batch: 414\n",
      "Done with the batch: 415\n",
      "Done with the batch: 416\n",
      "Done with the batch: 417\n",
      "Done with the batch: 418\n",
      "Done with the batch: 419\n",
      "Done with the batch: 420\n",
      "Done with the batch: 421\n",
      "Done with the batch: 422\n",
      "Done with the batch: 423\n",
      "Done with the batch: 424\n",
      "Done with the batch: 425\n",
      "Done with the batch: 426\n",
      "Done with the batch: 427\n",
      "Done with the batch: 428\n",
      "Done with the batch: 429\n",
      "Done with the batch: 430\n",
      "Done with the batch: 431\n",
      "Done with the batch: 432\n",
      "Done with the batch: 433\n",
      "Done with the batch: 434\n",
      "Done with the batch: 435\n",
      "Done with the batch: 436\n",
      "Done with the batch: 437\n",
      "Done with the batch: 438\n",
      "Done with the batch: 439\n",
      "Done with the batch: 440\n",
      "Done with the batch: 441\n",
      "Done with the batch: 442\n",
      "Done with the batch: 443\n",
      "Done with the batch: 444\n",
      "Done with the batch: 445\n",
      "Done with the batch: 446\n",
      "Done with the batch: 447\n",
      "Done with the batch: 448\n",
      "Done with the batch: 449\n",
      "Done with the batch: 450\n",
      "Done with the batch: 451\n",
      "Done with the batch: 452\n",
      "Done with the batch: 453\n",
      "Done with the batch: 454\n",
      "Done with the batch: 455\n",
      "Done with the batch: 456\n",
      "Done with the batch: 457\n",
      "Done with the batch: 458\n",
      "Done with the batch: 459\n",
      "Done with the batch: 460\n",
      "Done with the batch: 461\n",
      "Done with the batch: 462\n",
      "Done with the batch: 463\n",
      "Done with the batch: 464\n",
      "Done with the batch: 465\n",
      "Done with the batch: 466\n",
      "Done with the batch: 467\n",
      "Done with the batch: 468\n",
      "Done with the batch: 469\n",
      "Done with the batch: 470\n",
      "Done with the batch: 471\n",
      "Done with the batch: 472\n",
      "Done with the batch: 473\n",
      "Done with the batch: 474\n",
      "Done with the batch: 475\n",
      "Done with the batch: 476\n",
      "Done with the batch: 477\n",
      "Done with the batch: 478\n",
      "Done with the batch: 479\n",
      "Done with the batch: 480\n",
      "Done with the batch: 481\n",
      "Done with the batch: 482\n",
      "Done with the batch: 483\n",
      "Done with the batch: 484\n",
      "Done with the batch: 485\n",
      "Done with the batch: 486\n",
      "Done with the batch: 487\n",
      "Done with the batch: 488\n",
      "Done with the batch: 489\n",
      "Done with the batch: 490\n",
      "Done with the batch: 491\n",
      "Done with the batch: 492\n",
      "Done with the batch: 493\n",
      "Done with the batch: 494\n",
      "Done with the batch: 495\n",
      "Done with the batch: 496\n",
      "Done with the batch: 497\n",
      "Done with the batch: 498\n",
      "Done with the batch: 499\n",
      "Done with the batch: 500\n",
      "Done with the batch: 501\n",
      "Done with the batch: 502\n",
      "Done with the batch: 503\n",
      "Done with the batch: 504\n",
      "Done with the batch: 505\n",
      "Done with the batch: 506\n",
      "Done with the batch: 507\n",
      "Done with the batch: 508\n",
      "Done with the batch: 509\n",
      "Done with the batch: 510\n",
      "Done with the batch: 511\n",
      "Done with the batch: 512\n",
      "Done with the batch: 513\n",
      "Done with the batch: 514\n",
      "Done with the batch: 515\n",
      "Done with the batch: 516\n",
      "Done with the batch: 517\n",
      "Done with the batch: 518\n",
      "Done with the batch: 519\n",
      "Done with the batch: 520\n",
      "Done with the batch: 521\n",
      "Done with the batch: 522\n",
      "Done with the batch: 523\n",
      "Done with the batch: 524\n",
      "Done with the batch: 525\n",
      "Done with the batch: 526\n",
      "Done with the batch: 527\n",
      "Done with the batch: 528\n",
      "Done with the batch: 529\n",
      "Done with the batch: 530\n",
      "Done with the batch: 531\n",
      "Done with the batch: 532\n",
      "Done with the batch: 533\n",
      "Done with the batch: 534\n",
      "Done with the batch: 535\n",
      "Done with the batch: 536\n",
      "Done with the batch: 537\n",
      "Done with the batch: 538\n",
      "Done with the batch: 539\n",
      "Done with the batch: 540\n",
      "Done with the batch: 541\n",
      "Done with the batch: 542\n",
      "Done with the batch: 543\n",
      "Done with the batch: 544\n",
      "Done with the batch: 545\n",
      "Done with the batch: 546\n",
      "Done with the batch: 547\n",
      "Done with the batch: 548\n",
      "Done with the batch: 549\n",
      "Done with the batch: 550\n",
      "Done with the batch: 551\n",
      "Done with the batch: 552\n",
      "Done with the batch: 553\n",
      "Done with the batch: 554\n",
      "Done with the batch: 555\n",
      "Done with the batch: 556\n",
      "Done with the batch: 557\n",
      "Done with the batch: 558\n",
      "Done with the batch: 559\n",
      "Done with the batch: 560\n",
      "Done with the batch: 561\n",
      "Done with the batch: 562\n",
      "Done with the batch: 563\n",
      "Done with the batch: 564\n",
      "Done with the batch: 565\n",
      "Done with the batch: 566\n",
      "Done with the batch: 567\n",
      "Done with the batch: 568\n",
      "Done with the batch: 569\n",
      "Done with the batch: 570\n",
      "Done with the batch: 571\n",
      "Done with the batch: 572\n",
      "Done with the batch: 573\n",
      "Done with the batch: 574\n",
      "Done with the batch: 575\n",
      "Done with the batch: 576\n",
      "Done with the batch: 577\n",
      "Done with the batch: 578\n",
      "Done with the batch: 579\n",
      "Done with the batch: 580\n",
      "Done with the batch: 581\n",
      "Done with the batch: 582\n",
      "Done with the batch: 583\n",
      "Done with the batch: 584\n",
      "Done with the batch: 585\n",
      "Done with the batch: 586\n",
      "Done with the batch: 587\n",
      "Done with the batch: 588\n",
      "Done with the batch: 589\n",
      "Done with the batch: 590\n",
      "Done with the batch: 591\n",
      "Done with the batch: 592\n",
      "Done with the batch: 593\n",
      "Done with the batch: 594\n",
      "Done with the batch: 595\n",
      "Done with the batch: 596\n",
      "Done with the batch: 597\n",
      "Done with the batch: 598\n",
      "Done with the batch: 599\n",
      "Done with the batch: 600\n",
      "Done with the batch: 601\n",
      "Done with the batch: 602\n",
      "Done with the batch: 603\n",
      "Done with the batch: 604\n",
      "Done with the batch: 605\n",
      "Done with the batch: 606\n",
      "Done with the batch: 607\n",
      "Done with the batch: 608\n",
      "Done with the batch: 609\n",
      "Done with the batch: 610\n",
      "Done with the batch: 611\n",
      "Done with the batch: 612\n",
      "Done with the batch: 613\n",
      "Done with the batch: 614\n",
      "Done with the batch: 615\n",
      "Done with the batch: 616\n",
      "Done with the batch: 617\n",
      "Done with the batch: 618\n",
      "Done with the batch: 619\n",
      "Done with the batch: 620\n",
      "Done with the batch: 621\n",
      "Done with the batch: 622\n",
      "Done with the batch: 623\n",
      "Done with the batch: 624\n",
      "Done with the batch: 625\n",
      "Done with the batch: 626\n",
      "Done with the batch: 627\n",
      "Done with the batch: 628\n",
      "Done with the batch: 629\n",
      "Done with the batch: 630\n",
      "Done with the batch: 631\n",
      "Done with the batch: 632\n",
      "Done with the batch: 633\n",
      "Done with the batch: 634\n",
      "Done with the batch: 635\n",
      "Done with the batch: 636\n",
      "Done with the batch: 637\n",
      "Done with the batch: 638\n",
      "Done with the batch: 639\n",
      "Done with the batch: 640\n",
      "Done with the batch: 641\n",
      "Done with the batch: 642\n",
      "Done with the batch: 643\n",
      "Done with the batch: 644\n",
      "Done with the batch: 645\n",
      "Done with the batch: 646\n",
      "Done with the batch: 647\n",
      "Done with the batch: 648\n",
      "Done with the batch: 649\n",
      "Done with the batch: 650\n",
      "Done with the batch: 651\n",
      "Done with the batch: 652\n",
      "Done with the batch: 653\n",
      "Done with the batch: 654\n",
      "Done with the batch: 655\n",
      "Done with the batch: 656\n",
      "Done with the batch: 657\n",
      "Done with the batch: 658\n",
      "Done with the batch: 659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 660\n",
      "Done with the batch: 661\n",
      "Done with the batch: 662\n",
      "Done with the batch: 663\n",
      "Done with the batch: 664\n",
      "Done with the batch: 665\n",
      "Done with the batch: 666\n",
      "Done with the batch: 667\n",
      "Done with the batch: 668\n",
      "Done with the batch: 669\n",
      "Done with the batch: 670\n",
      "Done with the batch: 671\n",
      "Done with the batch: 672\n",
      "Done with the batch: 673\n",
      "Done with the batch: 674\n",
      "Done with the batch: 675\n",
      "Done with the batch: 676\n",
      "Done with the batch: 677\n",
      "Done with the batch: 678\n",
      "Done with the batch: 679\n",
      "Done with the batch: 680\n",
      "Done with the batch: 681\n",
      "Done with the batch: 682\n",
      "Done with the batch: 683\n",
      "Done with the batch: 684\n",
      "Done with the batch: 685\n",
      "Done with the batch: 686\n",
      "Done with the batch: 687\n",
      "Done with the batch: 688\n",
      "Done with the batch: 689\n",
      "Done with the batch: 690\n",
      "Done with the batch: 691\n",
      "Done with the batch: 692\n",
      "Done with the batch: 693\n",
      "Done with the batch: 694\n",
      "Done with the batch: 695\n",
      "Done with the batch: 696\n",
      "Done with the batch: 697\n",
      "Done with the batch: 698\n",
      "Done with the batch: 699\n",
      "Done with the batch: 700\n",
      "Done with the batch: 701\n",
      "Done with the batch: 702\n",
      "Done with the batch: 703\n",
      "Done with the batch: 704\n",
      "Done with the batch: 705\n",
      "Done with the batch: 706\n",
      "Done with the batch: 707\n",
      "Done with the batch: 708\n",
      "Done with the batch: 709\n",
      "Done with the batch: 710\n",
      "Done with the batch: 711\n",
      "Done with the batch: 712\n",
      "Done with the batch: 713\n",
      "Done with the batch: 714\n",
      "Done with the batch: 715\n",
      "Done with the batch: 716\n",
      "Done with the batch: 717\n",
      "Done with the batch: 718\n",
      "Done with the batch: 719\n",
      "Done with the batch: 720\n",
      "Done with the batch: 721\n",
      "Done with the batch: 722\n",
      "Done with the batch: 723\n",
      "Done with the batch: 724\n",
      "Done with the batch: 725\n",
      "Done with the batch: 726\n",
      "Done with the batch: 727\n",
      "Done with the batch: 728\n",
      "Done with the batch: 729\n",
      "Done with the batch: 730\n",
      "Done with the batch: 731\n",
      "Done with the batch: 732\n",
      "Done with the batch: 733\n",
      "Done with the batch: 734\n",
      "Done with the batch: 735\n",
      "Done with the batch: 736\n",
      "Done with the batch: 737\n",
      "Done with the batch: 738\n",
      "Done with the batch: 739\n",
      "Done with the batch: 740\n",
      "Done with the batch: 741\n",
      "Done with the batch: 742\n",
      "Done with the batch: 743\n",
      "Done with the batch: 744\n",
      "Done with the batch: 745\n",
      "Done with the batch: 746\n",
      "Done with the batch: 747\n",
      "Done with the batch: 748\n",
      "Done with the batch: 749\n",
      "Done with the batch: 750\n",
      "Done with the batch: 751\n",
      "Done with the batch: 752\n",
      "Done with the batch: 753\n",
      "Done with the batch: 754\n",
      "Done with the batch: 755\n",
      "Done with the batch: 756\n",
      "Done with the batch: 757\n",
      "Done with the batch: 758\n",
      "Done with the batch: 759\n",
      "Done with the batch: 760\n",
      "Done with the batch: 761\n",
      "Done with the batch: 762\n",
      "Done with the batch: 763\n",
      "Done with the batch: 764\n",
      "Done with the batch: 765\n",
      "Done with the batch: 766\n",
      "Done with the batch: 767\n",
      "Done with the batch: 768\n",
      "Done with the batch: 769\n",
      "Done with the batch: 770\n",
      "Done with the batch: 771\n",
      "Done with the batch: 772\n",
      "Done with the batch: 773\n",
      "Done with the batch: 774\n",
      "Done with the batch: 775\n",
      "Done with the batch: 776\n",
      "Done with the batch: 777\n",
      "Done with the batch: 778\n",
      "Done with the batch: 779\n",
      "Done with the batch: 780\n",
      "Done with the batch: 781\n",
      "Done with the batch: 782\n",
      "Done with the batch: 783\n",
      "Done with the batch: 784\n",
      "Done with the batch: 785\n",
      "Done with the batch: 786\n",
      "Done with the batch: 787\n",
      "Done with the batch: 788\n",
      "Done with the batch: 789\n",
      "Done with the batch: 790\n",
      "Done with the batch: 791\n",
      "Done with the batch: 792\n",
      "Done with the batch: 793\n",
      "Done with the batch: 794\n",
      "Done with the batch: 795\n",
      "Done with the batch: 796\n",
      "Done with the batch: 797\n",
      "Done with the batch: 798\n",
      "Done with the batch: 799\n",
      "Done with the batch: 800\n",
      "Done with the batch: 801\n",
      "Done with the batch: 802\n",
      "Done with the batch: 803\n",
      "Done with the batch: 804\n",
      "Done with the batch: 805\n",
      "Done with the batch: 806\n",
      "Done with the batch: 807\n",
      "Done with the batch: 808\n",
      "Done with the batch: 809\n",
      "Done with the batch: 810\n",
      "Done with the batch: 811\n",
      "Done with the batch: 812\n",
      "Done with the batch: 813\n",
      "Done with the batch: 814\n",
      "Done with the batch: 815\n",
      "Done with the batch: 816\n",
      "Done with the batch: 817\n",
      "Done with the batch: 818\n",
      "Done with the batch: 819\n",
      "Done with the batch: 820\n",
      "Done with the batch: 821\n",
      "Done with the batch: 822\n",
      "Done with the batch: 823\n",
      "Done with the batch: 824\n",
      "Done with the batch: 825\n",
      "Done with the batch: 826\n",
      "Done with the batch: 827\n",
      "Done with the batch: 828\n",
      "Done with the batch: 829\n",
      "Done with the batch: 830\n",
      "Done with the batch: 831\n",
      "Done with the batch: 832\n",
      "Done with the batch: 833\n",
      "Done with the batch: 834\n",
      "Done with the batch: 835\n",
      "Done with the batch: 836\n",
      "Done with the batch: 837\n",
      "Done with the batch: 838\n",
      "Done with the batch: 839\n",
      "Done with the batch: 840\n",
      "Done with the batch: 841\n",
      "Done with the batch: 842\n",
      "Done with the batch: 843\n",
      "Done with the batch: 844\n",
      "Done with the batch: 845\n",
      "Done with the batch: 846\n",
      "Done with the batch: 847\n",
      "Done with the batch: 848\n",
      "Done with the batch: 849\n",
      "Done with the batch: 850\n",
      "Done with the batch: 851\n",
      "Done with the batch: 852\n",
      "Done with the batch: 853\n",
      "Done with the batch: 854\n",
      "Done with the batch: 855\n",
      "Done with the batch: 856\n",
      "Done with the batch: 857\n",
      "Done with the batch: 858\n",
      "Done with the batch: 859\n",
      "Done with the batch: 860\n",
      "Done with the batch: 861\n",
      "Done with the batch: 862\n",
      "Done with the batch: 863\n",
      "Done with the batch: 864\n",
      "Done with the batch: 865\n",
      "Done with the batch: 866\n",
      "Done with the batch: 867\n",
      "Done with the batch: 868\n",
      "Done with the batch: 869\n",
      "Done with the batch: 870\n",
      "Done with the batch: 871\n",
      "Done with the batch: 872\n",
      "Done with the batch: 873\n",
      "Done with the batch: 874\n",
      "Done with the batch: 875\n",
      "Done with the batch: 876\n",
      "Done with the batch: 877\n",
      "Done with the batch: 878\n",
      "Done with the batch: 879\n",
      "Done with the batch: 880\n",
      "Done with the batch: 881\n",
      "Done with the batch: 882\n",
      "Done with the batch: 883\n",
      "Done with the batch: 884\n",
      "Done with the batch: 885\n",
      "Done with the batch: 886\n",
      "Done with the batch: 887\n",
      "Done with the batch: 888\n",
      "Done with the batch: 889\n",
      "Done with the batch: 890\n",
      "Done with the batch: 891\n",
      "Done with the batch: 892\n",
      "Done with the batch: 893\n",
      "Done with the batch: 894\n",
      "Done with the batch: 895\n",
      "Done with the batch: 896\n",
      "Done with the batch: 897\n",
      "Done with the batch: 898\n",
      "Done with the batch: 899\n",
      "Done with the batch: 900\n",
      "Done with the batch: 901\n",
      "Done with the batch: 902\n",
      "Done with the batch: 903\n",
      "Done with the batch: 904\n",
      "Done with the batch: 905\n",
      "Done with the batch: 906\n",
      "Done with the batch: 907\n",
      "Done with the batch: 908\n",
      "Done with the batch: 909\n",
      "Done with the batch: 910\n",
      "Done with the batch: 911\n",
      "Done with the batch: 912\n",
      "Done with the batch: 913\n",
      "Done with the batch: 914\n",
      "Done with the batch: 915\n",
      "Done with the batch: 916\n",
      "Done with the batch: 917\n",
      "Done with the batch: 918\n",
      "Done with the batch: 919\n",
      "Done with the batch: 920\n",
      "Done with the batch: 921\n",
      "Done with the batch: 922\n",
      "Done with the batch: 923\n",
      "Done with the batch: 924\n",
      "Done with the batch: 925\n",
      "Done with the batch: 926\n",
      "Done with the batch: 927\n",
      "Done with the batch: 928\n",
      "Done with the batch: 929\n",
      "Done with the batch: 930\n",
      "Done with the batch: 931\n",
      "Done with the batch: 932\n",
      "Done with the batch: 933\n",
      "Done with the batch: 934\n",
      "Done with the batch: 935\n",
      "Done with the batch: 936\n",
      "Done with the batch: 937\n",
      "Done with the batch: 938\n",
      "Done with the batch: 939\n",
      "Done with the batch: 940\n",
      "Done with the batch: 941\n",
      "Done with the batch: 942\n",
      "Done with the batch: 943\n",
      "Done with the batch: 944\n",
      "Done with the batch: 945\n",
      "Done with the batch: 946\n",
      "Done with the batch: 947\n",
      "Done with the batch: 948\n",
      "Done with the batch: 949\n",
      "Done with the batch: 950\n",
      "Done with the batch: 951\n",
      "Done with the batch: 952\n",
      "Done with the batch: 953\n",
      "Done with the batch: 954\n",
      "Done with the batch: 955\n",
      "Done with the batch: 956\n",
      "Done with the batch: 957\n",
      "Done with the batch: 958\n",
      "Done with the batch: 959\n",
      "Done with the batch: 960\n",
      "Done with the batch: 961\n",
      "Done with the batch: 962\n",
      "Done with the batch: 963\n",
      "Done with the batch: 964\n",
      "Done with the batch: 965\n",
      "Done with the batch: 966\n",
      "Done with the batch: 967\n",
      "Done with the batch: 968\n",
      "Done with the batch: 969\n",
      "Done with the batch: 970\n",
      "Done with the batch: 971\n",
      "Done with the batch: 972\n",
      "Done with the batch: 973\n",
      "Done with the batch: 974\n",
      "Done with the batch: 975\n",
      "Done with the batch: 976\n",
      "Done with the batch: 977\n",
      "Done with the batch: 978\n",
      "Done with the batch: 979\n",
      "Done with the batch: 980\n",
      "Done with the batch: 981\n",
      "Done with the batch: 982\n",
      "Done with the batch: 983\n",
      "Done with the batch: 984\n",
      "Done with the batch: 985\n",
      "Done with the batch: 986\n",
      "Done with the batch: 987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 988\n",
      "Done with the batch: 989\n",
      "Done with the batch: 990\n",
      "Done with the batch: 991\n",
      "Done with the batch: 992\n",
      "Done with the batch: 993\n",
      "Done with the batch: 994\n",
      "Done with the batch: 995\n",
      "Done with the batch: 996\n",
      "Done with the batch: 997\n",
      "Done with the batch: 998\n",
      "Done with the batch: 999\n",
      "Done with the batch: 1000\n",
      "Done with the batch: 1001\n",
      "Done with the batch: 1002\n",
      "Done with the batch: 1003\n",
      "Done with the batch: 1004\n",
      "Done with the batch: 1005\n",
      "Done with the batch: 1006\n",
      "Done with the batch: 1007\n",
      "Done with the batch: 1008\n",
      "Done with the batch: 1009\n",
      "Done with the batch: 1010\n",
      "Done with the batch: 1011\n",
      "Done with the batch: 1012\n",
      "Done with the batch: 1013\n",
      "Done with the batch: 1014\n",
      "Done with the batch: 1015\n",
      "Done with the batch: 1016\n",
      "Done with the batch: 1017\n",
      "Done with the batch: 1018\n",
      "Done with the batch: 1019\n",
      "Done with the batch: 1020\n",
      "Done with the batch: 1021\n",
      "Done with the batch: 1022\n",
      "Done with the batch: 1023\n",
      "Done with the batch: 1024\n",
      "Done with the batch: 1025\n",
      "Done with the batch: 1026\n",
      "Done with the batch: 1027\n",
      "Done with the batch: 1028\n",
      "Done with the batch: 1029\n",
      "Done with the batch: 1030\n",
      "Done with the batch: 1031\n",
      "Done with the batch: 1032\n",
      "Done with the batch: 1033\n",
      "Done with the batch: 1034\n",
      "Done with the batch: 1035\n",
      "Done with the batch: 1036\n",
      "Done with the batch: 1037\n",
      "Done with the batch: 1038\n",
      "Done with the batch: 1039\n",
      "Done with the batch: 1040\n",
      "Done with the batch: 1041\n",
      "Done with the batch: 1042\n",
      "Done with the batch: 1043\n",
      "Done with the batch: 1044\n",
      "Done with the batch: 1045\n",
      "Done with the batch: 1046\n",
      "Done with the batch: 1047\n",
      "Done with the batch: 1048\n",
      "Done with the batch: 1049\n",
      "Done with the batch: 1050\n",
      "Done with the batch: 1051\n",
      "Done with the batch: 1052\n",
      "Done with the batch: 1053\n",
      "Done with the batch: 1054\n",
      "Done with the batch: 1055\n",
      "Done with the batch: 1056\n",
      "Done with the batch: 1057\n",
      "Done with the batch: 1058\n",
      "Done with the batch: 1059\n",
      "Done with the batch: 1060\n",
      "Done with the batch: 1061\n",
      "Done with the batch: 1062\n",
      "Done with the batch: 1063\n",
      "Done with the batch: 1064\n",
      "Done with the batch: 1065\n",
      "Done with the batch: 1066\n",
      "Done with the batch: 1067\n",
      "Done with the batch: 1068\n",
      "Done with the batch: 1069\n",
      "Done with the batch: 1070\n",
      "Done with the batch: 1071\n",
      "Done with the batch: 1072\n",
      "Done with the batch: 1073\n",
      "Done with the batch: 1074\n",
      "Done with the batch: 1075\n",
      "Done with the batch: 1076\n",
      "Done with the batch: 1077\n",
      "Done with the batch: 1078\n",
      "Done with the batch: 1079\n",
      "Done with the batch: 1080\n",
      "Done with the batch: 1081\n",
      "Done with the batch: 1082\n",
      "Done with the batch: 1083\n",
      "Done with the batch: 1084\n",
      "Done with the batch: 1085\n",
      "Done with the batch: 1086\n",
      "Done with the batch: 1087\n",
      "Done with the batch: 1088\n",
      "Done with the batch: 1089\n",
      "Done with the batch: 1090\n",
      "Done with the batch: 1091\n",
      "Done with the batch: 1092\n",
      "Done with the batch: 1093\n",
      "Done with the batch: 1094\n",
      "Done with the batch: 1095\n",
      "Done with the batch: 1096\n",
      "Done with the batch: 1097\n",
      "Done with the batch: 1098\n",
      "Done with the batch: 1099\n",
      "Done with the batch: 1100\n",
      "Done with the batch: 1101\n",
      "Done with the batch: 1102\n",
      "Done with the batch: 1103\n",
      "Done with the batch: 1104\n",
      "Done with the batch: 1105\n",
      "Done with the batch: 1106\n",
      "Done with the batch: 1107\n",
      "Done with the batch: 1108\n",
      "Done with the batch: 1109\n",
      "Done with the batch: 1110\n",
      "Done with the batch: 1111\n",
      "Done with the batch: 1112\n",
      "Done with the batch: 1113\n",
      "Done with the batch: 1114\n",
      "Done with the batch: 1115\n",
      "Done with the batch: 1116\n",
      "Done with the batch: 1117\n",
      "Done with the batch: 1118\n",
      "Done with the batch: 1119\n",
      "Done with the batch: 1120\n",
      "Done with the batch: 1121\n",
      "Done with the batch: 1122\n",
      "Done with the batch: 1123\n",
      "Done with the batch: 1124\n",
      "Done with the batch: 1125\n",
      "Done with the batch: 1126\n",
      "Done with the batch: 1127\n",
      "Done with the batch: 1128\n",
      "Done with the batch: 1129\n",
      "Done with the batch: 1130\n",
      "Done with the batch: 1131\n",
      "Done with the batch: 1132\n",
      "Done with the batch: 1133\n",
      "Done with the batch: 1134\n",
      "Done with the batch: 1135\n",
      "Done with the batch: 1136\n",
      "Done with the batch: 1137\n",
      "Done with the batch: 1138\n",
      "Done with the batch: 1139\n",
      "Done with the batch: 1140\n",
      "Done with the batch: 1141\n",
      "Done with the batch: 1142\n",
      "Done with the batch: 1143\n",
      "Done with the batch: 1144\n",
      "Done with the batch: 1145\n",
      "Done with the batch: 1146\n",
      "Done with the batch: 1147\n",
      "Done with the batch: 1148\n",
      "Done with the batch: 1149\n",
      "Done with the batch: 1150\n",
      "Done with the batch: 1151\n",
      "Done with the batch: 1152\n",
      "Done with the batch: 1153\n",
      "Done with the batch: 1154\n",
      "Done with the batch: 1155\n",
      "Done with the batch: 1156\n",
      "Done with the batch: 1157\n",
      "Done with the batch: 1158\n",
      "Done with the batch: 1159\n",
      "Done with the batch: 1160\n",
      "Done with the batch: 1161\n",
      "Done with the batch: 1162\n",
      "Done with the batch: 1163\n",
      "Done with the batch: 1164\n",
      "Done with the batch: 1165\n",
      "Done with the batch: 1166\n",
      "Done with the batch: 1167\n",
      "Done with the batch: 1168\n",
      "Done with the batch: 1169\n",
      "Done with the batch: 1170\n",
      "Done with the batch: 1171\n",
      "Done with the batch: 1172\n",
      "Done with the batch: 1173\n",
      "Done with the batch: 1174\n",
      "Done with the batch: 1175\n",
      "Done with the batch: 1176\n",
      "Done with the batch: 1177\n",
      "Done with the batch: 1178\n",
      "Done with the batch: 1179\n",
      "Done with the batch: 1180\n",
      "Done with the batch: 1181\n",
      "Done with the batch: 1182\n",
      "Done with the batch: 1183\n",
      "Done with the batch: 1184\n",
      "Done with the batch: 1185\n",
      "Done with the batch: 1186\n",
      "Done with the batch: 1187\n",
      "Done with the batch: 1188\n",
      "Done with the batch: 1189\n",
      "Done with the batch: 1190\n",
      "Done with the batch: 1191\n",
      "Done with the batch: 1192\n",
      "Done with the batch: 1193\n",
      "Done with the batch: 1194\n",
      "Done with the batch: 1195\n",
      "Done with the batch: 1196\n",
      "Done with the batch: 1197\n",
      "Done with the batch: 1198\n",
      "Done with the batch: 1199\n",
      "Done with the batch: 1200\n",
      "Done with the batch: 1201\n",
      "Done with the batch: 1202\n",
      "Done with the batch: 1203\n",
      "Done with the batch: 1204\n",
      "Done with the batch: 1205\n",
      "Done with the batch: 1206\n",
      "Done with the batch: 1207\n",
      "Done with the batch: 1208\n",
      "Done with the batch: 1209\n",
      "Done with the batch: 1210\n",
      "Done with the batch: 1211\n",
      "Done with the batch: 1212\n",
      "Done with the batch: 1213\n",
      "Done with the batch: 1214\n",
      "Done with the batch: 1215\n",
      "Done with the batch: 1216\n",
      "Done with the batch: 1217\n",
      "Done with the batch: 1218\n",
      "Done with the batch: 1219\n",
      "Done with the batch: 1220\n",
      "Done with the batch: 1221\n",
      "Done with the batch: 1222\n",
      "Done with the batch: 1223\n",
      "Done with the batch: 1224\n",
      "Done with the batch: 1225\n",
      "Done with the batch: 1226\n",
      "Done with the batch: 1227\n",
      "Done with the batch: 1228\n",
      "Done with the batch: 1229\n",
      "Done with the batch: 1230\n",
      "Done with the batch: 1231\n",
      "Done with the batch: 1232\n",
      "Done with the batch: 1233\n",
      "Done with the batch: 1234\n",
      "Done with the batch: 1235\n",
      "Done with the batch: 1236\n",
      "Done with the batch: 1237\n",
      "Done with the batch: 1238\n",
      "Done with the batch: 1239\n",
      "Done with the batch: 1240\n",
      "Done with the batch: 1241\n",
      "Done with the batch: 1242\n",
      "Done with the batch: 1243\n",
      "Done with the batch: 1244\n",
      "Done with the batch: 1245\n",
      "Done with the batch: 1246\n",
      "Done with the batch: 1247\n",
      "Done with the batch: 1248\n",
      "Done with the batch: 1249\n",
      "Done with the batch: 1250\n",
      "Done with the batch: 1251\n",
      "Done with the batch: 1252\n",
      "Done with the batch: 1253\n",
      "Done with the batch: 1254\n",
      "Done with the batch: 1255\n",
      "Done with the batch: 1256\n",
      "Done with the batch: 1257\n",
      "Done with the batch: 1258\n",
      "Done with the batch: 1259\n",
      "Done with the batch: 1260\n",
      "Done with the batch: 1261\n",
      "Done with the batch: 1262\n",
      "Done with the batch: 1263\n",
      "Done with the batch: 1264\n",
      "Done with the batch: 1265\n",
      "Done with the batch: 1266\n",
      "Done with the batch: 1267\n",
      "Done with the batch: 1268\n",
      "Done with the batch: 1269\n",
      "Done with the batch: 1270\n",
      "Done with the batch: 1271\n",
      "Done with the batch: 1272\n",
      "Done with the batch: 1273\n",
      "Done with the batch: 1274\n",
      "Done with the batch: 1275\n",
      "Done with the batch: 1276\n",
      "Done with the batch: 1277\n",
      "Done with the batch: 1278\n",
      "Done with the batch: 1279\n",
      "Done with the batch: 1280\n",
      "Done with the batch: 1281\n",
      "Done with the batch: 1282\n",
      "Done with the batch: 1283\n",
      "Done with the batch: 1284\n",
      "Done with the batch: 1285\n",
      "Done with the batch: 1286\n",
      "Done with the batch: 1287\n",
      "Done with the batch: 1288\n",
      "Done with the batch: 1289\n",
      "Done with the batch: 1290\n",
      "Done with the batch: 1291\n",
      "Done with the batch: 1292\n",
      "Done with the batch: 1293\n",
      "Done with the batch: 1294\n",
      "Done with the batch: 1295\n",
      "Done with the batch: 1296\n",
      "Done with the batch: 1297\n",
      "Done with the batch: 1298\n",
      "Done with the batch: 1299\n",
      "Done with the batch: 1300\n",
      "Done with the batch: 1301\n",
      "Done with the batch: 1302\n",
      "Done with the batch: 1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 1304\n",
      "Done with the batch: 1305\n",
      "Done with the batch: 1306\n",
      "Done with the batch: 1307\n",
      "Done with the batch: 1308\n",
      "Done with the batch: 1309\n",
      "Done with the batch: 1310\n",
      "Done with the batch: 1311\n",
      "Done with the batch: 1312\n",
      "Done with the batch: 1313\n",
      "Done with the batch: 1314\n",
      "Done with the batch: 1315\n",
      "Done with the batch: 1316\n",
      "Done with the batch: 1317\n",
      "Done with the batch: 1318\n",
      "Done with the batch: 1319\n",
      "Done with the batch: 1320\n",
      "Done with the batch: 1321\n",
      "Done with the batch: 1322\n",
      "Done with the batch: 1323\n",
      "Done with the batch: 1324\n",
      "Done with the batch: 1325\n",
      "Done with the batch: 1326\n",
      "Done with the batch: 1327\n",
      "Done with the batch: 1328\n",
      "Done with the batch: 1329\n",
      "Done with the batch: 1330\n",
      "Done with the batch: 1331\n",
      "Done with the batch: 1332\n",
      "Done with the batch: 1333\n",
      "Done with the batch: 1334\n",
      "Done with the batch: 1335\n",
      "Done with the batch: 1336\n",
      "Done with the batch: 1337\n",
      "Done with the batch: 1338\n",
      "Done with the batch: 1339\n",
      "Done with the batch: 1340\n",
      "Done with the batch: 1341\n",
      "Done with the batch: 1342\n",
      "Done with the batch: 1343\n",
      "Done with the batch: 1344\n",
      "Done with the batch: 1345\n",
      "Done with the batch: 1346\n",
      "Done with the batch: 1347\n",
      "Done with the batch: 1348\n",
      "Done with the batch: 1349\n",
      "Done with the batch: 1350\n",
      "Done with the batch: 1351\n",
      "Done with the batch: 1352\n",
      "Done with the batch: 1353\n",
      "Done with the batch: 1354\n",
      "Done with the batch: 1355\n",
      "Done with the batch: 1356\n",
      "Done with the batch: 1357\n",
      "Done with the batch: 1358\n",
      "Done with the batch: 1359\n",
      "Done with the batch: 1360\n",
      "Done with the batch: 1361\n",
      "Done with the batch: 1362\n",
      "Done with the batch: 1363\n",
      "Done with the batch: 1364\n",
      "Done with the batch: 1365\n",
      "Done with the batch: 1366\n",
      "Done with the batch: 1367\n",
      "Done with the batch: 1368\n",
      "Done with the batch: 1369\n",
      "Done with the batch: 1370\n",
      "Done with the batch: 1371\n",
      "Done with the batch: 1372\n",
      "Done with the batch: 1373\n",
      "Done with the batch: 1374\n",
      "Done with the batch: 1375\n",
      "Done with the batch: 1376\n",
      "Done with the batch: 1377\n",
      "Done with the batch: 1378\n",
      "Done with the batch: 1379\n",
      "Done with the batch: 1380\n",
      "Done with the batch: 1381\n",
      "Done with the batch: 1382\n",
      "Done with the batch: 1383\n",
      "Done with the batch: 1384\n",
      "Done with the batch: 1385\n",
      "Done with the batch: 1386\n",
      "Done with the batch: 1387\n",
      "Done with the batch: 1388\n",
      "Done with the batch: 1389\n",
      "Done with the batch: 1390\n",
      "Done with the batch: 1391\n",
      "Done with the batch: 1392\n",
      "Done with the batch: 1393\n",
      "Done with the batch: 1394\n",
      "Done with the batch: 1395\n",
      "Done with the batch: 1396\n",
      "Done with the batch: 1397\n",
      "Done with the batch: 1398\n",
      "Done with the batch: 1399\n",
      "Done with the batch: 1400\n",
      "Done with the batch: 1401\n",
      "Done with the batch: 1402\n",
      "Done with the batch: 1403\n",
      "Done with the batch: 1404\n",
      "Done with the batch: 1405\n",
      "Done with the batch: 1406\n",
      "Done with the batch: 1407\n",
      "Done with the batch: 1408\n",
      "Done with the batch: 1409\n",
      "Done with the batch: 1410\n",
      "Done with the batch: 1411\n",
      "Done with the batch: 1412\n",
      "Done with the batch: 1413\n",
      "Done with the batch: 1414\n",
      "Done with the batch: 1415\n",
      "Done with the batch: 1416\n",
      "Done with the batch: 1417\n",
      "Done with the batch: 1418\n",
      "Done with the batch: 1419\n",
      "Done with the batch: 1420\n",
      "Done with the batch: 1421\n",
      "Done with the batch: 1422\n",
      "Done with the batch: 1423\n",
      "Done with the batch: 1424\n",
      "Done with the batch: 1425\n",
      "Done with the batch: 1426\n",
      "Done with the batch: 1427\n",
      "Done with the batch: 1428\n",
      "Done with the batch: 1429\n",
      "Done with the batch: 1430\n",
      "Done with the batch: 1431\n",
      "Done with the batch: 1432\n",
      "Done with the batch: 1433\n",
      "Done with the batch: 1434\n",
      "Done with the batch: 1435\n",
      "Done with the batch: 1436\n",
      "Done with the batch: 1437\n",
      "Done with the batch: 1438\n",
      "Done with the batch: 1439\n",
      "Done with the batch: 1440\n",
      "Done with the batch: 1441\n",
      "Done with the batch: 1442\n",
      "Done with the batch: 1443\n",
      "Done with the batch: 1444\n",
      "Done with the batch: 1445\n",
      "Done with the batch: 1446\n",
      "Done with the batch: 1447\n",
      "Done with the batch: 1448\n",
      "Done with the batch: 1449\n",
      "Done with the batch: 1450\n",
      "Done with the batch: 1451\n",
      "Done with the batch: 1452\n",
      "Done with the batch: 1453\n",
      "Done with the batch: 1454\n",
      "Done with the batch: 1455\n",
      "Done with the batch: 1456\n",
      "Done with the batch: 1457\n",
      "Done with the batch: 1458\n",
      "Done with the batch: 1459\n",
      "Done with the batch: 1460\n",
      "Done with the batch: 1461\n",
      "Done with the batch: 1462\n",
      "Done with the batch: 1463\n",
      "Done with the batch: 1464\n",
      "Done with the batch: 1465\n",
      "Done with the batch: 1466\n",
      "Done with the batch: 1467\n",
      "Done with the batch: 1468\n",
      "Done with the batch: 1469\n",
      "Done with the batch: 1470\n",
      "Done with the batch: 1471\n",
      "Done with the batch: 1472\n",
      "Done with the batch: 1473\n",
      "Done with the batch: 1474\n",
      "Done with the batch: 1475\n",
      "Done with the batch: 1476\n",
      "Done with the batch: 1477\n",
      "Done with the batch: 1478\n",
      "Done with the batch: 1479\n",
      "Done with the batch: 1480\n",
      "Done with the batch: 1481\n",
      "Done with the batch: 1482\n",
      "Done with the batch: 1483\n",
      "Done with the batch: 1484\n",
      "Done with the batch: 1485\n",
      "Done with the batch: 1486\n",
      "Done with the batch: 1487\n",
      "Done with the batch: 1488\n",
      "Done with the batch: 1489\n",
      "Done with the batch: 1490\n",
      "Done with the batch: 1491\n",
      "Done with the batch: 1492\n",
      "Done with the batch: 1493\n",
      "Done with the batch: 1494\n",
      "Done with the batch: 1495\n",
      "Done with the batch: 1496\n",
      "Done with the batch: 1497\n",
      "Done with the batch: 1498\n",
      "Done with the batch: 1499\n",
      "Done with the batch: 1500\n",
      "Done with the batch: 1501\n",
      "Done with the batch: 1502\n",
      "Done with the batch: 1503\n",
      "Done with the batch: 1504\n",
      "Done with the batch: 1505\n",
      "Done with the batch: 1506\n",
      "Done with the batch: 1507\n",
      "Done with the batch: 1508\n",
      "Done with the batch: 1509\n",
      "Done with the batch: 1510\n",
      "Done with the batch: 1511\n",
      "Done with the batch: 1512\n",
      "Done with the batch: 1513\n",
      "Done with the batch: 1514\n",
      "Done with the batch: 1515\n",
      "Done with the batch: 1516\n",
      "Done with the batch: 1517\n",
      "Done with the batch: 1518\n",
      "Done with the batch: 1519\n",
      "Done with the batch: 1520\n",
      "Done with the batch: 1521\n",
      "Done with the batch: 1522\n",
      "Done with the batch: 1523\n",
      "Done with the batch: 1524\n",
      "Done with the batch: 1525\n",
      "Done with the batch: 1526\n",
      "Done with the batch: 1527\n",
      "Done with the batch: 1528\n",
      "Done with the batch: 1529\n",
      "Done with the batch: 1530\n",
      "Done with the batch: 1531\n",
      "Done with the batch: 1532\n",
      "Done with the batch: 1533\n",
      "Done with the batch: 1534\n",
      "Done with the batch: 1535\n",
      "Done with the batch: 1536\n",
      "Done with the batch: 1537\n",
      "Done with the batch: 1538\n",
      "Done with the batch: 1539\n",
      "Done with the batch: 1540\n",
      "Done with the batch: 1541\n",
      "Done with the batch: 1542\n",
      "Done with the batch: 1543\n",
      "Done with the batch: 1544\n",
      "Done with the batch: 1545\n",
      "Done with the batch: 1546\n",
      "Done with the batch: 1547\n",
      "Done with the batch: 1548\n",
      "Done with the batch: 1549\n",
      "Done with the batch: 1550\n",
      "Done with the batch: 1551\n",
      "Done with the batch: 1552\n",
      "Done with the batch: 1553\n",
      "Done with the batch: 1554\n",
      "Done with the batch: 1555\n",
      "Done with the batch: 1556\n",
      "Done with the batch: 1557\n",
      "Done with the batch: 1558\n",
      "Done with the batch: 1559\n",
      "Done with the batch: 1560\n",
      "Done with the batch: 1561\n",
      "Done with the batch: 1562\n",
      "Done with the batch: 1563\n",
      "Done with the batch: 1564\n",
      "Done with the batch: 1565\n",
      "Done with the batch: 1566\n",
      "Done with the batch: 1567\n",
      "Done with the batch: 1568\n",
      "Done with the batch: 1569\n",
      "Done with the batch: 1570\n",
      "Done with the batch: 1571\n",
      "Done with the batch: 1572\n",
      "Done with the batch: 1573\n",
      "Done with the batch: 1574\n",
      "Done with the batch: 1575\n",
      "Done with the batch: 1576\n",
      "Done with the batch: 1577\n",
      "Done with the batch: 1578\n",
      "Done with the batch: 1579\n",
      "Done with the batch: 1580\n",
      "Done with the batch: 1581\n",
      "Done with the batch: 1582\n",
      "Done with the batch: 1583\n",
      "Done with the batch: 1584\n",
      "Done with the batch: 1585\n",
      "Done with the batch: 1586\n",
      "Done with the batch: 1587\n",
      "Done with the batch: 1588\n",
      "Done with the batch: 1589\n",
      "Done with the batch: 1590\n",
      "Done with the batch: 1591\n",
      "Done with the batch: 1592\n",
      "Done with the batch: 1593\n",
      "Done with the batch: 1594\n",
      "Done with the batch: 1595\n",
      "Done with the batch: 1596\n",
      "Done with the batch: 1597\n",
      "Done with the batch: 1598\n",
      "Done with the batch: 1599\n",
      "Done with the batch: 1600\n",
      "Done with the batch: 1601\n",
      "Done with the batch: 1602\n",
      "Done with the batch: 1603\n",
      "Done with the batch: 1604\n",
      "Done with the batch: 1605\n",
      "Done with the batch: 1606\n",
      "Done with the batch: 1607\n",
      "Done with the batch: 1608\n",
      "Done with the batch: 1609\n",
      "Done with the batch: 1610\n",
      "Done with the batch: 1611\n",
      "Done with the batch: 1612\n",
      "Done with the batch: 1613\n",
      "Done with the batch: 1614\n",
      "Done with the batch: 1615\n",
      "Done with the batch: 1616\n",
      "Done with the batch: 1617\n",
      "(6470, 512) (6470,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"46bba85c-93b7-4e11-a31d-a070b27ca016\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"46bba85c-93b7-4e11-a31d-a070b27ca016\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "\n",
    "X_Train=np.empty((0,512))\n",
    "Y_Train=np.empty((0,batch_size))\n",
    "print(X_Train.shape)\n",
    "for i,data in enumerate(trainloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    FCLayer=vgg.get_first_FC_Layer(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Train=np.append(X_Train,FCLayer,axis=0)\n",
    "    Y_Train=np.append(Y_Train,labels.numpy())\n",
    "print(X_Train.shape,Y_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84302e50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 512)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "(1618, 512) (1618,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"18af516b-2d8f-4745-95b7-9afe5c9a88eb\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"18af516b-2d8f-4745-95b7-9afe5c9a88eb\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "X_Test=np.empty((0,512))\n",
    "Y_Test=np.empty((0,batch_size))\n",
    "print(X_Test.shape)\n",
    "for i,data in enumerate(testloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    FCLayer=vgg.get_first_FC_Layer(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Test=np.append(X_Test,FCLayer,axis=0)\n",
    "    Y_Test=np.append(Y_Test,labels.numpy())\n",
    "print(X_Test.shape,Y_Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15afe902",
   "metadata": {},
   "source": [
    "### Getting the feature extraction layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda4793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 25088)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "Done with the batch: 405\n",
      "Done with the batch: 406\n",
      "Done with the batch: 407\n",
      "Done with the batch: 408\n",
      "Done with the batch: 409\n",
      "Done with the batch: 410\n",
      "Done with the batch: 411\n",
      "Done with the batch: 412\n",
      "Done with the batch: 413\n",
      "Done with the batch: 414\n",
      "Done with the batch: 415\n",
      "Done with the batch: 416\n",
      "Done with the batch: 417\n",
      "Done with the batch: 418\n",
      "Done with the batch: 419\n",
      "Done with the batch: 420\n",
      "Done with the batch: 421\n",
      "Done with the batch: 422\n",
      "Done with the batch: 423\n",
      "Done with the batch: 424\n",
      "Done with the batch: 425\n",
      "Done with the batch: 426\n",
      "Done with the batch: 427\n",
      "Done with the batch: 428\n",
      "Done with the batch: 429\n",
      "Done with the batch: 430\n",
      "Done with the batch: 431\n",
      "Done with the batch: 432\n",
      "Done with the batch: 433\n",
      "Done with the batch: 434\n",
      "Done with the batch: 435\n",
      "Done with the batch: 436\n",
      "Done with the batch: 437\n",
      "Done with the batch: 438\n",
      "Done with the batch: 439\n",
      "Done with the batch: 440\n",
      "Done with the batch: 441\n",
      "Done with the batch: 442\n",
      "Done with the batch: 443\n",
      "Done with the batch: 444\n",
      "Done with the batch: 445\n",
      "Done with the batch: 446\n",
      "Done with the batch: 447\n",
      "Done with the batch: 448\n",
      "Done with the batch: 449\n",
      "Done with the batch: 450\n",
      "Done with the batch: 451\n",
      "Done with the batch: 452\n",
      "Done with the batch: 453\n",
      "Done with the batch: 454\n",
      "Done with the batch: 455\n",
      "Done with the batch: 456\n",
      "Done with the batch: 457\n",
      "Done with the batch: 458\n",
      "Done with the batch: 459\n",
      "Done with the batch: 460\n",
      "Done with the batch: 461\n",
      "Done with the batch: 462\n",
      "Done with the batch: 463\n",
      "Done with the batch: 464\n",
      "Done with the batch: 465\n",
      "Done with the batch: 466\n",
      "Done with the batch: 467\n",
      "Done with the batch: 468\n",
      "Done with the batch: 469\n",
      "Done with the batch: 470\n",
      "Done with the batch: 471\n",
      "Done with the batch: 472\n",
      "Done with the batch: 473\n",
      "Done with the batch: 474\n",
      "Done with the batch: 475\n",
      "Done with the batch: 476\n",
      "Done with the batch: 477\n",
      "Done with the batch: 478\n",
      "Done with the batch: 479\n",
      "Done with the batch: 480\n",
      "Done with the batch: 481\n",
      "Done with the batch: 482\n",
      "Done with the batch: 483\n",
      "Done with the batch: 484\n",
      "Done with the batch: 485\n",
      "Done with the batch: 486\n",
      "Done with the batch: 487\n",
      "Done with the batch: 488\n",
      "Done with the batch: 489\n",
      "Done with the batch: 490\n",
      "Done with the batch: 491\n",
      "Done with the batch: 492\n",
      "Done with the batch: 493\n",
      "Done with the batch: 494\n",
      "Done with the batch: 495\n",
      "Done with the batch: 496\n",
      "Done with the batch: 497\n",
      "Done with the batch: 498\n",
      "Done with the batch: 499\n",
      "Done with the batch: 500\n",
      "Done with the batch: 501\n",
      "Done with the batch: 502\n",
      "Done with the batch: 503\n",
      "Done with the batch: 504\n",
      "Done with the batch: 505\n",
      "Done with the batch: 506\n",
      "Done with the batch: 507\n",
      "Done with the batch: 508\n",
      "Done with the batch: 509\n",
      "Done with the batch: 510\n",
      "Done with the batch: 511\n",
      "Done with the batch: 512\n",
      "Done with the batch: 513\n",
      "Done with the batch: 514\n",
      "Done with the batch: 515\n",
      "Done with the batch: 516\n",
      "Done with the batch: 517\n",
      "Done with the batch: 518\n",
      "Done with the batch: 519\n",
      "Done with the batch: 520\n",
      "Done with the batch: 521\n",
      "Done with the batch: 522\n",
      "Done with the batch: 523\n",
      "Done with the batch: 524\n",
      "Done with the batch: 525\n",
      "Done with the batch: 526\n",
      "Done with the batch: 527\n",
      "Done with the batch: 528\n",
      "Done with the batch: 529\n",
      "Done with the batch: 530\n",
      "Done with the batch: 531\n",
      "Done with the batch: 532\n",
      "Done with the batch: 533\n",
      "Done with the batch: 534\n",
      "Done with the batch: 535\n",
      "Done with the batch: 536\n",
      "Done with the batch: 537\n",
      "Done with the batch: 538\n",
      "Done with the batch: 539\n",
      "Done with the batch: 540\n",
      "Done with the batch: 541\n",
      "Done with the batch: 542\n",
      "Done with the batch: 543\n",
      "Done with the batch: 544\n",
      "Done with the batch: 545\n",
      "Done with the batch: 546\n",
      "Done with the batch: 547\n",
      "Done with the batch: 548\n",
      "Done with the batch: 549\n",
      "Done with the batch: 550\n",
      "Done with the batch: 551\n",
      "Done with the batch: 552\n",
      "Done with the batch: 553\n",
      "Done with the batch: 554\n",
      "Done with the batch: 555\n",
      "Done with the batch: 556\n",
      "Done with the batch: 557\n",
      "Done with the batch: 558\n",
      "Done with the batch: 559\n",
      "Done with the batch: 560\n",
      "Done with the batch: 561\n",
      "Done with the batch: 562\n",
      "Done with the batch: 563\n",
      "Done with the batch: 564\n",
      "Done with the batch: 565\n",
      "Done with the batch: 566\n",
      "Done with the batch: 567\n",
      "Done with the batch: 568\n",
      "Done with the batch: 569\n",
      "Done with the batch: 570\n",
      "Done with the batch: 571\n",
      "Done with the batch: 572\n",
      "Done with the batch: 573\n",
      "Done with the batch: 574\n",
      "Done with the batch: 575\n",
      "Done with the batch: 576\n",
      "Done with the batch: 577\n",
      "Done with the batch: 578\n",
      "Done with the batch: 579\n",
      "Done with the batch: 580\n",
      "Done with the batch: 581\n",
      "Done with the batch: 582\n",
      "Done with the batch: 583\n",
      "Done with the batch: 584\n",
      "Done with the batch: 585\n",
      "Done with the batch: 586\n",
      "Done with the batch: 587\n",
      "Done with the batch: 588\n",
      "Done with the batch: 589\n",
      "Done with the batch: 590\n",
      "Done with the batch: 591\n",
      "Done with the batch: 592\n",
      "Done with the batch: 593\n",
      "Done with the batch: 594\n",
      "Done with the batch: 595\n",
      "Done with the batch: 596\n",
      "Done with the batch: 597\n",
      "Done with the batch: 598\n",
      "Done with the batch: 599\n",
      "Done with the batch: 600\n",
      "Done with the batch: 601\n",
      "Done with the batch: 602\n",
      "Done with the batch: 603\n",
      "Done with the batch: 604\n",
      "Done with the batch: 605\n",
      "Done with the batch: 606\n",
      "Done with the batch: 607\n",
      "Done with the batch: 608\n",
      "Done with the batch: 609\n",
      "Done with the batch: 610\n",
      "Done with the batch: 611\n",
      "Done with the batch: 612\n",
      "Done with the batch: 613\n",
      "Done with the batch: 614\n",
      "Done with the batch: 615\n",
      "Done with the batch: 616\n",
      "Done with the batch: 617\n",
      "Done with the batch: 618\n",
      "Done with the batch: 619\n",
      "Done with the batch: 620\n",
      "Done with the batch: 621\n",
      "Done with the batch: 622\n",
      "Done with the batch: 623\n",
      "Done with the batch: 624\n",
      "Done with the batch: 625\n",
      "Done with the batch: 626\n",
      "Done with the batch: 627\n",
      "Done with the batch: 628\n",
      "Done with the batch: 629\n",
      "Done with the batch: 630\n",
      "Done with the batch: 631\n",
      "Done with the batch: 632\n",
      "Done with the batch: 633\n",
      "Done with the batch: 634\n",
      "Done with the batch: 635\n",
      "Done with the batch: 636\n",
      "Done with the batch: 637\n",
      "Done with the batch: 638\n",
      "Done with the batch: 639\n",
      "Done with the batch: 640\n",
      "Done with the batch: 641\n",
      "Done with the batch: 642\n",
      "Done with the batch: 643\n",
      "Done with the batch: 644\n",
      "Done with the batch: 645\n",
      "Done with the batch: 646\n",
      "Done with the batch: 647\n",
      "Done with the batch: 648\n",
      "Done with the batch: 649\n",
      "Done with the batch: 650\n",
      "Done with the batch: 651\n",
      "Done with the batch: 652\n",
      "Done with the batch: 653\n",
      "Done with the batch: 654\n",
      "Done with the batch: 655\n",
      "Done with the batch: 656\n",
      "Done with the batch: 657\n",
      "Done with the batch: 658\n",
      "Done with the batch: 659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 660\n",
      "Done with the batch: 661\n",
      "Done with the batch: 662\n",
      "Done with the batch: 663\n",
      "Done with the batch: 664\n",
      "Done with the batch: 665\n",
      "Done with the batch: 666\n",
      "Done with the batch: 667\n",
      "Done with the batch: 668\n",
      "Done with the batch: 669\n",
      "Done with the batch: 670\n",
      "Done with the batch: 671\n",
      "Done with the batch: 672\n",
      "Done with the batch: 673\n",
      "Done with the batch: 674\n",
      "Done with the batch: 675\n",
      "Done with the batch: 676\n",
      "Done with the batch: 677\n",
      "Done with the batch: 678\n",
      "Done with the batch: 679\n",
      "Done with the batch: 680\n",
      "Done with the batch: 681\n",
      "Done with the batch: 682\n",
      "Done with the batch: 683\n",
      "Done with the batch: 684\n",
      "Done with the batch: 685\n",
      "Done with the batch: 686\n",
      "Done with the batch: 687\n",
      "Done with the batch: 688\n",
      "Done with the batch: 689\n",
      "Done with the batch: 690\n",
      "Done with the batch: 691\n",
      "Done with the batch: 692\n",
      "Done with the batch: 693\n",
      "Done with the batch: 694\n",
      "Done with the batch: 695\n",
      "Done with the batch: 696\n",
      "Done with the batch: 697\n",
      "Done with the batch: 698\n",
      "Done with the batch: 699\n",
      "Done with the batch: 700\n",
      "Done with the batch: 701\n",
      "Done with the batch: 702\n",
      "Done with the batch: 703\n",
      "Done with the batch: 704\n",
      "Done with the batch: 705\n",
      "Done with the batch: 706\n",
      "Done with the batch: 707\n",
      "Done with the batch: 708\n",
      "Done with the batch: 709\n",
      "Done with the batch: 710\n",
      "Done with the batch: 711\n",
      "Done with the batch: 712\n",
      "Done with the batch: 713\n",
      "Done with the batch: 714\n",
      "Done with the batch: 715\n",
      "Done with the batch: 716\n",
      "Done with the batch: 717\n",
      "Done with the batch: 718\n",
      "Done with the batch: 719\n",
      "Done with the batch: 720\n",
      "Done with the batch: 721\n",
      "Done with the batch: 722\n",
      "Done with the batch: 723\n",
      "Done with the batch: 724\n",
      "Done with the batch: 725\n",
      "Done with the batch: 726\n",
      "Done with the batch: 727\n",
      "Done with the batch: 728\n",
      "Done with the batch: 729\n",
      "Done with the batch: 730\n",
      "Done with the batch: 731\n",
      "Done with the batch: 732\n",
      "Done with the batch: 733\n",
      "Done with the batch: 734\n",
      "Done with the batch: 735\n",
      "Done with the batch: 736\n",
      "Done with the batch: 737\n",
      "Done with the batch: 738\n",
      "Done with the batch: 739\n",
      "Done with the batch: 740\n",
      "Done with the batch: 741\n",
      "Done with the batch: 742\n",
      "Done with the batch: 743\n",
      "Done with the batch: 744\n",
      "Done with the batch: 745\n",
      "Done with the batch: 746\n",
      "Done with the batch: 747\n",
      "Done with the batch: 748\n",
      "Done with the batch: 749\n",
      "Done with the batch: 750\n",
      "Done with the batch: 751\n",
      "Done with the batch: 752\n",
      "Done with the batch: 753\n",
      "Done with the batch: 754\n",
      "Done with the batch: 755\n",
      "Done with the batch: 756\n",
      "Done with the batch: 757\n",
      "Done with the batch: 758\n",
      "Done with the batch: 759\n",
      "Done with the batch: 760\n",
      "Done with the batch: 761\n",
      "Done with the batch: 762\n",
      "Done with the batch: 763\n",
      "Done with the batch: 764\n",
      "Done with the batch: 765\n",
      "Done with the batch: 766\n",
      "Done with the batch: 767\n",
      "Done with the batch: 768\n",
      "Done with the batch: 769\n",
      "Done with the batch: 770\n",
      "Done with the batch: 771\n",
      "Done with the batch: 772\n",
      "Done with the batch: 773\n",
      "Done with the batch: 774\n",
      "Done with the batch: 775\n",
      "Done with the batch: 776\n",
      "Done with the batch: 777\n",
      "Done with the batch: 778\n",
      "Done with the batch: 779\n",
      "Done with the batch: 780\n",
      "Done with the batch: 781\n",
      "Done with the batch: 782\n",
      "Done with the batch: 783\n",
      "Done with the batch: 784\n",
      "Done with the batch: 785\n",
      "Done with the batch: 786\n",
      "Done with the batch: 787\n",
      "Done with the batch: 788\n",
      "Done with the batch: 789\n",
      "Done with the batch: 790\n",
      "Done with the batch: 791\n",
      "Done with the batch: 792\n",
      "Done with the batch: 793\n",
      "Done with the batch: 794\n",
      "Done with the batch: 795\n",
      "Done with the batch: 796\n",
      "Done with the batch: 797\n",
      "Done with the batch: 798\n",
      "Done with the batch: 799\n",
      "Done with the batch: 800\n",
      "Done with the batch: 801\n",
      "Done with the batch: 802\n",
      "Done with the batch: 803\n",
      "Done with the batch: 804\n",
      "Done with the batch: 805\n",
      "Done with the batch: 806\n",
      "Done with the batch: 807\n",
      "Done with the batch: 808\n",
      "Done with the batch: 809\n",
      "Done with the batch: 810\n",
      "Done with the batch: 811\n",
      "Done with the batch: 812\n",
      "Done with the batch: 813\n",
      "Done with the batch: 814\n",
      "Done with the batch: 815\n",
      "Done with the batch: 816\n",
      "Done with the batch: 817\n",
      "Done with the batch: 818\n",
      "Done with the batch: 819\n",
      "Done with the batch: 820\n",
      "Done with the batch: 821\n",
      "Done with the batch: 822\n",
      "Done with the batch: 823\n",
      "Done with the batch: 824\n",
      "Done with the batch: 825\n",
      "Done with the batch: 826\n",
      "Done with the batch: 827\n",
      "Done with the batch: 828\n",
      "Done with the batch: 829\n",
      "Done with the batch: 830\n",
      "Done with the batch: 831\n",
      "Done with the batch: 832\n",
      "Done with the batch: 833\n",
      "Done with the batch: 834\n",
      "Done with the batch: 835\n",
      "Done with the batch: 836\n",
      "Done with the batch: 837\n",
      "Done with the batch: 838\n",
      "Done with the batch: 839\n",
      "Done with the batch: 840\n",
      "Done with the batch: 841\n",
      "Done with the batch: 842\n",
      "Done with the batch: 843\n",
      "Done with the batch: 844\n",
      "Done with the batch: 845\n",
      "Done with the batch: 846\n",
      "Done with the batch: 847\n",
      "Done with the batch: 848\n",
      "Done with the batch: 849\n",
      "Done with the batch: 850\n",
      "Done with the batch: 851\n",
      "Done with the batch: 852\n",
      "Done with the batch: 853\n",
      "Done with the batch: 854\n",
      "Done with the batch: 855\n",
      "Done with the batch: 856\n",
      "Done with the batch: 857\n",
      "Done with the batch: 858\n",
      "Done with the batch: 859\n",
      "Done with the batch: 860\n",
      "Done with the batch: 861\n",
      "Done with the batch: 862\n",
      "Done with the batch: 863\n",
      "Done with the batch: 864\n",
      "Done with the batch: 865\n",
      "Done with the batch: 866\n",
      "Done with the batch: 867\n",
      "Done with the batch: 868\n",
      "Done with the batch: 869\n",
      "Done with the batch: 870\n",
      "Done with the batch: 871\n",
      "Done with the batch: 872\n",
      "Done with the batch: 873\n",
      "Done with the batch: 874\n",
      "Done with the batch: 875\n",
      "Done with the batch: 876\n",
      "Done with the batch: 877\n",
      "Done with the batch: 878\n",
      "Done with the batch: 879\n",
      "Done with the batch: 880\n",
      "Done with the batch: 881\n",
      "Done with the batch: 882\n",
      "Done with the batch: 883\n",
      "Done with the batch: 884\n",
      "Done with the batch: 885\n",
      "Done with the batch: 886\n",
      "Done with the batch: 887\n",
      "Done with the batch: 888\n",
      "Done with the batch: 889\n",
      "Done with the batch: 890\n",
      "Done with the batch: 891\n",
      "Done with the batch: 892\n",
      "Done with the batch: 893\n",
      "Done with the batch: 894\n",
      "Done with the batch: 895\n",
      "Done with the batch: 896\n",
      "Done with the batch: 897\n",
      "Done with the batch: 898\n",
      "Done with the batch: 899\n",
      "Done with the batch: 900\n",
      "Done with the batch: 901\n",
      "Done with the batch: 902\n",
      "Done with the batch: 903\n",
      "Done with the batch: 904\n",
      "Done with the batch: 905\n",
      "Done with the batch: 906\n",
      "Done with the batch: 907\n",
      "Done with the batch: 908\n",
      "Done with the batch: 909\n",
      "Done with the batch: 910\n",
      "Done with the batch: 911\n",
      "Done with the batch: 912\n",
      "Done with the batch: 913\n",
      "Done with the batch: 914\n",
      "Done with the batch: 915\n",
      "Done with the batch: 916\n",
      "Done with the batch: 917\n",
      "Done with the batch: 918\n",
      "Done with the batch: 919\n",
      "Done with the batch: 920\n",
      "Done with the batch: 921\n",
      "Done with the batch: 922\n",
      "Done with the batch: 923\n",
      "Done with the batch: 924\n",
      "Done with the batch: 925\n",
      "Done with the batch: 926\n",
      "Done with the batch: 927\n",
      "Done with the batch: 928\n",
      "Done with the batch: 929\n",
      "Done with the batch: 930\n",
      "Done with the batch: 931\n",
      "Done with the batch: 932\n",
      "Done with the batch: 933\n",
      "Done with the batch: 934\n",
      "Done with the batch: 935\n",
      "Done with the batch: 936\n",
      "Done with the batch: 937\n",
      "Done with the batch: 938\n",
      "Done with the batch: 939\n",
      "Done with the batch: 940\n",
      "Done with the batch: 941\n",
      "Done with the batch: 942\n",
      "Done with the batch: 943\n",
      "Done with the batch: 944\n",
      "Done with the batch: 945\n",
      "Done with the batch: 946\n",
      "Done with the batch: 947\n",
      "Done with the batch: 948\n",
      "Done with the batch: 949\n",
      "Done with the batch: 950\n",
      "Done with the batch: 951\n",
      "Done with the batch: 952\n",
      "Done with the batch: 953\n",
      "Done with the batch: 954\n",
      "Done with the batch: 955\n",
      "Done with the batch: 956\n",
      "Done with the batch: 957\n",
      "Done with the batch: 958\n",
      "Done with the batch: 959\n",
      "Done with the batch: 960\n",
      "Done with the batch: 961\n",
      "Done with the batch: 962\n",
      "Done with the batch: 963\n",
      "Done with the batch: 964\n",
      "Done with the batch: 965\n",
      "Done with the batch: 966\n",
      "Done with the batch: 967\n",
      "Done with the batch: 968\n",
      "Done with the batch: 969\n",
      "Done with the batch: 970\n",
      "Done with the batch: 971\n",
      "Done with the batch: 972\n",
      "Done with the batch: 973\n",
      "Done with the batch: 974\n",
      "Done with the batch: 975\n",
      "Done with the batch: 976\n",
      "Done with the batch: 977\n",
      "Done with the batch: 978\n",
      "Done with the batch: 979\n",
      "Done with the batch: 980\n",
      "Done with the batch: 981\n",
      "Done with the batch: 982\n",
      "Done with the batch: 983\n",
      "Done with the batch: 984\n",
      "Done with the batch: 985\n",
      "Done with the batch: 986\n",
      "Done with the batch: 987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 988\n",
      "Done with the batch: 989\n",
      "Done with the batch: 990\n",
      "Done with the batch: 991\n",
      "Done with the batch: 992\n",
      "Done with the batch: 993\n",
      "Done with the batch: 994\n",
      "Done with the batch: 995\n",
      "Done with the batch: 996\n",
      "Done with the batch: 997\n",
      "Done with the batch: 998\n",
      "Done with the batch: 999\n",
      "Done with the batch: 1000\n",
      "Done with the batch: 1001\n",
      "Done with the batch: 1002\n",
      "Done with the batch: 1003\n",
      "Done with the batch: 1004\n",
      "Done with the batch: 1005\n",
      "Done with the batch: 1006\n",
      "Done with the batch: 1007\n",
      "Done with the batch: 1008\n",
      "Done with the batch: 1009\n",
      "Done with the batch: 1010\n",
      "Done with the batch: 1011\n",
      "Done with the batch: 1012\n",
      "Done with the batch: 1013\n",
      "Done with the batch: 1014\n",
      "Done with the batch: 1015\n",
      "Done with the batch: 1016\n",
      "Done with the batch: 1017\n",
      "Done with the batch: 1018\n",
      "Done with the batch: 1019\n",
      "Done with the batch: 1020\n",
      "Done with the batch: 1021\n",
      "Done with the batch: 1022\n",
      "Done with the batch: 1023\n",
      "Done with the batch: 1024\n",
      "Done with the batch: 1025\n",
      "Done with the batch: 1026\n",
      "Done with the batch: 1027\n",
      "Done with the batch: 1028\n",
      "Done with the batch: 1029\n",
      "Done with the batch: 1030\n",
      "Done with the batch: 1031\n",
      "Done with the batch: 1032\n",
      "Done with the batch: 1033\n",
      "Done with the batch: 1034\n",
      "Done with the batch: 1035\n",
      "Done with the batch: 1036\n",
      "Done with the batch: 1037\n",
      "Done with the batch: 1038\n",
      "Done with the batch: 1039\n",
      "Done with the batch: 1040\n",
      "Done with the batch: 1041\n",
      "Done with the batch: 1042\n",
      "Done with the batch: 1043\n",
      "Done with the batch: 1044\n",
      "Done with the batch: 1045\n",
      "Done with the batch: 1046\n",
      "Done with the batch: 1047\n",
      "Done with the batch: 1048\n",
      "Done with the batch: 1049\n",
      "Done with the batch: 1050\n",
      "Done with the batch: 1051\n",
      "Done with the batch: 1052\n",
      "Done with the batch: 1053\n",
      "Done with the batch: 1054\n",
      "Done with the batch: 1055\n",
      "Done with the batch: 1056\n",
      "Done with the batch: 1057\n",
      "Done with the batch: 1058\n",
      "Done with the batch: 1059\n",
      "Done with the batch: 1060\n",
      "Done with the batch: 1061\n",
      "Done with the batch: 1062\n",
      "Done with the batch: 1063\n",
      "Done with the batch: 1064\n",
      "Done with the batch: 1065\n",
      "Done with the batch: 1066\n",
      "Done with the batch: 1067\n",
      "Done with the batch: 1068\n",
      "Done with the batch: 1069\n",
      "Done with the batch: 1070\n",
      "Done with the batch: 1071\n",
      "Done with the batch: 1072\n",
      "Done with the batch: 1073\n",
      "Done with the batch: 1074\n",
      "Done with the batch: 1075\n",
      "Done with the batch: 1076\n",
      "Done with the batch: 1077\n",
      "Done with the batch: 1078\n",
      "Done with the batch: 1079\n",
      "Done with the batch: 1080\n",
      "Done with the batch: 1081\n",
      "Done with the batch: 1082\n",
      "Done with the batch: 1083\n",
      "Done with the batch: 1084\n",
      "Done with the batch: 1085\n",
      "Done with the batch: 1086\n",
      "Done with the batch: 1087\n",
      "Done with the batch: 1088\n",
      "Done with the batch: 1089\n",
      "Done with the batch: 1090\n",
      "Done with the batch: 1091\n",
      "Done with the batch: 1092\n",
      "Done with the batch: 1093\n",
      "Done with the batch: 1094\n",
      "Done with the batch: 1095\n",
      "Done with the batch: 1096\n",
      "Done with the batch: 1097\n",
      "Done with the batch: 1098\n",
      "Done with the batch: 1099\n",
      "Done with the batch: 1100\n",
      "Done with the batch: 1101\n",
      "Done with the batch: 1102\n",
      "Done with the batch: 1103\n",
      "Done with the batch: 1104\n",
      "Done with the batch: 1105\n",
      "Done with the batch: 1106\n",
      "Done with the batch: 1107\n",
      "Done with the batch: 1108\n",
      "Done with the batch: 1109\n",
      "Done with the batch: 1110\n",
      "Done with the batch: 1111\n",
      "Done with the batch: 1112\n",
      "Done with the batch: 1113\n",
      "Done with the batch: 1114\n",
      "Done with the batch: 1115\n",
      "Done with the batch: 1116\n",
      "Done with the batch: 1117\n",
      "Done with the batch: 1118\n",
      "Done with the batch: 1119\n",
      "Done with the batch: 1120\n",
      "Done with the batch: 1121\n",
      "Done with the batch: 1122\n",
      "Done with the batch: 1123\n",
      "Done with the batch: 1124\n",
      "Done with the batch: 1125\n",
      "Done with the batch: 1126\n",
      "Done with the batch: 1127\n",
      "Done with the batch: 1128\n",
      "Done with the batch: 1129\n",
      "Done with the batch: 1130\n",
      "Done with the batch: 1131\n",
      "Done with the batch: 1132\n",
      "Done with the batch: 1133\n",
      "Done with the batch: 1134\n",
      "Done with the batch: 1135\n",
      "Done with the batch: 1136\n",
      "Done with the batch: 1137\n",
      "Done with the batch: 1138\n",
      "Done with the batch: 1139\n",
      "Done with the batch: 1140\n",
      "Done with the batch: 1141\n",
      "Done with the batch: 1142\n",
      "Done with the batch: 1143\n",
      "Done with the batch: 1144\n",
      "Done with the batch: 1145\n",
      "Done with the batch: 1146\n",
      "Done with the batch: 1147\n",
      "Done with the batch: 1148\n",
      "Done with the batch: 1149\n",
      "Done with the batch: 1150\n",
      "Done with the batch: 1151\n",
      "Done with the batch: 1152\n",
      "Done with the batch: 1153\n",
      "Done with the batch: 1154\n",
      "Done with the batch: 1155\n",
      "Done with the batch: 1156\n",
      "Done with the batch: 1157\n",
      "Done with the batch: 1158\n",
      "Done with the batch: 1159\n",
      "Done with the batch: 1160\n",
      "Done with the batch: 1161\n",
      "Done with the batch: 1162\n",
      "Done with the batch: 1163\n",
      "Done with the batch: 1164\n",
      "Done with the batch: 1165\n",
      "Done with the batch: 1166\n",
      "Done with the batch: 1167\n",
      "Done with the batch: 1168\n",
      "Done with the batch: 1169\n",
      "Done with the batch: 1170\n",
      "Done with the batch: 1171\n",
      "Done with the batch: 1172\n",
      "Done with the batch: 1173\n",
      "Done with the batch: 1174\n",
      "Done with the batch: 1175\n",
      "Done with the batch: 1176\n",
      "Done with the batch: 1177\n",
      "Done with the batch: 1178\n",
      "Done with the batch: 1179\n",
      "Done with the batch: 1180\n",
      "Done with the batch: 1181\n",
      "Done with the batch: 1182\n",
      "Done with the batch: 1183\n",
      "Done with the batch: 1184\n",
      "Done with the batch: 1185\n",
      "Done with the batch: 1186\n",
      "Done with the batch: 1187\n",
      "Done with the batch: 1188\n",
      "Done with the batch: 1189\n",
      "Done with the batch: 1190\n",
      "Done with the batch: 1191\n",
      "Done with the batch: 1192\n",
      "Done with the batch: 1193\n",
      "Done with the batch: 1194\n",
      "Done with the batch: 1195\n",
      "Done with the batch: 1196\n",
      "Done with the batch: 1197\n",
      "Done with the batch: 1198\n",
      "Done with the batch: 1199\n",
      "Done with the batch: 1200\n",
      "Done with the batch: 1201\n",
      "Done with the batch: 1202\n",
      "Done with the batch: 1203\n",
      "Done with the batch: 1204\n",
      "Done with the batch: 1205\n",
      "Done with the batch: 1206\n",
      "Done with the batch: 1207\n",
      "Done with the batch: 1208\n",
      "Done with the batch: 1209\n",
      "Done with the batch: 1210\n",
      "Done with the batch: 1211\n",
      "Done with the batch: 1212\n",
      "Done with the batch: 1213\n",
      "Done with the batch: 1214\n",
      "Done with the batch: 1215\n",
      "Done with the batch: 1216\n",
      "Done with the batch: 1217\n",
      "Done with the batch: 1218\n",
      "Done with the batch: 1219\n",
      "Done with the batch: 1220\n",
      "Done with the batch: 1221\n",
      "Done with the batch: 1222\n",
      "Done with the batch: 1223\n",
      "Done with the batch: 1224\n",
      "Done with the batch: 1225\n",
      "Done with the batch: 1226\n",
      "Done with the batch: 1227\n",
      "Done with the batch: 1228\n",
      "Done with the batch: 1229\n",
      "Done with the batch: 1230\n",
      "Done with the batch: 1231\n",
      "Done with the batch: 1232\n",
      "Done with the batch: 1233\n",
      "Done with the batch: 1234\n",
      "Done with the batch: 1235\n",
      "Done with the batch: 1236\n",
      "Done with the batch: 1237\n",
      "Done with the batch: 1238\n",
      "Done with the batch: 1239\n",
      "Done with the batch: 1240\n",
      "Done with the batch: 1241\n",
      "Done with the batch: 1242\n",
      "Done with the batch: 1243\n",
      "Done with the batch: 1244\n",
      "Done with the batch: 1245\n",
      "Done with the batch: 1246\n",
      "Done with the batch: 1247\n",
      "Done with the batch: 1248\n",
      "Done with the batch: 1249\n",
      "Done with the batch: 1250\n",
      "Done with the batch: 1251\n",
      "Done with the batch: 1252\n",
      "Done with the batch: 1253\n",
      "Done with the batch: 1254\n",
      "Done with the batch: 1255\n",
      "Done with the batch: 1256\n",
      "Done with the batch: 1257\n",
      "Done with the batch: 1258\n",
      "Done with the batch: 1259\n",
      "Done with the batch: 1260\n",
      "Done with the batch: 1261\n",
      "Done with the batch: 1262\n",
      "Done with the batch: 1263\n",
      "Done with the batch: 1264\n",
      "Done with the batch: 1265\n",
      "Done with the batch: 1266\n",
      "Done with the batch: 1267\n",
      "Done with the batch: 1268\n",
      "Done with the batch: 1269\n",
      "Done with the batch: 1270\n",
      "Done with the batch: 1271\n",
      "Done with the batch: 1272\n",
      "Done with the batch: 1273\n",
      "Done with the batch: 1274\n",
      "Done with the batch: 1275\n",
      "Done with the batch: 1276\n",
      "Done with the batch: 1277\n",
      "Done with the batch: 1278\n",
      "Done with the batch: 1279\n",
      "Done with the batch: 1280\n",
      "Done with the batch: 1281\n",
      "Done with the batch: 1282\n",
      "Done with the batch: 1283\n",
      "Done with the batch: 1284\n",
      "Done with the batch: 1285\n",
      "Done with the batch: 1286\n",
      "Done with the batch: 1287\n",
      "Done with the batch: 1288\n",
      "Done with the batch: 1289\n",
      "Done with the batch: 1290\n",
      "Done with the batch: 1291\n",
      "Done with the batch: 1292\n",
      "Done with the batch: 1293\n",
      "Done with the batch: 1294\n",
      "Done with the batch: 1295\n",
      "Done with the batch: 1296\n",
      "Done with the batch: 1297\n",
      "Done with the batch: 1298\n",
      "Done with the batch: 1299\n",
      "Done with the batch: 1300\n",
      "Done with the batch: 1301\n",
      "Done with the batch: 1302\n",
      "Done with the batch: 1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 1304\n",
      "Done with the batch: 1305\n",
      "Done with the batch: 1306\n",
      "Done with the batch: 1307\n",
      "Done with the batch: 1308\n",
      "Done with the batch: 1309\n",
      "Done with the batch: 1310\n",
      "Done with the batch: 1311\n",
      "Done with the batch: 1312\n",
      "Done with the batch: 1313\n",
      "Done with the batch: 1314\n",
      "Done with the batch: 1315\n",
      "Done with the batch: 1316\n",
      "Done with the batch: 1317\n",
      "Done with the batch: 1318\n",
      "Done with the batch: 1319\n",
      "Done with the batch: 1320\n",
      "Done with the batch: 1321\n",
      "Done with the batch: 1322\n",
      "Done with the batch: 1323\n",
      "Done with the batch: 1324\n",
      "Done with the batch: 1325\n",
      "Done with the batch: 1326\n",
      "Done with the batch: 1327\n",
      "Done with the batch: 1328\n",
      "Done with the batch: 1329\n",
      "Done with the batch: 1330\n",
      "Done with the batch: 1331\n",
      "Done with the batch: 1332\n",
      "Done with the batch: 1333\n",
      "Done with the batch: 1334\n",
      "Done with the batch: 1335\n",
      "Done with the batch: 1336\n",
      "Done with the batch: 1337\n",
      "Done with the batch: 1338\n",
      "Done with the batch: 1339\n",
      "Done with the batch: 1340\n",
      "Done with the batch: 1341\n",
      "Done with the batch: 1342\n",
      "Done with the batch: 1343\n",
      "Done with the batch: 1344\n",
      "Done with the batch: 1345\n",
      "Done with the batch: 1346\n",
      "Done with the batch: 1347\n",
      "Done with the batch: 1348\n",
      "Done with the batch: 1349\n",
      "Done with the batch: 1350\n",
      "Done with the batch: 1351\n",
      "Done with the batch: 1352\n",
      "Done with the batch: 1353\n",
      "Done with the batch: 1354\n",
      "Done with the batch: 1355\n",
      "Done with the batch: 1356\n",
      "Done with the batch: 1357\n",
      "Done with the batch: 1358\n",
      "Done with the batch: 1359\n",
      "Done with the batch: 1360\n",
      "Done with the batch: 1361\n",
      "Done with the batch: 1362\n",
      "Done with the batch: 1363\n",
      "Done with the batch: 1364\n",
      "Done with the batch: 1365\n",
      "Done with the batch: 1366\n",
      "Done with the batch: 1367\n",
      "Done with the batch: 1368\n",
      "Done with the batch: 1369\n",
      "Done with the batch: 1370\n",
      "Done with the batch: 1371\n",
      "Done with the batch: 1372\n",
      "Done with the batch: 1373\n",
      "Done with the batch: 1374\n",
      "Done with the batch: 1375\n",
      "Done with the batch: 1376\n",
      "Done with the batch: 1377\n",
      "Done with the batch: 1378\n",
      "Done with the batch: 1379\n",
      "Done with the batch: 1380\n",
      "Done with the batch: 1381\n",
      "Done with the batch: 1382\n",
      "Done with the batch: 1383\n",
      "Done with the batch: 1384\n",
      "Done with the batch: 1385\n",
      "Done with the batch: 1386\n",
      "Done with the batch: 1387\n",
      "Done with the batch: 1388\n",
      "Done with the batch: 1389\n",
      "Done with the batch: 1390\n",
      "Done with the batch: 1391\n",
      "Done with the batch: 1392\n",
      "Done with the batch: 1393\n",
      "Done with the batch: 1394\n",
      "Done with the batch: 1395\n",
      "Done with the batch: 1396\n",
      "Done with the batch: 1397\n",
      "Done with the batch: 1398\n",
      "Done with the batch: 1399\n",
      "Done with the batch: 1400\n",
      "Done with the batch: 1401\n",
      "Done with the batch: 1402\n",
      "Done with the batch: 1403\n",
      "Done with the batch: 1404\n",
      "Done with the batch: 1405\n",
      "Done with the batch: 1406\n",
      "Done with the batch: 1407\n",
      "Done with the batch: 1408\n",
      "Done with the batch: 1409\n",
      "Done with the batch: 1410\n",
      "Done with the batch: 1411\n",
      "Done with the batch: 1412\n",
      "Done with the batch: 1413\n",
      "Done with the batch: 1414\n",
      "Done with the batch: 1415\n",
      "Done with the batch: 1416\n",
      "Done with the batch: 1417\n",
      "Done with the batch: 1418\n",
      "Done with the batch: 1419\n",
      "Done with the batch: 1420\n",
      "Done with the batch: 1421\n",
      "Done with the batch: 1422\n",
      "Done with the batch: 1423\n",
      "Done with the batch: 1424\n",
      "Done with the batch: 1425\n",
      "Done with the batch: 1426\n",
      "Done with the batch: 1427\n",
      "Done with the batch: 1428\n",
      "Done with the batch: 1429\n",
      "Done with the batch: 1430\n",
      "Done with the batch: 1431\n",
      "Done with the batch: 1432\n",
      "Done with the batch: 1433\n",
      "Done with the batch: 1434\n",
      "Done with the batch: 1435\n",
      "Done with the batch: 1436\n",
      "Done with the batch: 1437\n",
      "Done with the batch: 1438\n",
      "Done with the batch: 1439\n",
      "Done with the batch: 1440\n",
      "Done with the batch: 1441\n",
      "Done with the batch: 1442\n",
      "Done with the batch: 1443\n",
      "Done with the batch: 1444\n",
      "Done with the batch: 1445\n",
      "Done with the batch: 1446\n",
      "Done with the batch: 1447\n",
      "Done with the batch: 1448\n",
      "Done with the batch: 1449\n",
      "Done with the batch: 1450\n",
      "Done with the batch: 1451\n",
      "Done with the batch: 1452\n",
      "Done with the batch: 1453\n",
      "Done with the batch: 1454\n",
      "Done with the batch: 1455\n",
      "Done with the batch: 1456\n",
      "Done with the batch: 1457\n",
      "Done with the batch: 1458\n",
      "Done with the batch: 1459\n",
      "Done with the batch: 1460\n",
      "Done with the batch: 1461\n",
      "Done with the batch: 1462\n",
      "Done with the batch: 1463\n",
      "Done with the batch: 1464\n",
      "Done with the batch: 1465\n",
      "Done with the batch: 1466\n",
      "Done with the batch: 1467\n",
      "Done with the batch: 1468\n",
      "Done with the batch: 1469\n",
      "Done with the batch: 1470\n",
      "Done with the batch: 1471\n",
      "Done with the batch: 1472\n",
      "Done with the batch: 1473\n",
      "Done with the batch: 1474\n",
      "Done with the batch: 1475\n",
      "Done with the batch: 1476\n",
      "Done with the batch: 1477\n",
      "Done with the batch: 1478\n",
      "Done with the batch: 1479\n",
      "Done with the batch: 1480\n",
      "Done with the batch: 1481\n",
      "Done with the batch: 1482\n",
      "Done with the batch: 1483\n",
      "Done with the batch: 1484\n",
      "Done with the batch: 1485\n",
      "Done with the batch: 1486\n",
      "Done with the batch: 1487\n",
      "Done with the batch: 1488\n",
      "Done with the batch: 1489\n",
      "Done with the batch: 1490\n",
      "Done with the batch: 1491\n",
      "Done with the batch: 1492\n",
      "Done with the batch: 1493\n",
      "Done with the batch: 1494\n",
      "Done with the batch: 1495\n",
      "Done with the batch: 1496\n",
      "Done with the batch: 1497\n",
      "Done with the batch: 1498\n",
      "Done with the batch: 1499\n",
      "Done with the batch: 1500\n",
      "Done with the batch: 1501\n",
      "Done with the batch: 1502\n",
      "Done with the batch: 1503\n",
      "Done with the batch: 1504\n",
      "Done with the batch: 1505\n",
      "Done with the batch: 1506\n",
      "Done with the batch: 1507\n",
      "Done with the batch: 1508\n",
      "Done with the batch: 1509\n",
      "Done with the batch: 1510\n",
      "Done with the batch: 1511\n",
      "Done with the batch: 1512\n",
      "Done with the batch: 1513\n",
      "Done with the batch: 1514\n",
      "Done with the batch: 1515\n",
      "Done with the batch: 1516\n",
      "Done with the batch: 1517\n",
      "Done with the batch: 1518\n",
      "Done with the batch: 1519\n",
      "Done with the batch: 1520\n",
      "Done with the batch: 1521\n",
      "Done with the batch: 1522\n",
      "Done with the batch: 1523\n",
      "Done with the batch: 1524\n",
      "Done with the batch: 1525\n",
      "Done with the batch: 1526\n",
      "Done with the batch: 1527\n",
      "Done with the batch: 1528\n",
      "Done with the batch: 1529\n",
      "Done with the batch: 1530\n",
      "Done with the batch: 1531\n",
      "Done with the batch: 1532\n",
      "Done with the batch: 1533\n",
      "Done with the batch: 1534\n",
      "Done with the batch: 1535\n",
      "Done with the batch: 1536\n",
      "Done with the batch: 1537\n",
      "Done with the batch: 1538\n",
      "Done with the batch: 1539\n",
      "Done with the batch: 1540\n",
      "Done with the batch: 1541\n",
      "Done with the batch: 1542\n",
      "Done with the batch: 1543\n",
      "Done with the batch: 1544\n",
      "Done with the batch: 1545\n",
      "Done with the batch: 1546\n",
      "Done with the batch: 1547\n",
      "Done with the batch: 1548\n",
      "Done with the batch: 1549\n",
      "Done with the batch: 1550\n",
      "Done with the batch: 1551\n",
      "Done with the batch: 1552\n",
      "Done with the batch: 1553\n",
      "Done with the batch: 1554\n",
      "Done with the batch: 1555\n",
      "Done with the batch: 1556\n",
      "Done with the batch: 1557\n",
      "Done with the batch: 1558\n",
      "Done with the batch: 1559\n",
      "Done with the batch: 1560\n",
      "Done with the batch: 1561\n",
      "Done with the batch: 1562\n",
      "Done with the batch: 1563\n",
      "Done with the batch: 1564\n",
      "Done with the batch: 1565\n",
      "Done with the batch: 1566\n",
      "Done with the batch: 1567\n",
      "Done with the batch: 1568\n",
      "Done with the batch: 1569\n",
      "Done with the batch: 1570\n",
      "Done with the batch: 1571\n",
      "Done with the batch: 1572\n",
      "Done with the batch: 1573\n",
      "Done with the batch: 1574\n",
      "Done with the batch: 1575\n",
      "Done with the batch: 1576\n",
      "Done with the batch: 1577\n",
      "Done with the batch: 1578\n",
      "Done with the batch: 1579\n",
      "Done with the batch: 1580\n",
      "Done with the batch: 1581\n",
      "Done with the batch: 1582\n",
      "Done with the batch: 1583\n",
      "Done with the batch: 1584\n",
      "Done with the batch: 1585\n",
      "Done with the batch: 1586\n",
      "Done with the batch: 1587\n",
      "Done with the batch: 1588\n",
      "Done with the batch: 1589\n",
      "Done with the batch: 1590\n",
      "Done with the batch: 1591\n",
      "Done with the batch: 1592\n",
      "Done with the batch: 1593\n",
      "Done with the batch: 1594\n",
      "Done with the batch: 1595\n",
      "Done with the batch: 1596\n",
      "Done with the batch: 1597\n",
      "Done with the batch: 1598\n",
      "Done with the batch: 1599\n",
      "Done with the batch: 1600\n",
      "Done with the batch: 1601\n",
      "Done with the batch: 1602\n",
      "Done with the batch: 1603\n",
      "Done with the batch: 1604\n",
      "Done with the batch: 1605\n",
      "Done with the batch: 1606\n",
      "Done with the batch: 1607\n",
      "Done with the batch: 1608\n",
      "Done with the batch: 1609\n",
      "Done with the batch: 1610\n",
      "Done with the batch: 1611\n",
      "Done with the batch: 1612\n",
      "Done with the batch: 1613\n",
      "Done with the batch: 1614\n",
      "Done with the batch: 1615\n",
      "Done with the batch: 1616\n",
      "Done with the batch: 1617\n",
      "(6470, 25088) (6470,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"fd42db66-d911-4fb1-af5c-9871d39e2c38\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"fd42db66-d911-4fb1-af5c-9871d39e2c38\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "X_Train_FeatureMap=np.empty((0,25088))\n",
    "Y_Train_FeatureMap=np.empty((0,batch_size))\n",
    "print(X_Train_FeatureMap.shape)\n",
    "for i,data in enumerate(trainloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    featureMap=vgg.get_Representation_Net(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Train_FeatureMap=np.append(X_Train_FeatureMap,featureMap,axis=0)\n",
    "    Y_Train_FeatureMap=np.append(Y_Train_FeatureMap,labels.numpy())\n",
    "print(X_Train_FeatureMap.shape,Y_Train_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f82e21d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 25088)\n",
      "Done with the batch: 0\n",
      "Done with the batch: 1\n",
      "Done with the batch: 2\n",
      "Done with the batch: 3\n",
      "Done with the batch: 4\n",
      "Done with the batch: 5\n",
      "Done with the batch: 6\n",
      "Done with the batch: 7\n",
      "Done with the batch: 8\n",
      "Done with the batch: 9\n",
      "Done with the batch: 10\n",
      "Done with the batch: 11\n",
      "Done with the batch: 12\n",
      "Done with the batch: 13\n",
      "Done with the batch: 14\n",
      "Done with the batch: 15\n",
      "Done with the batch: 16\n",
      "Done with the batch: 17\n",
      "Done with the batch: 18\n",
      "Done with the batch: 19\n",
      "Done with the batch: 20\n",
      "Done with the batch: 21\n",
      "Done with the batch: 22\n",
      "Done with the batch: 23\n",
      "Done with the batch: 24\n",
      "Done with the batch: 25\n",
      "Done with the batch: 26\n",
      "Done with the batch: 27\n",
      "Done with the batch: 28\n",
      "Done with the batch: 29\n",
      "Done with the batch: 30\n",
      "Done with the batch: 31\n",
      "Done with the batch: 32\n",
      "Done with the batch: 33\n",
      "Done with the batch: 34\n",
      "Done with the batch: 35\n",
      "Done with the batch: 36\n",
      "Done with the batch: 37\n",
      "Done with the batch: 38\n",
      "Done with the batch: 39\n",
      "Done with the batch: 40\n",
      "Done with the batch: 41\n",
      "Done with the batch: 42\n",
      "Done with the batch: 43\n",
      "Done with the batch: 44\n",
      "Done with the batch: 45\n",
      "Done with the batch: 46\n",
      "Done with the batch: 47\n",
      "Done with the batch: 48\n",
      "Done with the batch: 49\n",
      "Done with the batch: 50\n",
      "Done with the batch: 51\n",
      "Done with the batch: 52\n",
      "Done with the batch: 53\n",
      "Done with the batch: 54\n",
      "Done with the batch: 55\n",
      "Done with the batch: 56\n",
      "Done with the batch: 57\n",
      "Done with the batch: 58\n",
      "Done with the batch: 59\n",
      "Done with the batch: 60\n",
      "Done with the batch: 61\n",
      "Done with the batch: 62\n",
      "Done with the batch: 63\n",
      "Done with the batch: 64\n",
      "Done with the batch: 65\n",
      "Done with the batch: 66\n",
      "Done with the batch: 67\n",
      "Done with the batch: 68\n",
      "Done with the batch: 69\n",
      "Done with the batch: 70\n",
      "Done with the batch: 71\n",
      "Done with the batch: 72\n",
      "Done with the batch: 73\n",
      "Done with the batch: 74\n",
      "Done with the batch: 75\n",
      "Done with the batch: 76\n",
      "Done with the batch: 77\n",
      "Done with the batch: 78\n",
      "Done with the batch: 79\n",
      "Done with the batch: 80\n",
      "Done with the batch: 81\n",
      "Done with the batch: 82\n",
      "Done with the batch: 83\n",
      "Done with the batch: 84\n",
      "Done with the batch: 85\n",
      "Done with the batch: 86\n",
      "Done with the batch: 87\n",
      "Done with the batch: 88\n",
      "Done with the batch: 89\n",
      "Done with the batch: 90\n",
      "Done with the batch: 91\n",
      "Done with the batch: 92\n",
      "Done with the batch: 93\n",
      "Done with the batch: 94\n",
      "Done with the batch: 95\n",
      "Done with the batch: 96\n",
      "Done with the batch: 97\n",
      "Done with the batch: 98\n",
      "Done with the batch: 99\n",
      "Done with the batch: 100\n",
      "Done with the batch: 101\n",
      "Done with the batch: 102\n",
      "Done with the batch: 103\n",
      "Done with the batch: 104\n",
      "Done with the batch: 105\n",
      "Done with the batch: 106\n",
      "Done with the batch: 107\n",
      "Done with the batch: 108\n",
      "Done with the batch: 109\n",
      "Done with the batch: 110\n",
      "Done with the batch: 111\n",
      "Done with the batch: 112\n",
      "Done with the batch: 113\n",
      "Done with the batch: 114\n",
      "Done with the batch: 115\n",
      "Done with the batch: 116\n",
      "Done with the batch: 117\n",
      "Done with the batch: 118\n",
      "Done with the batch: 119\n",
      "Done with the batch: 120\n",
      "Done with the batch: 121\n",
      "Done with the batch: 122\n",
      "Done with the batch: 123\n",
      "Done with the batch: 124\n",
      "Done with the batch: 125\n",
      "Done with the batch: 126\n",
      "Done with the batch: 127\n",
      "Done with the batch: 128\n",
      "Done with the batch: 129\n",
      "Done with the batch: 130\n",
      "Done with the batch: 131\n",
      "Done with the batch: 132\n",
      "Done with the batch: 133\n",
      "Done with the batch: 134\n",
      "Done with the batch: 135\n",
      "Done with the batch: 136\n",
      "Done with the batch: 137\n",
      "Done with the batch: 138\n",
      "Done with the batch: 139\n",
      "Done with the batch: 140\n",
      "Done with the batch: 141\n",
      "Done with the batch: 142\n",
      "Done with the batch: 143\n",
      "Done with the batch: 144\n",
      "Done with the batch: 145\n",
      "Done with the batch: 146\n",
      "Done with the batch: 147\n",
      "Done with the batch: 148\n",
      "Done with the batch: 149\n",
      "Done with the batch: 150\n",
      "Done with the batch: 151\n",
      "Done with the batch: 152\n",
      "Done with the batch: 153\n",
      "Done with the batch: 154\n",
      "Done with the batch: 155\n",
      "Done with the batch: 156\n",
      "Done with the batch: 157\n",
      "Done with the batch: 158\n",
      "Done with the batch: 159\n",
      "Done with the batch: 160\n",
      "Done with the batch: 161\n",
      "Done with the batch: 162\n",
      "Done with the batch: 163\n",
      "Done with the batch: 164\n",
      "Done with the batch: 165\n",
      "Done with the batch: 166\n",
      "Done with the batch: 167\n",
      "Done with the batch: 168\n",
      "Done with the batch: 169\n",
      "Done with the batch: 170\n",
      "Done with the batch: 171\n",
      "Done with the batch: 172\n",
      "Done with the batch: 173\n",
      "Done with the batch: 174\n",
      "Done with the batch: 175\n",
      "Done with the batch: 176\n",
      "Done with the batch: 177\n",
      "Done with the batch: 178\n",
      "Done with the batch: 179\n",
      "Done with the batch: 180\n",
      "Done with the batch: 181\n",
      "Done with the batch: 182\n",
      "Done with the batch: 183\n",
      "Done with the batch: 184\n",
      "Done with the batch: 185\n",
      "Done with the batch: 186\n",
      "Done with the batch: 187\n",
      "Done with the batch: 188\n",
      "Done with the batch: 189\n",
      "Done with the batch: 190\n",
      "Done with the batch: 191\n",
      "Done with the batch: 192\n",
      "Done with the batch: 193\n",
      "Done with the batch: 194\n",
      "Done with the batch: 195\n",
      "Done with the batch: 196\n",
      "Done with the batch: 197\n",
      "Done with the batch: 198\n",
      "Done with the batch: 199\n",
      "Done with the batch: 200\n",
      "Done with the batch: 201\n",
      "Done with the batch: 202\n",
      "Done with the batch: 203\n",
      "Done with the batch: 204\n",
      "Done with the batch: 205\n",
      "Done with the batch: 206\n",
      "Done with the batch: 207\n",
      "Done with the batch: 208\n",
      "Done with the batch: 209\n",
      "Done with the batch: 210\n",
      "Done with the batch: 211\n",
      "Done with the batch: 212\n",
      "Done with the batch: 213\n",
      "Done with the batch: 214\n",
      "Done with the batch: 215\n",
      "Done with the batch: 216\n",
      "Done with the batch: 217\n",
      "Done with the batch: 218\n",
      "Done with the batch: 219\n",
      "Done with the batch: 220\n",
      "Done with the batch: 221\n",
      "Done with the batch: 222\n",
      "Done with the batch: 223\n",
      "Done with the batch: 224\n",
      "Done with the batch: 225\n",
      "Done with the batch: 226\n",
      "Done with the batch: 227\n",
      "Done with the batch: 228\n",
      "Done with the batch: 229\n",
      "Done with the batch: 230\n",
      "Done with the batch: 231\n",
      "Done with the batch: 232\n",
      "Done with the batch: 233\n",
      "Done with the batch: 234\n",
      "Done with the batch: 235\n",
      "Done with the batch: 236\n",
      "Done with the batch: 237\n",
      "Done with the batch: 238\n",
      "Done with the batch: 239\n",
      "Done with the batch: 240\n",
      "Done with the batch: 241\n",
      "Done with the batch: 242\n",
      "Done with the batch: 243\n",
      "Done with the batch: 244\n",
      "Done with the batch: 245\n",
      "Done with the batch: 246\n",
      "Done with the batch: 247\n",
      "Done with the batch: 248\n",
      "Done with the batch: 249\n",
      "Done with the batch: 250\n",
      "Done with the batch: 251\n",
      "Done with the batch: 252\n",
      "Done with the batch: 253\n",
      "Done with the batch: 254\n",
      "Done with the batch: 255\n",
      "Done with the batch: 256\n",
      "Done with the batch: 257\n",
      "Done with the batch: 258\n",
      "Done with the batch: 259\n",
      "Done with the batch: 260\n",
      "Done with the batch: 261\n",
      "Done with the batch: 262\n",
      "Done with the batch: 263\n",
      "Done with the batch: 264\n",
      "Done with the batch: 265\n",
      "Done with the batch: 266\n",
      "Done with the batch: 267\n",
      "Done with the batch: 268\n",
      "Done with the batch: 269\n",
      "Done with the batch: 270\n",
      "Done with the batch: 271\n",
      "Done with the batch: 272\n",
      "Done with the batch: 273\n",
      "Done with the batch: 274\n",
      "Done with the batch: 275\n",
      "Done with the batch: 276\n",
      "Done with the batch: 277\n",
      "Done with the batch: 278\n",
      "Done with the batch: 279\n",
      "Done with the batch: 280\n",
      "Done with the batch: 281\n",
      "Done with the batch: 282\n",
      "Done with the batch: 283\n",
      "Done with the batch: 284\n",
      "Done with the batch: 285\n",
      "Done with the batch: 286\n",
      "Done with the batch: 287\n",
      "Done with the batch: 288\n",
      "Done with the batch: 289\n",
      "Done with the batch: 290\n",
      "Done with the batch: 291\n",
      "Done with the batch: 292\n",
      "Done with the batch: 293\n",
      "Done with the batch: 294\n",
      "Done with the batch: 295\n",
      "Done with the batch: 296\n",
      "Done with the batch: 297\n",
      "Done with the batch: 298\n",
      "Done with the batch: 299\n",
      "Done with the batch: 300\n",
      "Done with the batch: 301\n",
      "Done with the batch: 302\n",
      "Done with the batch: 303\n",
      "Done with the batch: 304\n",
      "Done with the batch: 305\n",
      "Done with the batch: 306\n",
      "Done with the batch: 307\n",
      "Done with the batch: 308\n",
      "Done with the batch: 309\n",
      "Done with the batch: 310\n",
      "Done with the batch: 311\n",
      "Done with the batch: 312\n",
      "Done with the batch: 313\n",
      "Done with the batch: 314\n",
      "Done with the batch: 315\n",
      "Done with the batch: 316\n",
      "Done with the batch: 317\n",
      "Done with the batch: 318\n",
      "Done with the batch: 319\n",
      "Done with the batch: 320\n",
      "Done with the batch: 321\n",
      "Done with the batch: 322\n",
      "Done with the batch: 323\n",
      "Done with the batch: 324\n",
      "Done with the batch: 325\n",
      "Done with the batch: 326\n",
      "Done with the batch: 327\n",
      "Done with the batch: 328\n",
      "Done with the batch: 329\n",
      "Done with the batch: 330\n",
      "Done with the batch: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the batch: 332\n",
      "Done with the batch: 333\n",
      "Done with the batch: 334\n",
      "Done with the batch: 335\n",
      "Done with the batch: 336\n",
      "Done with the batch: 337\n",
      "Done with the batch: 338\n",
      "Done with the batch: 339\n",
      "Done with the batch: 340\n",
      "Done with the batch: 341\n",
      "Done with the batch: 342\n",
      "Done with the batch: 343\n",
      "Done with the batch: 344\n",
      "Done with the batch: 345\n",
      "Done with the batch: 346\n",
      "Done with the batch: 347\n",
      "Done with the batch: 348\n",
      "Done with the batch: 349\n",
      "Done with the batch: 350\n",
      "Done with the batch: 351\n",
      "Done with the batch: 352\n",
      "Done with the batch: 353\n",
      "Done with the batch: 354\n",
      "Done with the batch: 355\n",
      "Done with the batch: 356\n",
      "Done with the batch: 357\n",
      "Done with the batch: 358\n",
      "Done with the batch: 359\n",
      "Done with the batch: 360\n",
      "Done with the batch: 361\n",
      "Done with the batch: 362\n",
      "Done with the batch: 363\n",
      "Done with the batch: 364\n",
      "Done with the batch: 365\n",
      "Done with the batch: 366\n",
      "Done with the batch: 367\n",
      "Done with the batch: 368\n",
      "Done with the batch: 369\n",
      "Done with the batch: 370\n",
      "Done with the batch: 371\n",
      "Done with the batch: 372\n",
      "Done with the batch: 373\n",
      "Done with the batch: 374\n",
      "Done with the batch: 375\n",
      "Done with the batch: 376\n",
      "Done with the batch: 377\n",
      "Done with the batch: 378\n",
      "Done with the batch: 379\n",
      "Done with the batch: 380\n",
      "Done with the batch: 381\n",
      "Done with the batch: 382\n",
      "Done with the batch: 383\n",
      "Done with the batch: 384\n",
      "Done with the batch: 385\n",
      "Done with the batch: 386\n",
      "Done with the batch: 387\n",
      "Done with the batch: 388\n",
      "Done with the batch: 389\n",
      "Done with the batch: 390\n",
      "Done with the batch: 391\n",
      "Done with the batch: 392\n",
      "Done with the batch: 393\n",
      "Done with the batch: 394\n",
      "Done with the batch: 395\n",
      "Done with the batch: 396\n",
      "Done with the batch: 397\n",
      "Done with the batch: 398\n",
      "Done with the batch: 399\n",
      "Done with the batch: 400\n",
      "Done with the batch: 401\n",
      "Done with the batch: 402\n",
      "Done with the batch: 403\n",
      "Done with the batch: 404\n",
      "(1618, 25088) (1618,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"24677fbf-0a64-4bc7-8557-4dceac65dee6\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"24677fbf-0a64-4bc7-8557-4dceac65dee6\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "X_Test_FeatureMap=np.empty((0,25088))\n",
    "Y_Test_FeatureMap=np.empty((0,batch_size))\n",
    "print(X_Test_FeatureMap.shape)\n",
    "for i,data in enumerate(testloader):\n",
    "    print(f'Done with the batch: {i}')\n",
    "    images,labels=data\n",
    "    featuremap=vgg.get_Representation_Net(images).detach().numpy();\n",
    "#     print(FCLayer,FCLayer.shape,labels.numpy())\n",
    "    X_Test_FeatureMap=np.append(X_Test_FeatureMap,featuremap,axis=0)\n",
    "    Y_Test_FeatureMap=np.append(Y_Test_FeatureMap,labels.numpy())\n",
    "print(X_Test_FeatureMap.shape,Y_Test_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60451ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(model,dataset,loss_function,k_folds=5,epochs=10):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "              dataset, \n",
    "              batch_size=batch_size, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "              dataset,\n",
    "              batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        network = model\n",
    "        reset_weights(network)\n",
    "        optimizer = optim.Adam(network.parameters())\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, epochs):\n",
    "\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Perform forward pass\n",
    "                outputs = network(inputs)\n",
    "                targets = targets.unsqueeze(-1)\n",
    "                targets = targets.type_as(outputs)\n",
    "                # Compute loss\n",
    "                loss = loss_function(outputs, targets)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                if i % 500 == 499:\n",
    "                    print('Loss after mini-batch %5d: %.3f' %\n",
    "                      (i + 1, current_loss / 500))\n",
    "                    current_loss = 0.0\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving the trained model.')\n",
    "        save_path = f'./CNN3-fold-{fold}.pth'\n",
    "        torch.save(network, save_path)\n",
    "\n",
    "        # Evaluation for this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "                inputs,targets=inputs.to(device),targets.to(device)\n",
    "                # Generate outputs\n",
    "                outputs = network(inputs)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs=m(outputs)\n",
    "                pred=outputs>=0.5\n",
    "                pred=pred.flatten()\n",
    "                # Set total and correct\n",
    "                total += targets.size(0)\n",
    "                correct += (pred == targets).sum().item()\n",
    "\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab653581",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "145f2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,roc_auc_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d733ab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 1/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.501 total time=  13.9s\n",
      "[CV 2/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 2/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.502 total time=  13.6s\n",
      "[CV 3/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 3/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.502 total time=  12.9s\n",
      "[CV 4/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 4/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.502 total time=  12.8s\n",
      "[CV 5/5; 1/25] START C=0.001, gamma=0.001, kernel=rbf...........................\n",
      "[CV 5/5; 1/25] END C=0.001, gamma=0.001, kernel=rbf;, score=0.502 total time=  12.9s\n",
      "[CV 1/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 1/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.501 total time=  14.7s\n",
      "[CV 2/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 2/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.1s\n",
      "[CV 3/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 3/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.2s\n",
      "[CV 4/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 4/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=  15.4s\n",
      "[CV 5/5; 2/25] START C=0.001, gamma=0.01, kernel=rbf............................\n",
      "[CV 5/5; 2/25] END C=0.001, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.1s\n",
      "[CV 1/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 1/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.501 total time=  14.2s\n",
      "[CV 2/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 2/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 3/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 3/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.2s\n",
      "[CV 4/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 4/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 5/5; 3/25] START C=0.001, gamma=0.1, kernel=rbf.............................\n",
      "[CV 5/5; 3/25] END C=0.001, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.6s\n",
      "[CV 1/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 1/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.501 total time=  14.4s\n",
      "[CV 2/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 2/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=  15.7s\n",
      "[CV 3/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 3/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=  15.3s\n",
      "[CV 4/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 4/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=  15.2s\n",
      "[CV 5/5; 4/25] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 5/5; 4/25] END C=0.001, gamma=1, kernel=rbf;, score=0.502 total time=  14.2s\n",
      "[CV 1/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 1/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.501 total time=  14.3s\n",
      "[CV 2/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 2/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 3/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 3/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=  14.8s\n",
      "[CV 4/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 4/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=  15.0s\n",
      "[CV 5/5; 5/25] START C=0.001, gamma=10, kernel=rbf..............................\n",
      "[CV 5/5; 5/25] END C=0.001, gamma=10, kernel=rbf;, score=0.502 total time=  14.9s\n",
      "[CV 1/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 1/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.501 total time=  13.1s\n",
      "[CV 2/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 2/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time=  12.9s\n",
      "[CV 3/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 3/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time=  13.2s\n",
      "[CV 4/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 4/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time=  13.3s\n",
      "[CV 5/5; 6/25] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 5/5; 6/25] END C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time=  13.0s\n",
      "[CV 1/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 1/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.501 total time=  14.3s\n",
      "[CV 2/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 2/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 3/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 3/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.1s\n",
      "[CV 4/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 4/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 5/5; 7/25] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 5/5; 7/25] END C=0.1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 1/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 1/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.501 total time=  14.7s\n",
      "[CV 2/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 2/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.9s\n",
      "[CV 3/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 3/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 4/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 4/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 5/5; 8/25] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 5/5; 8/25] END C=0.1, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.7s\n",
      "[CV 1/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 1/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.501 total time=  14.7s\n",
      "[CV 2/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 2/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=  15.1s\n",
      "[CV 3/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 3/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 4/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 4/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=  14.6s\n",
      "[CV 5/5; 9/25] START C=0.1, gamma=1, kernel=rbf.................................\n",
      "[CV 5/5; 9/25] END ..C=0.1, gamma=1, kernel=rbf;, score=0.502 total time=  14.6s\n",
      "[CV 1/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 1/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.501 total time=  14.6s\n",
      "[CV 2/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 2/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=  14.8s\n",
      "[CV 3/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 3/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=  14.8s\n",
      "[CV 4/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 4/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=  14.6s\n",
      "[CV 5/5; 10/25] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 5/5; 10/25] END C=0.1, gamma=10, kernel=rbf;, score=0.502 total time=  14.9s\n",
      "[CV 1/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.631 total time=  13.2s\n",
      "[CV 2/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 2/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.648 total time=  13.0s\n",
      "[CV 3/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 3/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.665 total time=  13.0s\n",
      "[CV 4/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 4/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.655 total time=  13.0s\n",
      "[CV 5/5; 11/25] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 5/5; 11/25] END C=1, gamma=0.001, kernel=rbf;, score=0.662 total time=  12.9s\n",
      "[CV 1/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 1/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.501 total time=  14.1s\n",
      "[CV 2/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 2/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.2s\n",
      "[CV 3/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 3/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 4/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 4/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 5/5; 12/25] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 5/5; 12/25] END C=1, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.2s\n",
      "[CV 1/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 1/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.501 total time=  14.3s\n",
      "[CV 2/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 2/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 3/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 3/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 4/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 4/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 5/5; 13/25] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 5/5; 13/25] END .C=1, gamma=0.1, kernel=rbf;, score=0.502 total time=  15.2s\n",
      "[CV 1/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 1/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.501 total time=  14.3s\n",
      "[CV 2/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 2/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 3/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 3/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.502 total time=  14.2s\n",
      "[CV 4/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 4/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 5/5; 14/25] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 5/5; 14/25] END ...C=1, gamma=1, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 1/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 1/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.501 total time=  14.4s\n",
      "[CV 2/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 2/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=  14.7s\n",
      "[CV 3/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 3/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=  14.7s\n",
      "[CV 4/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 4/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=  14.9s\n",
      "[CV 5/5; 15/25] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 5/5; 15/25] END ..C=1, gamma=10, kernel=rbf;, score=0.502 total time=  15.0s\n",
      "[CV 1/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 1/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.648 total time=  13.0s\n",
      "[CV 2/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 2/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.664 total time=  13.1s\n",
      "[CV 3/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 3/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.675 total time=  13.1s\n",
      "[CV 4/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 4/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.671 total time=  13.1s\n",
      "[CV 5/5; 16/25] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 5/5; 16/25] END C=10, gamma=0.001, kernel=rbf;, score=0.679 total time=  12.9s\n",
      "[CV 1/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 1/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.501 total time=  14.2s\n",
      "[CV 2/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 2/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 3/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 3/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.2s\n",
      "[CV 4/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 4/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 5/5; 17/25] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 5/5; 17/25] END C=10, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.1s\n",
      "[CV 1/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 1/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.501 total time=  14.4s\n",
      "[CV 2/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 2/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 3/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 3/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 4/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 4/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 5/5; 18/25] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 5/5; 18/25] END C=10, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 1/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 1/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.501 total time=  14.5s\n",
      "[CV 2/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 2/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.502 total time=  14.9s\n",
      "[CV 3/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 3/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.502 total time=  14.6s\n",
      "[CV 4/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 4/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 5/5; 19/25] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 5/5; 19/25] END ..C=10, gamma=1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 1/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 1/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.501 total time=  15.3s\n",
      "[CV 2/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 2/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=  14.9s\n",
      "[CV 3/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 3/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=  14.8s\n",
      "[CV 4/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 4/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=  14.8s\n",
      "[CV 5/5; 20/25] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 5/5; 20/25] END .C=10, gamma=10, kernel=rbf;, score=0.502 total time=  14.8s\n",
      "[CV 1/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 1/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.648 total time=  12.9s\n",
      "[CV 2/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.664 total time=  12.7s\n",
      "[CV 3/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 3/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.675 total time=  12.8s\n",
      "[CV 4/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 4/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.671 total time=  13.0s\n",
      "[CV 5/5; 21/25] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 5/5; 21/25] END C=100, gamma=0.001, kernel=rbf;, score=0.679 total time=  13.2s\n",
      "[CV 1/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 1/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.501 total time=  14.4s\n",
      "[CV 2/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 2/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 3/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 3/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 4/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 4/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 5/5; 22/25] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 5/5; 22/25] END C=100, gamma=0.01, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 1/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 1/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.501 total time=  14.5s\n",
      "[CV 2/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 2/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 3/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 3/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 4/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 4/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 5/5; 23/25] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 5/5; 23/25] END C=100, gamma=0.1, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 1/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 1/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.501 total time=  14.4s\n",
      "[CV 2/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 2/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.502 total time=  14.6s\n",
      "[CV 3/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 3/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 4/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 4/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.502 total time=  14.4s\n",
      "[CV 5/5; 24/25] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 5/5; 24/25] END .C=100, gamma=1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 1/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 1/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.501 total time=  13.4s\n",
      "[CV 2/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 2/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=  11.1s\n",
      "[CV 3/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 3/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=  11.2s\n",
      "[CV 4/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 4/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=  11.1s\n",
      "[CV 5/5; 25/25] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 5/5; 25/25] END C=100, gamma=10, kernel=rbf;, score=0.502 total time=  11.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.001, 0.1, 1, 10, 100],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'kernel': ['rbf']},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-2,0.1,1,10],\n",
    "                     'C': [0.001,0.1,1, 10, 100],\n",
    "}\n",
    "# tuned_parameters = {'kernel': ['rbf'], 'gamma': [1e-3],\n",
    "#                      'C': [0.001],\n",
    "#                    }\n",
    "clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring= 'accuracy',verbose=10\n",
    "    )\n",
    "clf.fit(X_Train, Y_Train.ravel())\n",
    "# print(clf.best_score_)\n",
    "# print(clf.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e7c6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_svm(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "#         clf=SVC(C=10,kernel='rbf',gamma=0.0001)\n",
    "        clf=SVC(C=10,kernel='rbf',gamma=10)\n",
    "        clf.fit(X_train,y_train.ravel())\n",
    "        y_pred = clf.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del clf\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dcb5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81835392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 97.2952086553323\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 97.75888717156104\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 95.90417310664606\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 97.06336939721793\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 96.90880989180835\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 97.2952086553323 %\n",
      "Fold 1: 97.75888717156104 %\n",
      "Fold 2: 95.90417310664606 %\n",
      "Fold 3: 97.06336939721793 %\n",
      "Fold 4: 96.90880989180835 %\n",
      "Average: 96.98608964451313 %\n",
      "Accuracy:  0.9610630407911002\n",
      "F1-Score:  0.9617950272892662\n",
      "Precision:  0.9542719614921781\n",
      "Recall:  0.969437652811736\n",
      "AUC:  0.9609688264058679\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_svm(X_Train,Y_Train.ravel())\n",
    "clf=SVC(C=10,kernel='rbf',gamma=0.0001)\n",
    "clf.fit(X_Train,Y_Train.ravel())\n",
    "y_pred = clf.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f71827",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e853587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f102a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_dtree(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        decision_tree = DecisionTreeClassifier(random_state=102)\n",
    "        decision_tree = decision_tree.fit(X_train, y_train.ravel())\n",
    "        y_pred = decision_tree.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del decision_tree\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f29e6912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6470,) (1618,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_Train.shape,Y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c07b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 94.97681607418856\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 95.05409582689336\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 94.66769706336939\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 95.98145285935085\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 94.74497681607419\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.97681607418856 %\n",
      "Fold 1: 95.05409582689336 %\n",
      "Fold 2: 94.66769706336939 %\n",
      "Fold 3: 95.98145285935085 %\n",
      "Fold 4: 94.74497681607419 %\n",
      "Average: 95.08500772797527 %\n",
      "Accuracy:  0.9326328800988876\n",
      "F1-Score:  0.9342977697408077\n",
      "Precision:  0.9215219976218787\n",
      "Recall:  0.9474327628361858\n",
      "AUC:  0.9324663814180929\n"
     ]
    }
   ],
   "source": [
    "dtree=k_fold_cv_dtree(X_Train,Y_Train.ravel())\n",
    "dtree = DecisionTreeClassifier(random_state=102)\n",
    "dtree = dtree.fit(X_Train, Y_Train.ravel())\n",
    "y_pred=dtree.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81964ca8",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efb2b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a204fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_rforest(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        random_forest = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=102)\n",
    "        random_forest = random_forest.fit(X_train, y_train.ravel())\n",
    "        y_pred = random_forest.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del random_forest\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9385d604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 96.67697063369397\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 96.83153013910355\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 97.3724884080371\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 97.14064914992272\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 97.83616692426584\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 96.67697063369397 %\n",
      "Fold 1: 96.83153013910355 %\n",
      "Fold 2: 97.3724884080371 %\n",
      "Fold 3: 97.14064914992272 %\n",
      "Fold 4: 97.83616692426584 %\n",
      "Average: 97.17156105100464 %\n",
      "Accuracy:  0.9598269468479604\n",
      "F1-Score:  0.960582171012735\n",
      "Precision:  0.9530685920577617\n",
      "Recall:  0.9682151589242054\n",
      "AUC:  0.9597325794621028\n"
     ]
    }
   ],
   "source": [
    "random_forest=k_fold_cv_rforest(X_Train,Y_Train.ravel())\n",
    "random_forest = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=102)\n",
    "random_forest = random_forest.fit(X_Train, Y_Train.ravel())\n",
    "y_pred=random_forest.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "176ed13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with criterion gini and 1 trees/estimators:  0.9320148331273177\n",
      "Accuracy with criterion entropy and 1 trees/estimators:  0.9276885043263288\n",
      "Accuracy with criterion gini and 10 trees/estimators:  0.9567367119901112\n",
      "Accuracy with criterion entropy and 10 trees/estimators:  0.9585908529048207\n",
      "Accuracy with criterion gini and 100 trees/estimators:  0.9610630407911002\n",
      "Accuracy with criterion entropy and 100 trees/estimators:  0.9610630407911002\n",
      "Accuracy with criterion gini and 200 trees/estimators:  0.9610630407911002\n",
      "Accuracy with criterion entropy and 200 trees/estimators:  0.9604449938195303\n",
      "Accuracy with criterion gini and 500 trees/estimators:  0.9604449938195303\n",
      "Accuracy with criterion entropy and 500 trees/estimators:  0.9616810877626699\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"7f775684-e7c9-4772-baf3-af327256ec4d\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"7f775684-e7c9-4772-baf3-af327256ec4d\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "# With subsampling the features and bootstrapping in random forest we get\n",
    "for i in [1,10,100,200,500]:\n",
    "    for crit in [\"gini\",\"entropy\"]:\n",
    "        random_forest = RandomForestClassifier(n_estimators=i,random_state=102,criterion=crit)\n",
    "        random_forest=random_forest.fit(X_Train,Y_Train.ravel())\n",
    "        y_pred=random_forest.predict(X_Test)\n",
    "        print(f\"Accuracy with criterion {crit} and {i} trees/estimators: \",accuracy_score(Y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "18c7c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with criterion gini and 1 trees/estimators:  0.9487021013597033\n",
      "Accuracy with criterion entropy and 1 trees/estimators:  0.9499381953028431\n",
      "Accuracy with criterion gini and 10 trees/estimators:  0.953646477132262\n",
      "Accuracy with criterion entropy and 10 trees/estimators:  0.9511742892459827\n",
      "Accuracy with criterion gini and 100 trees/estimators:  0.9555006180469716\n",
      "Accuracy with criterion entropy and 100 trees/estimators:  0.9480840543881335\n",
      "Accuracy with criterion gini and 200 trees/estimators:  0.9542645241038319\n",
      "Accuracy with criterion entropy and 200 trees/estimators:  0.946229913473424\n",
      "Accuracy with criterion gini and 500 trees/estimators:  0.9548825710754018\n",
      "Accuracy with criterion entropy and 500 trees/estimators:  0.946229913473424\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"82838dec-75f5-40ea-b151-c059aa19fc02\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"82838dec-75f5-40ea-b151-c059aa19fc02\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Completed\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Completed\"\n",
    "# With taking whole features and no bootstrapping in random forest we get (i.e) all classifiers are a single decision tree\n",
    "for i in [1,10,100,200,500]:\n",
    "    for crit in [\"gini\",\"entropy\"]:\n",
    "        random_forest = RandomForestClassifier(n_estimators=i,random_state=102,criterion=crit,bootstrap=False,max_features=None)\n",
    "        random_forest=random_forest.fit(X_Train,Y_Train.ravel())\n",
    "        y_pred=random_forest.predict(X_Test)\n",
    "        print(f\"Accuracy with criterion {crit} and {i} trees/estimators: \",accuracy_score(Y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45e2a5",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce4397c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a24fe74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_xgb(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        eval_set = [(X_train, y_train.ravel()), (X_test, y_test)]\n",
    "        xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, seed=102,use_label_encoder=False)\n",
    "        xg_cl.fit(X_train,y_train.ravel())\n",
    "        y_pred = xg_cl.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del xg_cl\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return xg_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e21a1d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "[23:53:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 97.3724884080371\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "[23:54:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 97.99072642967542\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "[23:54:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 97.60432766615146\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "[23:54:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 97.3724884080371\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "[23:54:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 96.83153013910355\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 97.3724884080371 %\n",
      "Fold 1: 97.99072642967542 %\n",
      "Fold 2: 97.60432766615146 %\n",
      "Fold 3: 97.3724884080371 %\n",
      "Fold 4: 96.83153013910355 %\n",
      "Average: 97.43431221020093 %\n",
      "[23:54:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy:  0.9616810877626699\n",
      "F1-Score:  0.9621951219512195\n",
      "Precision:  0.9598540145985401\n",
      "Recall:  0.9645476772616137\n",
      "AUC:  0.9616488386308069\n"
     ]
    }
   ],
   "source": [
    "xg=k_fold_cv_xgb(X_Train,Y_Train.ravel())\n",
    "xg = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, seed=102,use_label_encoder=False)\n",
    "xg.fit(X_Train,Y_Train.ravel())\n",
    "y_pred=xg.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444caa9",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af482111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3ed4b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_mlp(X,Y,k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    # Initialize optimizer\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)): \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = Y[train_ids], Y[test_ids]\n",
    "        clf = MLPClassifier(random_state=102, max_iter=3000, verbose=True).fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        results[fold] = 100.0 * accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\",results[fold])\n",
    "        if fold != k_folds-1:\n",
    "            # The last model used for testing accuracy\n",
    "            del clf\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaea3fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Iteration 1, loss = 2.26143490\n",
      "Iteration 2, loss = 0.58412682\n",
      "Iteration 3, loss = 0.38872076\n",
      "Iteration 4, loss = 0.27695517\n",
      "Iteration 5, loss = 0.22505846\n",
      "Iteration 6, loss = 0.28284174\n",
      "Iteration 7, loss = 0.24412891\n",
      "Iteration 8, loss = 0.17698757\n",
      "Iteration 9, loss = 0.27256135\n",
      "Iteration 10, loss = 0.27535134\n",
      "Iteration 11, loss = 0.25920197\n",
      "Iteration 12, loss = 0.19432195\n",
      "Iteration 13, loss = 0.14354798\n",
      "Iteration 14, loss = 0.13674576\n",
      "Iteration 15, loss = 0.10997184\n",
      "Iteration 16, loss = 0.15044805\n",
      "Iteration 17, loss = 0.15586096\n",
      "Iteration 18, loss = 0.13938034\n",
      "Iteration 19, loss = 0.17435096\n",
      "Iteration 20, loss = 0.13080709\n",
      "Iteration 21, loss = 0.12261794\n",
      "Iteration 22, loss = 0.18835403\n",
      "Iteration 23, loss = 0.09239147\n",
      "Iteration 24, loss = 0.10236244\n",
      "Iteration 25, loss = 0.09492834\n",
      "Iteration 26, loss = 0.09228966\n",
      "Iteration 27, loss = 0.11060052\n",
      "Iteration 28, loss = 0.10841134\n",
      "Iteration 29, loss = 0.08753741\n",
      "Iteration 30, loss = 0.12984777\n",
      "Iteration 31, loss = 0.11630421\n",
      "Iteration 32, loss = 0.13592161\n",
      "Iteration 33, loss = 0.18888818\n",
      "Iteration 34, loss = 0.17292035\n",
      "Iteration 35, loss = 0.09497094\n",
      "Iteration 36, loss = 0.09033137\n",
      "Iteration 37, loss = 0.10559104\n",
      "Iteration 38, loss = 0.12138506\n",
      "Iteration 39, loss = 0.08513550\n",
      "Iteration 40, loss = 0.06549885\n",
      "Iteration 41, loss = 0.10778933\n",
      "Iteration 42, loss = 0.06691153\n",
      "Iteration 43, loss = 0.22575415\n",
      "Iteration 44, loss = 0.17296004\n",
      "Iteration 45, loss = 0.13024980\n",
      "Iteration 46, loss = 0.09691906\n",
      "Iteration 47, loss = 0.06495028\n",
      "Iteration 48, loss = 0.06736338\n",
      "Iteration 49, loss = 0.14165131\n",
      "Iteration 50, loss = 0.07870012\n",
      "Iteration 51, loss = 0.06890956\n",
      "Iteration 52, loss = 0.10129235\n",
      "Iteration 53, loss = 0.05759093\n",
      "Iteration 54, loss = 0.06724967\n",
      "Iteration 55, loss = 0.07119508\n",
      "Iteration 56, loss = 0.17282631\n",
      "Iteration 57, loss = 0.08531304\n",
      "Iteration 58, loss = 0.06759701\n",
      "Iteration 59, loss = 0.19568999\n",
      "Iteration 60, loss = 0.08445580\n",
      "Iteration 61, loss = 0.06387677\n",
      "Iteration 62, loss = 0.08350010\n",
      "Iteration 63, loss = 0.06795065\n",
      "Iteration 64, loss = 0.08609195\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 97.52704791344668\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Iteration 1, loss = 2.15656144\n",
      "Iteration 2, loss = 0.58669346\n",
      "Iteration 3, loss = 0.40227575\n",
      "Iteration 4, loss = 0.29828252\n",
      "Iteration 5, loss = 0.22114100\n",
      "Iteration 6, loss = 0.18416693\n",
      "Iteration 7, loss = 0.17292731\n",
      "Iteration 8, loss = 0.15217832\n",
      "Iteration 9, loss = 0.14166031\n",
      "Iteration 10, loss = 0.12841017\n",
      "Iteration 11, loss = 0.12590722\n",
      "Iteration 12, loss = 0.13828136\n",
      "Iteration 13, loss = 0.13593938\n",
      "Iteration 14, loss = 0.10432158\n",
      "Iteration 15, loss = 0.22558176\n",
      "Iteration 16, loss = 0.34016722\n",
      "Iteration 17, loss = 0.16636355\n",
      "Iteration 18, loss = 0.15949611\n",
      "Iteration 19, loss = 0.14358502\n",
      "Iteration 20, loss = 0.10168910\n",
      "Iteration 21, loss = 0.08900990\n",
      "Iteration 22, loss = 0.08332376\n",
      "Iteration 23, loss = 0.11824718\n",
      "Iteration 24, loss = 0.12635504\n",
      "Iteration 25, loss = 0.08473913\n",
      "Iteration 26, loss = 0.08250466\n",
      "Iteration 27, loss = 0.08632276\n",
      "Iteration 28, loss = 0.06979951\n",
      "Iteration 29, loss = 0.06295793\n",
      "Iteration 30, loss = 0.06842332\n",
      "Iteration 31, loss = 0.07262388\n",
      "Iteration 32, loss = 0.06703091\n",
      "Iteration 33, loss = 0.06348874\n",
      "Iteration 34, loss = 0.07805222\n",
      "Iteration 35, loss = 0.09022019\n",
      "Iteration 36, loss = 0.06544561\n",
      "Iteration 37, loss = 0.06751457\n",
      "Iteration 38, loss = 0.13471013\n",
      "Iteration 39, loss = 0.17308538\n",
      "Iteration 40, loss = 0.35437651\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 97.06336939721793\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Iteration 1, loss = 2.08227790\n",
      "Iteration 2, loss = 0.52995253\n",
      "Iteration 3, loss = 0.50713453\n",
      "Iteration 4, loss = 0.32611974\n",
      "Iteration 5, loss = 0.23682618\n",
      "Iteration 6, loss = 0.20261485\n",
      "Iteration 7, loss = 0.20797145\n",
      "Iteration 8, loss = 0.16426636\n",
      "Iteration 9, loss = 0.13902189\n",
      "Iteration 10, loss = 0.14591413\n",
      "Iteration 11, loss = 0.15899021\n",
      "Iteration 12, loss = 0.14578811\n",
      "Iteration 13, loss = 0.16636960\n",
      "Iteration 14, loss = 0.13599685\n",
      "Iteration 15, loss = 0.10690557\n",
      "Iteration 16, loss = 0.09548637\n",
      "Iteration 17, loss = 0.13348205\n",
      "Iteration 18, loss = 0.13336043\n",
      "Iteration 19, loss = 0.20137542\n",
      "Iteration 20, loss = 0.16457196\n",
      "Iteration 21, loss = 0.09250547\n",
      "Iteration 22, loss = 0.09356321\n",
      "Iteration 23, loss = 0.08998455\n",
      "Iteration 24, loss = 0.10659058\n",
      "Iteration 25, loss = 0.13980470\n",
      "Iteration 26, loss = 0.14158291\n",
      "Iteration 27, loss = 0.13162448\n",
      "Iteration 28, loss = 0.12233483\n",
      "Iteration 29, loss = 0.10102819\n",
      "Iteration 30, loss = 0.09452393\n",
      "Iteration 31, loss = 0.11271960\n",
      "Iteration 32, loss = 0.12927197\n",
      "Iteration 33, loss = 0.08755429\n",
      "Iteration 34, loss = 0.07776223\n",
      "Iteration 35, loss = 0.07582773\n",
      "Iteration 36, loss = 0.07705585\n",
      "Iteration 37, loss = 0.12099328\n",
      "Iteration 38, loss = 0.12451620\n",
      "Iteration 39, loss = 0.06960251\n",
      "Iteration 40, loss = 0.13123459\n",
      "Iteration 41, loss = 0.08600405\n",
      "Iteration 42, loss = 0.06024225\n",
      "Iteration 43, loss = 0.05846785\n",
      "Iteration 44, loss = 0.08439597\n",
      "Iteration 45, loss = 0.05573338\n",
      "Iteration 46, loss = 0.04719447\n",
      "Iteration 47, loss = 0.10707673\n",
      "Iteration 48, loss = 0.11443767\n",
      "Iteration 49, loss = 0.28904201\n",
      "Iteration 50, loss = 0.17952546\n",
      "Iteration 51, loss = 0.17482319\n",
      "Iteration 52, loss = 0.15548757\n",
      "Iteration 53, loss = 0.13782480\n",
      "Iteration 54, loss = 0.07288005\n",
      "Iteration 55, loss = 0.05369920\n",
      "Iteration 56, loss = 0.11806362\n",
      "Iteration 57, loss = 0.05718631\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 95.5950540958269\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Iteration 1, loss = 2.31455262\n",
      "Iteration 2, loss = 0.62647779\n",
      "Iteration 3, loss = 0.41733716\n",
      "Iteration 4, loss = 0.29669465\n",
      "Iteration 5, loss = 0.25351152\n",
      "Iteration 6, loss = 0.25884768\n",
      "Iteration 7, loss = 0.22112624\n",
      "Iteration 8, loss = 0.16455854\n",
      "Iteration 9, loss = 0.22795706\n",
      "Iteration 10, loss = 0.16376263\n",
      "Iteration 11, loss = 0.13426325\n",
      "Iteration 12, loss = 0.11658373\n",
      "Iteration 13, loss = 0.12155110\n",
      "Iteration 14, loss = 0.13212424\n",
      "Iteration 15, loss = 0.13121664\n",
      "Iteration 16, loss = 0.12228015\n",
      "Iteration 17, loss = 0.10642031\n",
      "Iteration 18, loss = 0.09193253\n",
      "Iteration 19, loss = 0.08767823\n",
      "Iteration 20, loss = 0.10010624\n",
      "Iteration 21, loss = 0.09433874\n",
      "Iteration 22, loss = 0.09606017\n",
      "Iteration 23, loss = 0.11962971\n",
      "Iteration 24, loss = 0.16115770\n",
      "Iteration 25, loss = 0.12607816\n",
      "Iteration 26, loss = 0.09559837\n",
      "Iteration 27, loss = 0.12983358\n",
      "Iteration 28, loss = 0.10113382\n",
      "Iteration 29, loss = 0.06888015\n",
      "Iteration 30, loss = 0.08716722\n",
      "Iteration 31, loss = 0.07280159\n",
      "Iteration 32, loss = 0.08546159\n",
      "Iteration 33, loss = 0.09315552\n",
      "Iteration 34, loss = 0.12665842\n",
      "Iteration 35, loss = 0.09713841\n",
      "Iteration 36, loss = 0.18354425\n",
      "Iteration 37, loss = 0.16100017\n",
      "Iteration 38, loss = 0.10906705\n",
      "Iteration 39, loss = 0.09827997\n",
      "Iteration 40, loss = 0.08477502\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 97.44976816074188\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Iteration 1, loss = 2.11617406\n",
      "Iteration 2, loss = 0.51783478\n",
      "Iteration 3, loss = 0.39421392\n",
      "Iteration 4, loss = 0.27594641\n",
      "Iteration 5, loss = 0.25630493\n",
      "Iteration 6, loss = 0.20708828\n",
      "Iteration 7, loss = 0.19370780\n",
      "Iteration 8, loss = 0.21865014\n",
      "Iteration 9, loss = 0.13754664\n",
      "Iteration 10, loss = 0.14085901\n",
      "Iteration 11, loss = 0.13423289\n",
      "Iteration 12, loss = 0.25063947\n",
      "Iteration 13, loss = 0.19333333\n",
      "Iteration 14, loss = 0.12637450\n",
      "Iteration 15, loss = 0.12342087\n",
      "Iteration 16, loss = 0.15718463\n",
      "Iteration 17, loss = 0.12101343\n",
      "Iteration 18, loss = 0.13813697\n",
      "Iteration 19, loss = 0.09167002\n",
      "Iteration 20, loss = 0.16145176\n",
      "Iteration 21, loss = 0.11637915\n",
      "Iteration 22, loss = 0.08347826\n",
      "Iteration 23, loss = 0.07816739\n",
      "Iteration 24, loss = 0.07533749\n",
      "Iteration 25, loss = 0.08346364\n",
      "Iteration 26, loss = 0.12827662\n",
      "Iteration 27, loss = 0.15972220\n",
      "Iteration 28, loss = 0.08044353\n",
      "Iteration 29, loss = 0.08922009\n",
      "Iteration 30, loss = 0.12185732\n",
      "Iteration 31, loss = 0.26638146\n",
      "Iteration 32, loss = 0.17738803\n",
      "Iteration 33, loss = 0.19850760\n",
      "Iteration 34, loss = 0.12952239\n",
      "Iteration 35, loss = 0.18777957\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.5950540958269\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 97.52704791344668 %\n",
      "Fold 1: 97.06336939721793 %\n",
      "Fold 2: 95.5950540958269 %\n",
      "Fold 3: 97.44976816074188 %\n",
      "Fold 4: 95.5950540958269 %\n",
      "Average: 96.64605873261205 %\n",
      "Iteration 1, loss = 2.03614554\n",
      "Iteration 2, loss = 0.47496226\n",
      "Iteration 3, loss = 0.30060235\n",
      "Iteration 4, loss = 0.27346142\n",
      "Iteration 5, loss = 0.24578009\n",
      "Iteration 6, loss = 0.17588551\n",
      "Iteration 7, loss = 0.25892180\n",
      "Iteration 8, loss = 0.16780370\n",
      "Iteration 9, loss = 0.15719360\n",
      "Iteration 10, loss = 0.17284413\n",
      "Iteration 11, loss = 0.14356606\n",
      "Iteration 12, loss = 0.24584866\n",
      "Iteration 13, loss = 0.13810284\n",
      "Iteration 14, loss = 0.10415210\n",
      "Iteration 15, loss = 0.15115524\n",
      "Iteration 16, loss = 0.24345093\n",
      "Iteration 17, loss = 0.10563536\n",
      "Iteration 18, loss = 0.12416872\n",
      "Iteration 19, loss = 0.10712560\n",
      "Iteration 20, loss = 0.12611728\n",
      "Iteration 21, loss = 0.12096051\n",
      "Iteration 22, loss = 0.12700508\n",
      "Iteration 23, loss = 0.20871900\n",
      "Iteration 24, loss = 0.09697589\n",
      "Iteration 25, loss = 0.10432027\n",
      "Iteration 26, loss = 0.19106709\n",
      "Iteration 27, loss = 0.09317402\n",
      "Iteration 28, loss = 0.10881285\n",
      "Iteration 29, loss = 0.07469919\n",
      "Iteration 30, loss = 0.09042792\n",
      "Iteration 31, loss = 0.06753403\n",
      "Iteration 32, loss = 0.07072741\n",
      "Iteration 33, loss = 0.15910572\n",
      "Iteration 34, loss = 0.22668961\n",
      "Iteration 35, loss = 0.11154611\n",
      "Iteration 36, loss = 0.17542969\n",
      "Iteration 37, loss = 0.10586608\n",
      "Iteration 38, loss = 0.08790391\n",
      "Iteration 39, loss = 0.09328504\n",
      "Iteration 40, loss = 0.07965880\n",
      "Iteration 41, loss = 0.06538463\n",
      "Iteration 42, loss = 0.11461437\n",
      "Iteration 43, loss = 0.13793603\n",
      "Iteration 44, loss = 0.15443326\n",
      "Iteration 45, loss = 0.25066188\n",
      "Iteration 46, loss = 0.09437056\n",
      "Iteration 47, loss = 0.08066705\n",
      "Iteration 48, loss = 0.08053461\n",
      "Iteration 49, loss = 0.09110618\n",
      "Iteration 50, loss = 0.06220920\n",
      "Iteration 51, loss = 0.16890854\n",
      "Iteration 52, loss = 0.16961885\n",
      "Iteration 53, loss = 0.08913518\n",
      "Iteration 54, loss = 0.07900488\n",
      "Iteration 55, loss = 0.07072542\n",
      "Iteration 56, loss = 0.06804736\n",
      "Iteration 57, loss = 0.06143201\n",
      "Iteration 58, loss = 0.12272426\n",
      "Iteration 59, loss = 0.07018611\n",
      "Iteration 60, loss = 0.06184108\n",
      "Iteration 61, loss = 0.07305003\n",
      "Iteration 62, loss = 0.08301805\n",
      "Iteration 63, loss = 0.10748678\n",
      "Iteration 64, loss = 0.05334996\n",
      "Iteration 65, loss = 0.08057689\n",
      "Iteration 66, loss = 0.07384084\n",
      "Iteration 67, loss = 0.09514801\n",
      "Iteration 68, loss = 0.06667369\n",
      "Iteration 69, loss = 0.09568499\n",
      "Iteration 70, loss = 0.07946104\n",
      "Iteration 71, loss = 0.08048769\n",
      "Iteration 72, loss = 0.06131262\n",
      "Iteration 73, loss = 0.04947448\n",
      "Iteration 74, loss = 0.08233281\n",
      "Iteration 75, loss = 0.09405757\n",
      "Iteration 76, loss = 0.13794153\n",
      "Iteration 77, loss = 0.10714890\n",
      "Iteration 78, loss = 0.06619343\n",
      "Iteration 79, loss = 0.05167636\n",
      "Iteration 80, loss = 0.15206389\n",
      "Iteration 81, loss = 0.14445480\n",
      "Iteration 82, loss = 0.11113500\n",
      "Iteration 83, loss = 0.07276754\n",
      "Iteration 84, loss = 0.06192566\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.9542645241038319\n",
      "F1-Score:  0.9544334975369457\n",
      "Precision:  0.9615384615384616\n",
      "Recall:  0.9474327628361858\n",
      "AUC:  0.9543413814180929\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_mlp(X_Train,Y_Train.ravel())\n",
    "clf=MLPClassifier(random_state=102, max_iter=3000, verbose=True).fit(X_Train, Y_Train.ravel())\n",
    "y_pred=clf.predict(X_Test)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddddc1",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e4c59bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451694cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kpca = KernelPCA(kernel = 'rbf')\n",
    "kpca_transform = kpca.fit_transform(X_Train_FeatureMap)\n",
    "explained_variance = np.var(kpca_transform, axis=0)\n",
    "explained_variance_ratio = explained_variance / np.sum(explained_variance)\n",
    "plt.yticks([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.plot(np.cumsum(explained_variance_ratio))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb87a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6470, 6000)\n"
     ]
    }
   ],
   "source": [
    "kpca = KernelPCA(kernel = 'rbf',n_components=6000)\n",
    "X_Train_Transformed_FeatureMap = kpca.fit_transform(X_Train_FeatureMap)\n",
    "print(X_Train_Transformed_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbcd9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1618, 25088) (1618, 6000)\n"
     ]
    }
   ],
   "source": [
    "X_Test_Transformed_FeatureMap = kpca.transform(X_Test_FeatureMap)\n",
    "\n",
    "print(X_Test_FeatureMap.shape,X_Test_Transformed_FeatureMap.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5135d",
   "metadata": {},
   "source": [
    "## SVM (with PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce5069a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 95.36321483771252\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 94.5904173106646\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 94.82225656877898\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 96.05873261205564\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 94.74497681607419\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 95.36321483771252 %\n",
      "Fold 1: 94.5904173106646 %\n",
      "Fold 2: 94.82225656877898 %\n",
      "Fold 3: 96.05873261205564 %\n",
      "Fold 4: 94.74497681607419 %\n",
      "Average: 95.11591962905719 %\n",
      "Accuracy:  0.9456118665018541\n",
      "F1-Score:  0.9469240048250905\n",
      "Precision:  0.9345238095238095\n",
      "Recall:  0.9596577017114915\n",
      "AUC:  0.9454538508557457\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_svm(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "clf=SVC(C=10,kernel='rbf',gamma=10)\n",
    "clf.fit(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "y_pred=clf.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440ab53",
   "metadata": {},
   "source": [
    "## Decision Tree (with PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a57587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 80.52550231839258\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 78.516228748068\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 79.36630602782071\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 78.97990726429676\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 81.06646058732612\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 80.52550231839258 %\n",
      "Fold 1: 78.516228748068 %\n",
      "Fold 2: 79.36630602782071 %\n",
      "Fold 3: 78.97990726429676 %\n",
      "Fold 4: 81.06646058732612 %\n",
      "Average: 79.69088098918084 %\n",
      "Accuracy:  0.8220024721878862\n",
      "F1-Score:  0.8275449101796407\n",
      "Precision:  0.8110328638497653\n",
      "Recall:  0.8447432762836186\n",
      "AUC:  0.8217466381418093\n"
     ]
    }
   ],
   "source": [
    "dtree=k_fold_cv_dtree(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "dtree = DecisionTreeClassifier(random_state=102)\n",
    "dtree = dtree.fit(X_Train_Transformed_FeatureMap, Y_Train_FeatureMap.ravel())\n",
    "y_pred=dtree.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd9045",
   "metadata": {},
   "source": [
    "## Random Forest (with PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e9a8777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Accuracy: 80.98918083462134\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Accuracy: 78.5935085007728\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Accuracy: 76.97063369397218\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Accuracy: 79.05718701700154\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Accuracy: 74.42040185471407\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 80.98918083462134 %\n",
      "Fold 1: 78.5935085007728 %\n",
      "Fold 2: 76.97063369397218 %\n",
      "Fold 3: 79.05718701700154 %\n",
      "Fold 4: 74.42040185471407 %\n",
      "Average: 78.00618238021639 %\n",
      "Accuracy:  0.7991347342398022\n",
      "F1-Score:  0.7750865051903114\n",
      "Precision:  0.8931419457735247\n",
      "Recall:  0.684596577017115\n",
      "AUC:  0.8004232885085575\n"
     ]
    }
   ],
   "source": [
    "random_forest=k_fold_cv_rforest(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "random_forest = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=102)\n",
    "random_forest = random_forest.fit(X_Train_Transformed_FeatureMap, Y_Train_FeatureMap.ravel())\n",
    "y_pred=random_forest.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6dafe",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6649e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "[00:19:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 91.88562596599691\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "[00:21:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 92.8129829984544\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "[00:24:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 92.42658423493046\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "[00:27:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 92.73570324574962\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "[00:30:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 92.65842349304482\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 91.88562596599691 %\n",
      "Fold 1: 92.8129829984544 %\n",
      "Fold 2: 92.42658423493046 %\n",
      "Fold 3: 92.73570324574962 %\n",
      "Fold 4: 92.65842349304482 %\n",
      "Average: 92.50386398763524 %\n",
      "[00:33:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy:  0.9239802224969098\n",
      "F1-Score:  0.9245861434702636\n",
      "Precision:  0.9274292742927429\n",
      "Recall:  0.921760391198044\n",
      "AUC:  0.9240051955990221\n"
     ]
    }
   ],
   "source": [
    "xg=k_fold_cv_xgb(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "xg = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, seed=102,use_label_encoder=False)\n",
    "xg.fit(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "y_pred=xg.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538008e",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "767f57c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69083233\n",
      "Iteration 2, loss = 0.66542371\n",
      "Iteration 3, loss = 0.62130651\n",
      "Iteration 4, loss = 0.55766791\n",
      "Iteration 5, loss = 0.48433600\n",
      "Iteration 6, loss = 0.40783375\n",
      "Iteration 7, loss = 0.33738868\n",
      "Iteration 8, loss = 0.27664467\n",
      "Iteration 9, loss = 0.22630096\n",
      "Iteration 10, loss = 0.18544501\n",
      "Iteration 11, loss = 0.15314036\n",
      "Iteration 12, loss = 0.12756556\n",
      "Iteration 13, loss = 0.10721567\n",
      "Iteration 14, loss = 0.09100723\n",
      "Iteration 15, loss = 0.07791644\n",
      "Iteration 16, loss = 0.06730575\n",
      "Iteration 17, loss = 0.05862480\n",
      "Iteration 18, loss = 0.05143372\n",
      "Iteration 19, loss = 0.04545278\n",
      "Iteration 20, loss = 0.04040932\n",
      "Iteration 21, loss = 0.03621829\n",
      "Iteration 22, loss = 0.03265539\n",
      "Iteration 23, loss = 0.02955417\n",
      "Iteration 24, loss = 0.02687821\n",
      "Iteration 25, loss = 0.02455805\n",
      "Iteration 26, loss = 0.02256060\n",
      "Iteration 27, loss = 0.02081248\n",
      "Iteration 28, loss = 0.01924690\n",
      "Iteration 29, loss = 0.01788823\n",
      "Iteration 30, loss = 0.01666439\n",
      "Iteration 31, loss = 0.01557078\n",
      "Iteration 32, loss = 0.01458496\n",
      "Iteration 33, loss = 0.01371142\n",
      "Iteration 34, loss = 0.01293364\n",
      "Iteration 35, loss = 0.01221060\n",
      "Iteration 36, loss = 0.01154918\n",
      "Iteration 37, loss = 0.01095727\n",
      "Iteration 38, loss = 0.01042128\n",
      "Iteration 39, loss = 0.00992554\n",
      "Iteration 40, loss = 0.00945393\n",
      "Iteration 41, loss = 0.00906481\n",
      "Iteration 42, loss = 0.00868677\n",
      "Iteration 43, loss = 0.00830694\n",
      "Iteration 44, loss = 0.00799784\n",
      "Iteration 45, loss = 0.00769743\n",
      "Iteration 46, loss = 0.00741797\n",
      "Iteration 47, loss = 0.00714387\n",
      "Iteration 48, loss = 0.00689923\n",
      "Iteration 49, loss = 0.00666973\n",
      "Iteration 50, loss = 0.00646559\n",
      "Iteration 51, loss = 0.00625904\n",
      "Iteration 52, loss = 0.00608435\n",
      "Iteration 53, loss = 0.00590239\n",
      "Iteration 54, loss = 0.00574898\n",
      "Iteration 55, loss = 0.00559840\n",
      "Iteration 56, loss = 0.00544219\n",
      "Iteration 57, loss = 0.00530553\n",
      "Iteration 58, loss = 0.00518167\n",
      "Iteration 59, loss = 0.00506386\n",
      "Iteration 60, loss = 0.00494811\n",
      "Iteration 61, loss = 0.00484498\n",
      "Iteration 62, loss = 0.00474364\n",
      "Iteration 63, loss = 0.00465506\n",
      "Iteration 64, loss = 0.00455990\n",
      "Iteration 65, loss = 0.00446891\n",
      "Iteration 66, loss = 0.00438601\n",
      "Iteration 67, loss = 0.00430532\n",
      "Iteration 68, loss = 0.00423647\n",
      "Iteration 69, loss = 0.00415905\n",
      "Iteration 70, loss = 0.00409473\n",
      "Iteration 71, loss = 0.00403490\n",
      "Iteration 72, loss = 0.00397178\n",
      "Iteration 73, loss = 0.00391384\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 94.51313755795981\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69062081\n",
      "Iteration 2, loss = 0.66450994\n",
      "Iteration 3, loss = 0.61887280\n",
      "Iteration 4, loss = 0.55495687\n",
      "Iteration 5, loss = 0.48093969\n",
      "Iteration 6, loss = 0.40585579\n",
      "Iteration 7, loss = 0.33599253\n",
      "Iteration 8, loss = 0.27559497\n",
      "Iteration 9, loss = 0.22535158\n",
      "Iteration 10, loss = 0.18497751\n",
      "Iteration 11, loss = 0.15274505\n",
      "Iteration 12, loss = 0.12725058\n",
      "Iteration 13, loss = 0.10706941\n",
      "Iteration 14, loss = 0.09084437\n",
      "Iteration 15, loss = 0.07780919\n",
      "Iteration 16, loss = 0.06729039\n",
      "Iteration 17, loss = 0.05856175\n",
      "Iteration 18, loss = 0.05138916\n",
      "Iteration 19, loss = 0.04540604\n",
      "Iteration 20, loss = 0.04035798\n",
      "Iteration 21, loss = 0.03617175\n",
      "Iteration 22, loss = 0.03253234\n",
      "Iteration 23, loss = 0.02947894\n",
      "Iteration 24, loss = 0.02681280\n",
      "Iteration 25, loss = 0.02450153\n",
      "Iteration 26, loss = 0.02248100\n",
      "Iteration 27, loss = 0.02071969\n",
      "Iteration 28, loss = 0.01917285\n",
      "Iteration 29, loss = 0.01778410\n",
      "Iteration 30, loss = 0.01657945\n",
      "Iteration 31, loss = 0.01548357\n",
      "Iteration 32, loss = 0.01450836\n",
      "Iteration 33, loss = 0.01361850\n",
      "Iteration 34, loss = 0.01283503\n",
      "Iteration 35, loss = 0.01212841\n",
      "Iteration 36, loss = 0.01147236\n",
      "Iteration 37, loss = 0.01087796\n",
      "Iteration 38, loss = 0.01034885\n",
      "Iteration 39, loss = 0.00984051\n",
      "Iteration 40, loss = 0.00940275\n",
      "Iteration 41, loss = 0.00897873\n",
      "Iteration 42, loss = 0.00859102\n",
      "Iteration 43, loss = 0.00824017\n",
      "Iteration 44, loss = 0.00792435\n",
      "Iteration 45, loss = 0.00762499\n",
      "Iteration 46, loss = 0.00733941\n",
      "Iteration 47, loss = 0.00707435\n",
      "Iteration 48, loss = 0.00683443\n",
      "Iteration 49, loss = 0.00661040\n",
      "Iteration 50, loss = 0.00639901\n",
      "Iteration 51, loss = 0.00620838\n",
      "Iteration 52, loss = 0.00601541\n",
      "Iteration 53, loss = 0.00584767\n",
      "Iteration 54, loss = 0.00568867\n",
      "Iteration 55, loss = 0.00553851\n",
      "Iteration 56, loss = 0.00539424\n",
      "Iteration 57, loss = 0.00526601\n",
      "Iteration 58, loss = 0.00513475\n",
      "Iteration 59, loss = 0.00501733\n",
      "Iteration 60, loss = 0.00490921\n",
      "Iteration 61, loss = 0.00479494\n",
      "Iteration 62, loss = 0.00469490\n",
      "Iteration 63, loss = 0.00459933\n",
      "Iteration 64, loss = 0.00451164\n",
      "Iteration 65, loss = 0.00442794\n",
      "Iteration 66, loss = 0.00434856\n",
      "Iteration 67, loss = 0.00426671\n",
      "Iteration 68, loss = 0.00419333\n",
      "Iteration 69, loss = 0.00412305\n",
      "Iteration 70, loss = 0.00405864\n",
      "Iteration 71, loss = 0.00399700\n",
      "Iteration 72, loss = 0.00393277\n",
      "Iteration 73, loss = 0.00387915\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 93.81761978361669\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69133431\n",
      "Iteration 2, loss = 0.66402586\n",
      "Iteration 3, loss = 0.61816036\n",
      "Iteration 4, loss = 0.55487177\n",
      "Iteration 5, loss = 0.48155035\n",
      "Iteration 6, loss = 0.40761285\n",
      "Iteration 7, loss = 0.33881038\n",
      "Iteration 8, loss = 0.27887564\n",
      "Iteration 9, loss = 0.22892786\n",
      "Iteration 10, loss = 0.18790366\n",
      "Iteration 11, loss = 0.15545558\n",
      "Iteration 12, loss = 0.12967363\n",
      "Iteration 13, loss = 0.10915826\n",
      "Iteration 14, loss = 0.09279277\n",
      "Iteration 15, loss = 0.07957281\n",
      "Iteration 16, loss = 0.06883838\n",
      "Iteration 17, loss = 0.06005390\n",
      "Iteration 18, loss = 0.05271835\n",
      "Iteration 19, loss = 0.04660471\n",
      "Iteration 20, loss = 0.04149484\n",
      "Iteration 21, loss = 0.03720060\n",
      "Iteration 22, loss = 0.03351979\n",
      "Iteration 23, loss = 0.03034916\n",
      "Iteration 24, loss = 0.02765700\n",
      "Iteration 25, loss = 0.02525946\n",
      "Iteration 26, loss = 0.02323625\n",
      "Iteration 27, loss = 0.02139988\n",
      "Iteration 28, loss = 0.01980042\n",
      "Iteration 29, loss = 0.01839444\n",
      "Iteration 30, loss = 0.01713164\n",
      "Iteration 31, loss = 0.01598238\n",
      "Iteration 32, loss = 0.01503735\n",
      "Iteration 33, loss = 0.01409528\n",
      "Iteration 34, loss = 0.01330877\n",
      "Iteration 35, loss = 0.01254863\n",
      "Iteration 36, loss = 0.01190803\n",
      "Iteration 37, loss = 0.01126297\n",
      "Iteration 38, loss = 0.01071378\n",
      "Iteration 39, loss = 0.01020051\n",
      "Iteration 40, loss = 0.00973534\n",
      "Iteration 41, loss = 0.00929934\n",
      "Iteration 42, loss = 0.00890239\n",
      "Iteration 43, loss = 0.00855191\n",
      "Iteration 44, loss = 0.00821533\n",
      "Iteration 45, loss = 0.00789582\n",
      "Iteration 46, loss = 0.00758828\n",
      "Iteration 47, loss = 0.00732742\n",
      "Iteration 48, loss = 0.00706698\n",
      "Iteration 49, loss = 0.00685161\n",
      "Iteration 50, loss = 0.00663391\n",
      "Iteration 51, loss = 0.00644163\n",
      "Iteration 52, loss = 0.00623169\n",
      "Iteration 53, loss = 0.00604576\n",
      "Iteration 54, loss = 0.00587897\n",
      "Iteration 55, loss = 0.00572997\n",
      "Iteration 56, loss = 0.00556781\n",
      "Iteration 57, loss = 0.00544086\n",
      "Iteration 58, loss = 0.00530821\n",
      "Iteration 59, loss = 0.00518602\n",
      "Iteration 60, loss = 0.00506831\n",
      "Iteration 61, loss = 0.00495806\n",
      "Iteration 62, loss = 0.00484999\n",
      "Iteration 63, loss = 0.00475127\n",
      "Iteration 64, loss = 0.00466071\n",
      "Iteration 65, loss = 0.00456838\n",
      "Iteration 66, loss = 0.00448404\n",
      "Iteration 67, loss = 0.00440782\n",
      "Iteration 68, loss = 0.00432931\n",
      "Iteration 69, loss = 0.00425402\n",
      "Iteration 70, loss = 0.00418840\n",
      "Iteration 71, loss = 0.00411963\n",
      "Iteration 72, loss = 0.00405638\n",
      "Iteration 73, loss = 0.00399694\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 95.74961360123648\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69014282\n",
      "Iteration 2, loss = 0.66381409\n",
      "Iteration 3, loss = 0.61910398\n",
      "Iteration 4, loss = 0.55765318\n",
      "Iteration 5, loss = 0.48626087\n",
      "Iteration 6, loss = 0.41274120\n",
      "Iteration 7, loss = 0.34402620\n",
      "Iteration 8, loss = 0.28375395\n",
      "Iteration 9, loss = 0.23340834\n",
      "Iteration 10, loss = 0.19231778\n",
      "Iteration 11, loss = 0.15921178\n",
      "Iteration 12, loss = 0.13324691\n",
      "Iteration 13, loss = 0.11214174\n",
      "Iteration 14, loss = 0.09537111\n",
      "Iteration 15, loss = 0.08184389\n",
      "Iteration 16, loss = 0.07077615\n",
      "Iteration 17, loss = 0.06169765\n",
      "Iteration 18, loss = 0.05423229\n",
      "Iteration 19, loss = 0.04792841\n",
      "Iteration 20, loss = 0.04263415\n",
      "Iteration 21, loss = 0.03818835\n",
      "Iteration 22, loss = 0.03439588\n",
      "Iteration 23, loss = 0.03109664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.02829617\n",
      "Iteration 25, loss = 0.02585252\n",
      "Iteration 26, loss = 0.02371240\n",
      "Iteration 27, loss = 0.02185942\n",
      "Iteration 28, loss = 0.02022221\n",
      "Iteration 29, loss = 0.01874166\n",
      "Iteration 30, loss = 0.01744449\n",
      "Iteration 31, loss = 0.01627817\n",
      "Iteration 32, loss = 0.01527856\n",
      "Iteration 33, loss = 0.01434292\n",
      "Iteration 34, loss = 0.01349751\n",
      "Iteration 35, loss = 0.01273556\n",
      "Iteration 36, loss = 0.01203765\n",
      "Iteration 37, loss = 0.01141858\n",
      "Iteration 38, loss = 0.01085401\n",
      "Iteration 39, loss = 0.01031604\n",
      "Iteration 40, loss = 0.00984901\n",
      "Iteration 41, loss = 0.00942504\n",
      "Iteration 42, loss = 0.00899827\n",
      "Iteration 43, loss = 0.00864653\n",
      "Iteration 44, loss = 0.00830396\n",
      "Iteration 45, loss = 0.00797736\n",
      "Iteration 46, loss = 0.00767947\n",
      "Iteration 47, loss = 0.00740282\n",
      "Iteration 48, loss = 0.00713648\n",
      "Iteration 49, loss = 0.00690320\n",
      "Iteration 50, loss = 0.00667942\n",
      "Iteration 51, loss = 0.00648062\n",
      "Iteration 52, loss = 0.00628483\n",
      "Iteration 53, loss = 0.00610331\n",
      "Iteration 54, loss = 0.00593351\n",
      "Iteration 55, loss = 0.00577583\n",
      "Iteration 56, loss = 0.00561529\n",
      "Iteration 57, loss = 0.00547953\n",
      "Iteration 58, loss = 0.00534252\n",
      "Iteration 59, loss = 0.00522221\n",
      "Iteration 60, loss = 0.00509865\n",
      "Iteration 61, loss = 0.00499062\n",
      "Iteration 62, loss = 0.00488261\n",
      "Iteration 63, loss = 0.00478596\n",
      "Iteration 64, loss = 0.00468922\n",
      "Iteration 65, loss = 0.00460107\n",
      "Iteration 66, loss = 0.00452139\n",
      "Iteration 67, loss = 0.00443277\n",
      "Iteration 68, loss = 0.00435218\n",
      "Iteration 69, loss = 0.00428257\n",
      "Iteration 70, loss = 0.00421219\n",
      "Iteration 71, loss = 0.00415490\n",
      "Iteration 72, loss = 0.00408138\n",
      "Iteration 73, loss = 0.00402124\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 95.13137557959814\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Iteration 1, loss = 0.69056628\n",
      "Iteration 2, loss = 0.66447965\n",
      "Iteration 3, loss = 0.61962616\n",
      "Iteration 4, loss = 0.55688253\n",
      "Iteration 5, loss = 0.48452919\n",
      "Iteration 6, loss = 0.41034856\n",
      "Iteration 7, loss = 0.34083494\n",
      "Iteration 8, loss = 0.28057792\n",
      "Iteration 9, loss = 0.22977773\n",
      "Iteration 10, loss = 0.18905644\n",
      "Iteration 11, loss = 0.15631213\n",
      "Iteration 12, loss = 0.13049822\n",
      "Iteration 13, loss = 0.11009051\n",
      "Iteration 14, loss = 0.09326935\n",
      "Iteration 15, loss = 0.08002321\n",
      "Iteration 16, loss = 0.06915145\n",
      "Iteration 17, loss = 0.06024576\n",
      "Iteration 18, loss = 0.05291241\n",
      "Iteration 19, loss = 0.04680254\n",
      "Iteration 20, loss = 0.04162816\n",
      "Iteration 21, loss = 0.03730326\n",
      "Iteration 22, loss = 0.03357658\n",
      "Iteration 23, loss = 0.03039234\n",
      "Iteration 24, loss = 0.02767466\n",
      "Iteration 25, loss = 0.02530372\n",
      "Iteration 26, loss = 0.02321389\n",
      "Iteration 27, loss = 0.02138426\n",
      "Iteration 28, loss = 0.01978911\n",
      "Iteration 29, loss = 0.01834757\n",
      "Iteration 30, loss = 0.01710236\n",
      "Iteration 31, loss = 0.01598024\n",
      "Iteration 32, loss = 0.01498010\n",
      "Iteration 33, loss = 0.01406787\n",
      "Iteration 34, loss = 0.01324633\n",
      "Iteration 35, loss = 0.01251605\n",
      "Iteration 36, loss = 0.01183709\n",
      "Iteration 37, loss = 0.01123803\n",
      "Iteration 38, loss = 0.01067559\n",
      "Iteration 39, loss = 0.01017861\n",
      "Iteration 40, loss = 0.00969158\n",
      "Iteration 41, loss = 0.00927490\n",
      "Iteration 42, loss = 0.00887812\n",
      "Iteration 43, loss = 0.00850811\n",
      "Iteration 44, loss = 0.00817937\n",
      "Iteration 45, loss = 0.00786532\n",
      "Iteration 46, loss = 0.00757593\n",
      "Iteration 47, loss = 0.00731483\n",
      "Iteration 48, loss = 0.00706373\n",
      "Iteration 49, loss = 0.00682692\n",
      "Iteration 50, loss = 0.00661766\n",
      "Iteration 51, loss = 0.00641424\n",
      "Iteration 52, loss = 0.00622267\n",
      "Iteration 53, loss = 0.00604976\n",
      "Iteration 54, loss = 0.00588246\n",
      "Iteration 55, loss = 0.00572199\n",
      "Iteration 56, loss = 0.00557733\n",
      "Iteration 57, loss = 0.00543584\n",
      "Iteration 58, loss = 0.00531050\n",
      "Iteration 59, loss = 0.00518842\n",
      "Iteration 60, loss = 0.00507355\n",
      "Iteration 61, loss = 0.00496466\n",
      "Iteration 62, loss = 0.00485740\n",
      "Iteration 63, loss = 0.00476084\n",
      "Iteration 64, loss = 0.00466907\n",
      "Iteration 65, loss = 0.00457957\n",
      "Iteration 66, loss = 0.00449773\n",
      "Iteration 67, loss = 0.00441794\n",
      "Iteration 68, loss = 0.00434015\n",
      "Iteration 69, loss = 0.00426885\n",
      "Iteration 70, loss = 0.00420336\n",
      "Iteration 71, loss = 0.00413948\n",
      "Iteration 72, loss = 0.00407410\n",
      "Iteration 73, loss = 0.00401474\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 95.44049459041732\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.51313755795981 %\n",
      "Fold 1: 93.81761978361669 %\n",
      "Fold 2: 95.74961360123648 %\n",
      "Fold 3: 95.13137557959814 %\n",
      "Fold 4: 95.44049459041732 %\n",
      "Average: 94.93044822256567 %\n",
      "Iteration 1, loss = 0.68890190\n",
      "Iteration 2, loss = 0.65275584\n",
      "Iteration 3, loss = 0.58997446\n",
      "Iteration 4, loss = 0.50716319\n",
      "Iteration 5, loss = 0.41836654\n",
      "Iteration 6, loss = 0.33614076\n",
      "Iteration 7, loss = 0.26680589\n",
      "Iteration 8, loss = 0.21196290\n",
      "Iteration 9, loss = 0.16934602\n",
      "Iteration 10, loss = 0.13700261\n",
      "Iteration 11, loss = 0.11231820\n",
      "Iteration 12, loss = 0.09316383\n",
      "Iteration 13, loss = 0.07826781\n",
      "Iteration 14, loss = 0.06650899\n",
      "Iteration 15, loss = 0.05697023\n",
      "Iteration 16, loss = 0.04937857\n",
      "Iteration 17, loss = 0.04307117\n",
      "Iteration 18, loss = 0.03792134\n",
      "Iteration 19, loss = 0.03363739\n",
      "Iteration 20, loss = 0.02998913\n",
      "Iteration 21, loss = 0.02696075\n",
      "Iteration 22, loss = 0.02435751\n",
      "Iteration 23, loss = 0.02213261\n",
      "Iteration 24, loss = 0.02019567\n",
      "Iteration 25, loss = 0.01851432\n",
      "Iteration 26, loss = 0.01708293\n",
      "Iteration 27, loss = 0.01578010\n",
      "Iteration 28, loss = 0.01466133\n",
      "Iteration 29, loss = 0.01367228\n",
      "Iteration 30, loss = 0.01277035\n",
      "Iteration 31, loss = 0.01196776\n",
      "Iteration 32, loss = 0.01124436\n",
      "Iteration 33, loss = 0.01059910\n",
      "Iteration 34, loss = 0.01004964\n",
      "Iteration 35, loss = 0.00952196\n",
      "Iteration 36, loss = 0.00902091\n",
      "Iteration 37, loss = 0.00859847\n",
      "Iteration 38, loss = 0.00820791\n",
      "Iteration 39, loss = 0.00784077\n",
      "Iteration 40, loss = 0.00751830\n",
      "Iteration 41, loss = 0.00718128\n",
      "Iteration 42, loss = 0.00691147\n",
      "Iteration 43, loss = 0.00665510\n",
      "Iteration 44, loss = 0.00641185\n",
      "Iteration 45, loss = 0.00619766\n",
      "Iteration 46, loss = 0.00597734\n",
      "Iteration 47, loss = 0.00579016\n",
      "Iteration 48, loss = 0.00560214\n",
      "Iteration 49, loss = 0.00544141\n",
      "Iteration 50, loss = 0.00529468\n",
      "Iteration 51, loss = 0.00514102\n",
      "Iteration 52, loss = 0.00500980\n",
      "Iteration 53, loss = 0.00487921\n",
      "Iteration 54, loss = 0.00476989\n",
      "Iteration 55, loss = 0.00464967\n",
      "Iteration 56, loss = 0.00454988\n",
      "Iteration 57, loss = 0.00445181\n",
      "Iteration 58, loss = 0.00435094\n",
      "Iteration 59, loss = 0.00426642\n",
      "Iteration 60, loss = 0.00418170\n",
      "Iteration 61, loss = 0.00411132\n",
      "Iteration 62, loss = 0.00403146\n",
      "Iteration 63, loss = 0.00396115\n",
      "Iteration 64, loss = 0.00389577\n",
      "Iteration 65, loss = 0.00383581\n",
      "Iteration 66, loss = 0.00377023\n",
      "Iteration 67, loss = 0.00371782\n",
      "Iteration 68, loss = 0.00365888\n",
      "Iteration 69, loss = 0.00360809\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.9524103831891224\n",
      "F1-Score:  0.9532483302975108\n",
      "Precision:  0.9469240048250904\n",
      "Recall:  0.9596577017114915\n",
      "AUC:  0.9523288508557457\n"
     ]
    }
   ],
   "source": [
    "clf=k_fold_cv_mlp(X_Train_Transformed_FeatureMap,Y_Train_FeatureMap.ravel())\n",
    "clf=MLPClassifier(random_state=102, max_iter=3000, verbose=True).fit(X_Train_Transformed_FeatureMap, Y_Train_FeatureMap.ravel())\n",
    "y_pred=clf.predict(X_Test_Transformed_FeatureMap)\n",
    "print(\"Accuracy: \",accuracy_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"F1-Score: \",f1_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Precision: \",precision_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"Recall: \",recall_score(Y_Test_FeatureMap.ravel(),y_pred))\n",
    "print(\"AUC: \",roc_auc_score(Y_Test_FeatureMap.ravel(),y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
